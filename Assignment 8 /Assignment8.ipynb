{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyhrXhdgcdCN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxCK7spor_qg"
      },
      "source": [
        "def predict(x_test, y_test, weight):\n",
        "  # This function will take the weight of the trained model and takes decission based on the threshold value\n",
        "  # Add Intercept\n",
        "  # x_test = add_intercept(x_test)\n",
        "  y_pred = np.ones(y_test.shape[0])\n",
        "  hypothesis = np.dot(x_test, weight.T)\n",
        "  for i in range(0, hypothesis.shape[0]):\n",
        "    if (hypothesis[i]<0.5):\n",
        "      y_pred[i] = 0\n",
        "    if (hypothesis[i]>=0.5):\n",
        "      y_pred[i] = 1\n",
        "  test_acc = accuracy_score(y_test, y_pred)\n",
        "  return test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr6ZrA2CsCRh"
      },
      "source": [
        "def new_predict(x_test, y_test, weight):\n",
        "  # This function will take the weight of the trained model and takes decission based on the threshold value\n",
        "  # Add Intercept\n",
        "  x_test = add_intercept(x_test)\n",
        "  y_pred = np.ones(y_test.shape[0])\n",
        "  hypothesis = np.dot(x_test, weight.T)\n",
        "  for i in range(0, hypothesis.shape[0]):\n",
        "    if (hypothesis[i]<0.5):\n",
        "      y_pred[i] = 0\n",
        "    if (hypothesis[i]>=0.5):\n",
        "      y_pred[i] = 1\n",
        "  test_acc = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)*100\n",
        "  recall = recall_score(y_test, y_pred)*100\n",
        "  f1 = f1_score(y_test, y_pred)*100\n",
        "  print(\"Training Accuracy: \", test_acc)\n",
        "  print(\"Prescission Score:\", precision)\n",
        "  print(\"Recall Score : \", recall) \n",
        "  print('F1 Score : ', f1)\n",
        "  print('Confusion Matrix : \\n' + str(confusion_matrix(y_test, y_pred)))\n",
        "  print(\"Classification Report for 3-classes: \")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  # calculate the overall accuracy\n",
        "  # print the confussion matrix\n",
        "  # print the classification report\n",
        "  return test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_RQFgvbsCUi"
      },
      "source": [
        "def add_intercept(x):\n",
        "  intercept = np.ones((x.shape[0], 1))\n",
        "  return np.concatenate((intercept, x), axis=1)\n",
        "def perceptron(x_train, y_train, same_weight = False):\n",
        "  # it uses only the threshold function (basic perceptron)\n",
        "  # add intercept \n",
        "  x_train = add_intercept(x_train)\n",
        "  used_index = []\n",
        "  weight = np.zeros(x_train.shape[1])# Intialize the weight randomly\n",
        "  if (same_weight == True): # If we need to do the same weight initilization\n",
        "    random.seed(10)\n",
        "  for i in range(0, x_train.shape[1]):\n",
        "    weight[i] = 0.1 # random.uniform(0, 0.1)\n",
        "  converged  = True\n",
        "  x_train, y_train = shuffle(x_train, y_train)  # shuffel the training sample\n",
        "  index = random.randint(0, x_train.shape[0]-1)\n",
        "  epoch = 1\n",
        "  while converged:\n",
        "    print(\"Epoch:\", epoch)\n",
        "    hypothesis = np.dot(x_train[index], weight.T)\n",
        "    if (y_train[index]==1 and hypothesis<0):\n",
        "      # update the weight\n",
        "      # w = w + x\n",
        "      weight = weight + x_train[index]\n",
        "    if (y_train[index]==0 and hypothesis>=0):\n",
        "      # update the weight\n",
        "      # w = w - x\n",
        "      weight = weight - x_train[index]\n",
        "    index = random.randint(0, x_train.shape[0]-1)     # pick the random sample\n",
        "    used_index.append(index)\n",
        "    if (len(set(used_index)) == x_train.shape[0]):\n",
        "      # now check what is the accuracy now\n",
        "      score = predict(x_train, y_train, weight)\n",
        "      if (score*100==100):\n",
        "        print(\"Succefully Converged:\")\n",
        "        converged = False\n",
        "    epoch = epoch + 1\n",
        "  return weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE8gOu15sJ0r"
      },
      "source": [
        "# OR Gate\n",
        "x_train = np.array([[0, 1], [1, 1], [0, 0], [1, 0]])\n",
        "y_train = np.array([1, 1, 0, 1])\n",
        "weight  = perceptron(x_train, y_train, same_weight = False)\n",
        "test_arr = new_predict(x_train, y_train, weight)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r96v9nxfsJ3p"
      },
      "source": [
        "# AND Gate\n",
        "x_train = np.array([[0, 1], [1, 1], [0, 0], [1, 0]])\n",
        "y_train = np.array([0, 1, 0, 0])\n",
        "weight  = perceptron(x_train, y_train, same_weight = False)\n",
        "test_arr = new_predict(x_train, y_train, weight)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U31Mxu1OsWdh"
      },
      "source": [
        "# NAND gate\n",
        "x_train = np.array([[0, 1], [1, 1], [0, 0], [1, 0]])\n",
        "y_train = np.array([1, 0, 1, 1])\n",
        "weight  = perceptron(x_train, y_train, same_weight = False)\n",
        "test_arr = new_predict(x_train, y_train, weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EI6HkIesppS"
      },
      "source": [
        "x_train = np.array([[0, 1], [1, 1], [0, 0], [1, 0]])\n",
        "y_train = np.array([1, 0, 0, 1])\n",
        "weight  = perceptron(x_train, y_train, same_weight = False)\n",
        "test_arr = new_predict(x_train, y_train, weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnjyI46kctWM",
        "outputId": "6aab79b2-3612-47d0-df1b-7adc9e0bb69c"
      },
      "source": [
        "from sklearn import datasets\n",
        "wine = datasets.load_wine()\n",
        "# print(wine)\n",
        "\n",
        "x = wine.data\n",
        "y = wine.target\n",
        "print(x.shape)\n",
        "# print(wine.DESCR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_61lKb1zmWVQ",
        "outputId": "394a90d7-aed0-48e3-c91a-eacf31925fcf"
      },
      "source": [
        "# add intercept / add x0\n",
        "X = wine.data\n",
        "def add_intercept(X):\n",
        "  X= np.hstack([np.ones((X.shape[0],1)), X])\n",
        "  return X\n",
        "\n",
        "print(X.shape)\n",
        "# print(X)\n",
        "y = add_intercept(X)\n",
        "# print(y)\n",
        "print(y.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13)\n",
            "(178, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4kaE_dFn3SI",
        "outputId": "f92799b3-32a0-48c7-d3e9-691914da6f83"
      },
      "source": [
        "# # Normalization\n",
        "# from sklearn import preprocessing\n",
        "# nor_data = preprocessing.normalize(x)\n",
        "# print(\"Before   \\n\\n\",x)\n",
        "# print(\"After\\n\\n\",nor_data)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# nor\n",
        "y = np.array(wine['target'])\n",
        "my_data = np.array(wine['data'])\n",
        "# print(my_data)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(my_data)\n",
        "nor_data = scaler.transform(my_data)\n",
        "# print(my_data)\n",
        "print(y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah0mlMAInfzj",
        "outputId": "9521ebf2-9232-4e04-8a98-a56854b645a3"
      },
      "source": [
        "# data after adding x0\n",
        "print(\"Before\\n\\n\",nor_data,\"\\nAfter\\n\\n\")\n",
        "x_total = add_intercept(nor_data)\n",
        "y_total = wine.target\n",
        "print(x_total[0])\n",
        "print(x_total[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before\n",
            "\n",
            " [[0.84210526 0.1916996  0.57219251 ... 0.45528455 0.97069597 0.56134094]\n",
            " [0.57105263 0.2055336  0.4171123  ... 0.46341463 0.78021978 0.55064194]\n",
            " [0.56052632 0.3201581  0.70053476 ... 0.44715447 0.6959707  0.64693295]\n",
            " ...\n",
            " [0.58947368 0.69960474 0.48128342 ... 0.08943089 0.10622711 0.39728959]\n",
            " [0.56315789 0.36561265 0.54010695 ... 0.09756098 0.12820513 0.40085592]\n",
            " [0.81578947 0.66403162 0.73796791 ... 0.10569106 0.12087912 0.20114123]] \n",
            "After\n",
            "\n",
            "\n",
            "[1.         0.84210526 0.1916996  0.57219251 0.25773196 0.61956522\n",
            " 0.62758621 0.57383966 0.28301887 0.59305994 0.37201365 0.45528455\n",
            " 0.97069597 0.56134094]\n",
            "[1.         0.57105263 0.2055336  0.4171123  0.03092784 0.32608696\n",
            " 0.57586207 0.51054852 0.24528302 0.27444795 0.26450512 0.46341463\n",
            " 0.78021978 0.55064194]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if1BnWd-EQBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfddfd9d-4d39-4df7-968b-92d572377461"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "[1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GetDChyppeYS"
      },
      "source": [
        "# spliting data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "# x_total = nor_x\n",
        "# y_total = y\n",
        "X_train,X_test,y_train,y_test = train_test_split(x_total,y_total,test_size = 0.5,random_state = 1)\n",
        "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size = 0.4,random_state = 1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_validation.shape)\n",
        "# print(X_test.shape)\n",
        "# print(X_train)\n",
        "# print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve1TLHxk-ncL"
      },
      "source": [
        "# Sigmoid function to bound the hypothesis\n",
        "def sigmoid(z):                 \n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "# log-loss function\n",
        "def loss(h, y):                \n",
        "    return (-y*np.log(h) - (1-y)*np.log(1-h)).mean()\n",
        "\n",
        "\n",
        "# mean square error\n",
        "def mse(h, y):                \n",
        "    return (((h-y)**2).mean())/2\n",
        "\n",
        "# predict probability\n",
        "def predict_prob(x):\n",
        "    return sigmoid(x)\n",
        "\n",
        "# \n",
        "def y_predict(x):\n",
        "    return predict_prob(x).round()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olUprVHip5_X"
      },
      "source": [
        "# learnig algorithm\n",
        "# Single layer perceptron(SLP)\n",
        "\n",
        "def Algorithm(x,y,epoch,rho):\n",
        "  weight = np.zeros(x.shape[1])\n",
        "  current_loss = 1  \n",
        "  error = 0\n",
        "  # random weight initialization\n",
        "  for i in range(0, x.shape[1]):\n",
        "      weight[i] = random.uniform(-0.3, 0.3)\n",
        "  theta = weight \n",
        "\n",
        "  for i in range(epoch):\n",
        "    # convergence if we reached the max epoch and\n",
        "    z = np.dot(x[i],theta)\n",
        "    d = sigmoid(z)\n",
        "    # gradient\n",
        "    gradient = np.dot(x.T, (h - y)) / y.size\n",
        "    theta = theta - alpha * gradient\n",
        "    z = np.dot(x, theta)\n",
        "    y_pre = d\n",
        "    los = loss(h, y)\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}