{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN6hAmWkgrVE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZO09dVkg45p",
        "outputId": "84b6bc27-a215-4c8a-fa93-6e9eadac538b"
      },
      "source": [
        "# data loading\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "iris_x = iris['data']\n",
        "iris_y = iris['target']\n",
        "# print(iris.data)\n",
        "# print(iris['feature_names'])\n",
        "# print(iris['data'].shape)\n",
        "print(iris['target'])    \n",
        "# print(iris['target_names'])    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFcW9iYuqNd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699f211b-c84f-4f83-ba82-07a90f0151ab"
      },
      "source": [
        "y = np.array(iris['target'])\n",
        "x = np.array(iris['data'])\n",
        "print(\"No of the feature vectors: %d\"%features.shape[1])\n",
        "print(\"No of the Patterns: %d\"%features.shape[0])\n",
        "print(\"No of classes:\", list(set(iris['target'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of the feature vectors: 4\n",
            "No of the Patterns: 150\n",
            "No of classes: [0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoQmPeFMiZvU"
      },
      "source": [
        "# Normalization using MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = np.array(iris['data'])\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(data)\n",
        "nor_x = scaler.transform(data)\n",
        "\n",
        "# print(nor_x)\n",
        "# print(data ,\"\\nAfter Normalization \\n\\n\")\n",
        "# print(nor_x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOTmaTBWltV1"
      },
      "source": [
        "# shuffel the datasample\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "x, y = shuffle(features, y_actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EGsA7V-keJB"
      },
      "source": [
        "# splinting data    train = 30%, test = 50%, validation = 20%\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_total = x\n",
        "y_total = y\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(x_total,y_total,test_size = 0.5,random_state = 1)\n",
        "X_train,X_validation,y_train,y_validation = train_test_split(X_train,y_train,test_size = 0.4,random_state = 1)\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(X_validation.shape)\n",
        "# print(X_test.shape)\n",
        "# print(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "OWtYHo6B9Gp5",
        "outputId": "136b27ab-b783-4259-f2c7-3bcba7ddc170"
      },
      "source": [
        "# ploting\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "iris[\"ID\"] = iris.index\n",
        "iris[\"ratio\"] = iris[\"sepal_length\"]/iris[\"sepal_width\"]\n",
        "\n",
        "sns.lmplot(x=\"ID\", y=\"ratio\", data=iris, hue=\"species\", fit_reg=False, legend=False)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZVoDcXTl8Mb",
        "outputId": "8f307704-d7a3-48d6-c5b0-c41136ee5974"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "def fold(features,y_actual):\n",
        "  kf = KFold(n_splits=5,random_state=1000, shuffle=True)\n",
        "  kf.get_n_splits(features)\n",
        "  print(kf)\n",
        "  all_x_train = []\n",
        "  all_x_test = []\n",
        "  all_y_train = []\n",
        "  all_y_test = []\n",
        "  for train_index, test_index in kf.split(features):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = y_actual[train_index], y_actual[test_index]\n",
        "    all_x_train.append(X_train)\n",
        "    all_x_test.append(X_test)\n",
        "    all_y_train.append(y_train)\n",
        "    all_y_test.append(y_test)\n",
        "  all_x_train, all_x_test, all_y_train, all_y_test  = np.array(all_x_train), np.array(all_x_test), np.array(all_y_train), np.array(all_y_test)\n",
        "  return all_x_train, all_x_test, all_y_train, all_y_test\n",
        "\n",
        "\n",
        "all_x_train, all_x_test, all_y_train, all_y_test = fold(features,y_actual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KFold(n_splits=5, random_state=1000, shuffle=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ks2KPwkiiC",
        "outputId": "3eedc901-70ff-43d6-99eb-1305cab87843"
      },
      "source": [
        "# one-hot-encoding\n",
        "def oneHotEncoding(Y):\n",
        "  y1 = []\n",
        "  y2 = []\n",
        "  y3 = []\n",
        "  \n",
        "  for i in range(0 , len(Y)):\n",
        "    if (Y[i] == 0):\n",
        "      y1.append(1)\n",
        "      y2.append(0)\n",
        "      y3.append(0)\n",
        "     \n",
        "    elif (Y[i] == 1):\n",
        "      y1.append(0)\n",
        "      y2.append(1)\n",
        "      y3.append(0)\n",
        "    \n",
        "    else :\n",
        "      y1.append(0)\n",
        "      y2.append(0)\n",
        "      y3.append(1)\n",
        "    \n",
        "  return y1 ,y2 ,y3\n",
        "\n",
        "# check\n",
        "y1,y2,y3 = oneHotEncoding(y_train)\n",
        "print(y1)\n",
        "print(y2)\n",
        "print(y3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
            "[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7PNi4YflANc"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def one_hot_encoding(y):\n",
        "  label_encoder = LabelEncoder()\n",
        "  integer_encoded = label_encoder.fit_transform(y)\n",
        "  onehot_encoder = OneHotEncoder(sparse=False)\n",
        "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "  onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "  return onehot_encoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNnhnhw2CPR-"
      },
      "source": [
        "# adding one column with all once\n",
        "def add_intercept(x):\n",
        "  intercept = np.ones((x.shape[0], 1))\n",
        "  return np.concatenate((intercept, x), axis=1)\n",
        "\n",
        "\n",
        "# Sigmoid function to bound the hypothesis\n",
        "def sigmoid(z):                 \n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "# log-loss function\n",
        "def loss(h, y):                \n",
        "    return sum(-y*np.log(h) - (1-y)*np.log(1-h))\n",
        "\n",
        "\n",
        "# mean square error\n",
        "def mse(h, y):                \n",
        "    return (((h-y)**2).mean())/2\n",
        "\n",
        "def mse_in_iter(h,y):\n",
        "  return (sum((h-y)**2))/2\n",
        "\n",
        "# predictation\n",
        "def predict(x, y, all_weights):\n",
        "  # add intercept into x values\n",
        "  X = add_intercept(x)\n",
        "  y = []\n",
        "  for i in range(len(X)):\n",
        "    d1 = np.dot(all_weights[0], X[i].T)\n",
        "    d2 = np.dot(all_weights[1], X[i].T)\n",
        "    d3 = np.dot(all_weights[2], X[i].T)\n",
        "    if (d1 > d2 and d1 > d3):\n",
        "      y.append(0)\n",
        "    elif (d2 > d1 and d2 > d3):\n",
        "      y.append(1)\n",
        "    else :\n",
        "      y.append(2)\n",
        "  return y\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9ZDsbMlCscq",
        "outputId": "6db23155-8f4a-4e95-bb4d-1284de60e566"
      },
      "source": [
        "y_new = one_hot_encoding(y)\n",
        "print(y_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMl6fP39DaJb"
      },
      "source": [
        "def sigmoid_neuron(x, y, lr=0.01, roh = 0.000001, num_iter=100):\n",
        "  x = add_intercept(x) # add intercept in the feature vectors (in independent varibales)\n",
        "  all_hypothesis = []\n",
        "  all_weights = []\n",
        "  final_hypothesis = []\n",
        "  classes = list(set(y)) # find how many classes are there...\n",
        "  d = np.ones(len(classes))\n",
        "  # calculate the weight vector (2D array, shape will be (no_of_classes*no_of_feature_vector))\n",
        "  for i in range(0, len(classes)):\n",
        "    weight = np.ones(x.shape[1])*0.1\n",
        "    all_weights.append(weight)\n",
        "  all_weights = np.array(all_weights)\n",
        "  converged = True\n",
        "  epoch = 0\n",
        "  # make one hot encoding\n",
        "  y_onehot = one_hot_encoding(y)\n",
        "  current_loss = 0\n",
        "  while converged:\n",
        "    logloss_error = 0\n",
        "    mse_error = 0   # at the starting of each epoch mse will be 0\n",
        "    for i in range(0, x.shape[0]): # for each training sample one by one\n",
        "      hypo = np.ones(len(classes))\n",
        "      for k in range(0, len(classes)): # for calculating d values\n",
        "        z = np.dot(x[i], all_weights[k].T)\n",
        "        h = sigmoid(z)  # hypothesis\n",
        "        hypo[k] = h\n",
        "        if (h>=0.5):\n",
        "          d[k] = 1 # predicted one\n",
        "        if (h<0.5):\n",
        "          d[k] = 0 # predicted one\n",
        "      # calculate the errror (mse and logloss)\n",
        "      # but we are converging through the logloss only\n",
        "      mse_error = mse_error + mse_in_iter(hypo, y_onehot[i])\n",
        "      logloss_error = logloss_error + loss(hypo, y_onehot[i])\n",
        "      # Weight updation using the current training sample\n",
        "      update_weights = []\n",
        "      for j in range(0, len(classes)):\n",
        "        all_weights[j] = all_weights[j] + x[i]*(y_onehot[i][j]-d[j])*lr\n",
        "    print(f'Epoch: {epoch} ------>' + f'logloss: {logloss_error/x.shape[0]} ------>' + f' ------> Mse: {mse_error/x.shape[0]} \\t ')\n",
        "    if(abs(current_loss - (logloss_error/x.shape[0])) <= roh):\n",
        "        print(f\"Converged through roh criteria: epoch = {i}\")\n",
        "        break # converged\n",
        "    current_loss = logloss_error/x.shape[0] # save the previous error to calculate the diff in current error and previous error\n",
        "    epoch = epoch + 1\n",
        "    if (epoch== num_iter):\n",
        "      print(\"Converged through maximum epoch no criteria...\") # converged\n",
        "      # return the traning accuracy also\n",
        "      return all_weights\n",
        "  # return the accuracy also\n",
        "  y_predicted = predict_inner(x, y, all_weights)\n",
        "  y_predicted = np.array(y_predicted)\n",
        "  acc = accuracy_score(y, y_predicted)*100\n",
        "  print(\"Train Accuracy: \" + str(acc))\n",
        "  return all_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Gi8bVansg2",
        "outputId": "6cf2d7cc-9f48-4a31-8f15-6529163f2206"
      },
      "source": [
        "all_weights = sigmoid_neuron(X_train, y_train, lr=0.3, roh = 0.000001, num_iter=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 ------>logloss: 8.685748170651376 ------> ------> Mse: 0.44465272454488186 \t \n",
            "Epoch: 1 ------>logloss: 5.944872271759041 ------> ------> Mse: 0.2620832044201669 \t \n",
            "Epoch: 2 ------>logloss: 3.878354819401645 ------> ------> Mse: 0.1949655681717792 \t \n",
            "Epoch: 3 ------>logloss: 4.057895198750287 ------> ------> Mse: 0.18064127837701136 \t \n",
            "Epoch: 4 ------>logloss: 3.2535619710499084 ------> ------> Mse: 0.17923190481529103 \t \n",
            "Epoch: 5 ------>logloss: 4.4367908972257855 ------> ------> Mse: 0.19486454734081093 \t \n",
            "Epoch: 6 ------>logloss: 3.8874410118266787 ------> ------> Mse: 0.19406410548949035 \t \n",
            "Epoch: 7 ------>logloss: 3.5921125854828153 ------> ------> Mse: 0.1969576727882761 \t \n",
            "Epoch: 8 ------>logloss: 4.311534663195786 ------> ------> Mse: 0.20151003736503711 \t \n",
            "Epoch: 9 ------>logloss: 4.192466008414691 ------> ------> Mse: 0.19338500917777926 \t \n",
            "Epoch: 10 ------>logloss: 3.610133369364738 ------> ------> Mse: 0.1902126295179424 \t \n",
            "Epoch: 11 ------>logloss: 3.449234695270425 ------> ------> Mse: 0.18837259965575043 \t \n",
            "Epoch: 12 ------>logloss: 3.9940935627226737 ------> ------> Mse: 0.18207522876864243 \t \n",
            "Epoch: 13 ------>logloss: 3.2511783322833336 ------> ------> Mse: 0.16390503887564908 \t \n",
            "Epoch: 14 ------>logloss: 3.4105905389409 ------> ------> Mse: 0.18811615991297603 \t \n",
            "Epoch: 15 ------>logloss: 2.120610944603039 ------> ------> Mse: 0.12536135605771337 \t \n",
            "Epoch: 16 ------>logloss: 1.9290343648541548 ------> ------> Mse: 0.09507154209443638 \t \n",
            "Epoch: 17 ------>logloss: 1.9269296142960501 ------> ------> Mse: 0.0931281010906667 \t \n",
            "Epoch: 18 ------>logloss: 2.67322479642485 ------> ------> Mse: 0.11559565634425871 \t \n",
            "Epoch: 19 ------>logloss: 3.7310319845455373 ------> ------> Mse: 0.17432436503899937 \t \n",
            "Epoch: 20 ------>logloss: 2.792123545839191 ------> ------> Mse: 0.14940569612299145 \t \n",
            "Epoch: 21 ------>logloss: 2.6705949685476726 ------> ------> Mse: 0.1154087261518416 \t \n",
            "Epoch: 22 ------>logloss: 3.105253060399295 ------> ------> Mse: 0.16389490594961284 \t \n",
            "Epoch: 23 ------>logloss: 3.22524007355522 ------> ------> Mse: 0.19245196072717433 \t \n",
            "Epoch: 24 ------>logloss: 2.6757466257532077 ------> ------> Mse: 0.13624134474527588 \t \n",
            "Epoch: 25 ------>logloss: 2.2117899483108996 ------> ------> Mse: 0.09968701496179008 \t \n",
            "Epoch: 26 ------>logloss: 3.1763087110343613 ------> ------> Mse: 0.16572262771902393 \t \n",
            "Epoch: 27 ------>logloss: 2.573377367762571 ------> ------> Mse: 0.14782549244764523 \t \n",
            "Epoch: 28 ------>logloss: 2.9115384416121484 ------> ------> Mse: 0.16957036374787288 \t \n",
            "Epoch: 29 ------>logloss: 2.609615855572683 ------> ------> Mse: 0.1450137786152059 \t \n",
            "Epoch: 30 ------>logloss: 1.86999940260848 ------> ------> Mse: 0.09950376222154554 \t \n",
            "Epoch: 31 ------>logloss: 1.8646992040551345 ------> ------> Mse: 0.0973218164741059 \t \n",
            "Epoch: 32 ------>logloss: 2.213057294536532 ------> ------> Mse: 0.10312581572871708 \t \n",
            "Epoch: 33 ------>logloss: 2.214287796863845 ------> ------> Mse: 0.09850737857220854 \t \n",
            "Epoch: 34 ------>logloss: 3.1124362295687504 ------> ------> Mse: 0.16268354199626994 \t \n",
            "Epoch: 35 ------>logloss: 2.8798953814394155 ------> ------> Mse: 0.17673991871793823 \t \n",
            "Epoch: 36 ------>logloss: 2.5149214905151487 ------> ------> Mse: 0.14305860277567287 \t \n",
            "Epoch: 37 ------>logloss: 2.210714803896476 ------> ------> Mse: 0.1011033822348967 \t \n",
            "Epoch: 38 ------>logloss: 2.221034673264451 ------> ------> Mse: 0.09706097307706205 \t \n",
            "Epoch: 39 ------>logloss: 3.0844889989615574 ------> ------> Mse: 0.1599168896071711 \t \n",
            "Epoch: 40 ------>logloss: 2.490932128672159 ------> ------> Mse: 0.14458914634504708 \t \n",
            "Epoch: 41 ------>logloss: 3.203324539337306 ------> ------> Mse: 0.1771323747297803 \t \n",
            "Epoch: 42 ------>logloss: 2.2238011013367576 ------> ------> Mse: 0.10202315970506069 \t \n",
            "Epoch: 43 ------>logloss: 3.515336958682615 ------> ------> Mse: 0.18799453701705524 \t \n",
            "Epoch: 44 ------>logloss: 3.4897525532013534 ------> ------> Mse: 0.18678867244719316 \t \n",
            "Epoch: 45 ------>logloss: 2.236146374814037 ------> ------> Mse: 0.10213845058718696 \t \n",
            "Epoch: 46 ------>logloss: 2.8857233212997704 ------> ------> Mse: 0.1642396767512021 \t \n",
            "Epoch: 47 ------>logloss: 2.2766377812964205 ------> ------> Mse: 0.1278865369114453 \t \n",
            "Epoch: 48 ------>logloss: 2.2249371723178495 ------> ------> Mse: 0.10301527193748683 \t \n",
            "Epoch: 49 ------>logloss: 2.2158598379515104 ------> ------> Mse: 0.0996411322589584 \t \n",
            "Epoch: 50 ------>logloss: 3.1830420313179513 ------> ------> Mse: 0.17889932720232976 \t \n",
            "Epoch: 51 ------>logloss: 2.218358131489052 ------> ------> Mse: 0.10179670474660417 \t \n",
            "Epoch: 52 ------>logloss: 2.2206832026332015 ------> ------> Mse: 0.09832737188274523 \t \n",
            "Epoch: 53 ------>logloss: 3.18258993756785 ------> ------> Mse: 0.17796947022255694 \t \n",
            "Epoch: 54 ------>logloss: 2.216187821342054 ------> ------> Mse: 0.1007537131271244 \t \n",
            "Epoch: 55 ------>logloss: 3.1810611902471724 ------> ------> Mse: 0.17945103796659959 \t \n",
            "Epoch: 56 ------>logloss: 2.224710033473141 ------> ------> Mse: 0.10324471715509001 \t \n",
            "Epoch: 57 ------>logloss: 2.217922325191083 ------> ------> Mse: 0.09947171007827499 \t \n",
            "Epoch: 58 ------>logloss: 3.1770722082073948 ------> ------> Mse: 0.17905016191027773 \t \n",
            "Epoch: 59 ------>logloss: 2.220243839241945 ------> ------> Mse: 0.10224949091207447 \t \n",
            "Epoch: 60 ------>logloss: 2.223830967732027 ------> ------> Mse: 0.09790953705918712 \t \n",
            "Epoch: 61 ------>logloss: 3.1785936500977825 ------> ------> Mse: 0.17743732754097782 \t \n",
            "Epoch: 62 ------>logloss: 2.219462421241659 ------> ------> Mse: 0.10110853973728053 \t \n",
            "Epoch: 63 ------>logloss: 3.291066981376589 ------> ------> Mse: 0.1930560996245028 \t \n",
            "Epoch: 64 ------>logloss: 1.376576183620561 ------> ------> Mse: 0.09049373540159274 \t \n",
            "Epoch: 65 ------>logloss: 1.2718719784810935 ------> ------> Mse: 0.08187976303023514 \t \n",
            "Epoch: 66 ------>logloss: 3.1067365777017106 ------> ------> Mse: 0.173773190748732 \t \n",
            "Epoch: 67 ------>logloss: 2.224655408872504 ------> ------> Mse: 0.10130132334144304 \t \n",
            "Epoch: 68 ------>logloss: 3.1065855383309002 ------> ------> Mse: 0.17433052290599652 \t \n",
            "Epoch: 69 ------>logloss: 2.2313922767536076 ------> ------> Mse: 0.10245391567560207 \t \n",
            "Epoch: 70 ------>logloss: 2.225231664313064 ------> ------> Mse: 0.10067119150227839 \t \n",
            "Epoch: 71 ------>logloss: 3.100646895982752 ------> ------> Mse: 0.17440795752801247 \t \n",
            "Epoch: 72 ------>logloss: 2.2271386224991394 ------> ------> Mse: 0.10199112546789739 \t \n",
            "Epoch: 73 ------>logloss: 2.228910163152908 ------> ------> Mse: 0.09965496403567567 \t \n",
            "Epoch: 74 ------>logloss: 3.100301969015803 ------> ------> Mse: 0.1731458970940654 \t \n",
            "Epoch: 75 ------>logloss: 2.2258029045057106 ------> ------> Mse: 0.10146536290912676 \t \n",
            "Epoch: 76 ------>logloss: 3.0996144217943593 ------> ------> Mse: 0.17464927565288565 \t \n",
            "Epoch: 77 ------>logloss: 2.2324742232126695 ------> ------> Mse: 0.1030588255192647 \t \n",
            "Epoch: 78 ------>logloss: 2.227175574406748 ------> ------> Mse: 0.10061345651396526 \t \n",
            "Epoch: 79 ------>logloss: 3.0956233483283326 ------> ------> Mse: 0.17433560280843396 \t \n",
            "Epoch: 80 ------>logloss: 2.2294810094401614 ------> ------> Mse: 0.10259997123537355 \t \n",
            "Epoch: 81 ------>logloss: 2.2316599066403318 ------> ------> Mse: 0.0992948067690687 \t \n",
            "Epoch: 82 ------>logloss: 3.0976419991309894 ------> ------> Mse: 0.17246675774811396 \t \n",
            "Epoch: 83 ------>logloss: 2.2289749918823403 ------> ------> Mse: 0.1019089160200221 \t \n",
            "Epoch: 84 ------>logloss: 3.1886255969608794 ------> ------> Mse: 0.18724196875241184 \t \n",
            "Epoch: 85 ------>logloss: nan ------> ------> Mse: 0.13312367920411522 \t \n",
            "Epoch: 86 ------>logloss: 3.0375935197945765 ------> ------> Mse: 0.16853941511685822 \t \n",
            "Epoch: 87 ------>logloss: 2.2341266326510003 ------> ------> Mse: 0.1016327738797932 \t \n",
            "Epoch: 88 ------>logloss: 3.042450041157091 ------> ------> Mse: 0.1672312310963275 \t \n",
            "Epoch: 89 ------>logloss: 2.2410645042630697 ------> ------> Mse: 0.10214397027156008 \t \n",
            "Epoch: 90 ------>logloss: 2.2333277399302336 ------> ------> Mse: 0.101521518422401 \t \n",
            "Epoch: 91 ------>logloss: 3.032785803439906 ------> ------> Mse: 0.1680520732256029 \t \n",
            "Epoch: 92 ------>logloss: 2.236341696577194 ------> ------> Mse: 0.10195153613878531 \t \n",
            "Epoch: 93 ------>logloss: 2.2347706683895847 ------> ------> Mse: 0.10116615765295026 \t \n",
            "Epoch: 94 ------>logloss: 3.029540995868388 ------> ------> Mse: 0.16785654776430128 \t \n",
            "Epoch: 95 ------>logloss: 2.234090357919357 ------> ------> Mse: 0.10183320347233557 \t \n",
            "Epoch: 96 ------>logloss: 3.0336127761135003 ------> ------> Mse: 0.16718603496191858 \t \n",
            "Epoch: 97 ------>logloss: 2.240854632388503 ------> ------> Mse: 0.10259960396830212 \t \n",
            "Epoch: 98 ------>logloss: 2.233904640972462 ------> ------> Mse: 0.10157932519176652 \t \n",
            "Epoch: 99 ------>logloss: 3.0259841584963523 ------> ------> Mse: 0.16776181587858272 \t \n",
            "Epoch: 100 ------>logloss: 2.2372631617500245 ------> ------> Mse: 0.10244693080456668 \t \n",
            "Epoch: 101 ------>logloss: 2.235908862854038 ------> ------> Mse: 0.10097210212465108 \t \n",
            "Epoch: 102 ------>logloss: 3.025092622660505 ------> ------> Mse: 0.167185244228302 \t \n",
            "Epoch: 103 ------>logloss: 2.2356917694134926 ------> ------> Mse: 0.10223897153538947 \t \n",
            "Epoch: 104 ------>logloss: 3.028389282025086 ------> ------> Mse: 0.16735649502723368 \t \n",
            "Epoch: 105 ------>logloss: 2.2430498812732504 ------> ------> Mse: 0.1034988651599372 \t \n",
            "Epoch: 106 ------>logloss: 2.2360320882528444 ------> ------> Mse: 0.10178945856527823 \t \n",
            "Epoch: 107 ------>logloss: 3.022981713396725 ------> ------> Mse: 0.16756401154374187 \t \n",
            "Epoch: 108 ------>logloss: 2.240256549287906 ------> ------> Mse: 0.1033074710537043 \t \n",
            "Epoch: 109 ------>logloss: 2.2386299444909663 ------> ------> Mse: 0.10086771196032578 \t \n",
            "Epoch: 110 ------>logloss: 3.024739862372573 ------> ------> Mse: 0.16673593714866164 \t \n",
            "Epoch: 111 ------>logloss: 2.239218227489857 ------> ------> Mse: 0.10295799426272717 \t \n",
            "Epoch: 112 ------>logloss: 3.0858678222078284 ------> ------> Mse: 0.17748461084764844 \t \n",
            "Epoch: 113 ------>logloss: nan ------> ------> Mse: 0.12903482197351426 \t \n",
            "Epoch: 114 ------>logloss: 2.2429086968715626 ------> ------> Mse: 0.1031539317115471 \t \n",
            "Epoch: 115 ------>logloss: 2.23866011706304 ------> ------> Mse: 0.10151000941786226 \t \n",
            "Epoch: 116 ------>logloss: 2.999957167390903 ------> ------> Mse: 0.1645081471889953 \t \n",
            "Epoch: 117 ------>logloss: 2.2410069144660993 ------> ------> Mse: 0.10297502534925607 \t \n",
            "Epoch: 118 ------>logloss: 3.055083544509139 ------> ------> Mse: 0.17296678213172462 \t \n",
            "Epoch: 119 ------>logloss: nan ------> ------> Mse: 0.1333489111799006 \t \n",
            "Epoch: 120 ------>logloss: nan ------> ------> Mse: 0.10293366083047858 \t \n",
            "Epoch: 121 ------>logloss: 2.239844257083225 ------> ------> Mse: 0.10182723151432685 \t \n",
            "Epoch: 122 ------>logloss: 2.9780239782850515 ------> ------> Mse: 0.161685339129424 \t \n",
            "Epoch: 123 ------>logloss: nan ------> ------> Mse: 0.10284846392137159 \t \n",
            "Epoch: 124 ------>logloss: 2.2418706899345597 ------> ------> Mse: 0.10117314857998626 \t \n",
            "Epoch: 125 ------>logloss: 3.1204107346361476 ------> ------> Mse: 0.172783236226786 \t \n",
            "Epoch: 126 ------>logloss: 2.2410491452975045 ------> ------> Mse: 0.1026642469628181 \t \n",
            "Epoch: 127 ------>logloss: 3.028223674087264 ------> ------> Mse: 0.16989158509235586 \t \n",
            "Epoch: 128 ------>logloss: nan ------> ------> Mse: 0.13309983919367027 \t \n",
            "Epoch: 129 ------>logloss: nan ------> ------> Mse: 0.10266476968457373 \t \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 130 ------>logloss: 2.2410657600219173 ------> ------> Mse: 0.10151173353052985 \t \n",
            "Epoch: 131 ------>logloss: 2.958315215006527 ------> ------> Mse: 0.15881239965834018 \t \n",
            "Epoch: 132 ------>logloss: nan ------> ------> Mse: 0.10256911307601396 \t \n",
            "Epoch: 133 ------>logloss: 2.2188103013602145 ------> ------> Mse: 0.11531354833562932 \t \n",
            "Epoch: 134 ------>logloss: 2.7841808483659825 ------> ------> Mse: 0.15394667408657658 \t \n",
            "Epoch: 135 ------>logloss: 1.207913730048714 ------> ------> Mse: 0.10563909827946279 \t \n",
            "Epoch: 136 ------>logloss: 1.8678604866341646 ------> ------> Mse: 0.09904336942321529 \t \n",
            "Epoch: 137 ------>logloss: 2.0918729367529107 ------> ------> Mse: 0.12139476197467436 \t \n",
            "Epoch: 138 ------>logloss: nan ------> ------> Mse: 0.13016396303908967 \t \n",
            "Epoch: 139 ------>logloss: 1.3756102429496453 ------> ------> Mse: 0.08986954273751782 \t \n",
            "Epoch: 140 ------>logloss: nan ------> ------> Mse: 0.12825067513223515 \t \n",
            "Epoch: 141 ------>logloss: nan ------> ------> Mse: 0.1278036215857874 \t \n",
            "Epoch: 142 ------>logloss: nan ------> ------> Mse: 0.12391049657458444 \t \n",
            "Epoch: 143 ------>logloss: 2.0289693260347788 ------> ------> Mse: 0.12553551296677504 \t \n",
            "Epoch: 144 ------>logloss: 1.8022479436604573 ------> ------> Mse: 0.09329767851025016 \t \n",
            "Epoch: 145 ------>logloss: nan ------> ------> Mse: 0.12883675136446326 \t \n",
            "Epoch: 146 ------>logloss: nan ------> ------> Mse: 0.12503681271845787 \t \n",
            "Epoch: 147 ------>logloss: nan ------> ------> Mse: 0.09489167726413186 \t \n",
            "Epoch: 148 ------>logloss: 2.5645011117372927 ------> ------> Mse: 0.1208120652863761 \t \n",
            "Epoch: 149 ------>logloss: nan ------> ------> Mse: 0.12233629073380009 \t \n",
            "Epoch: 150 ------>logloss: 1.9324544860169064 ------> ------> Mse: 0.11755504660344888 \t \n",
            "Epoch: 151 ------>logloss: nan ------> ------> Mse: 0.12445974543944681 \t \n",
            "Epoch: 152 ------>logloss: 2.692140498786806 ------> ------> Mse: 0.1477946917621281 \t \n",
            "Epoch: 153 ------>logloss: 1.2869411551761962 ------> ------> Mse: 0.06967896585852015 \t \n",
            "Epoch: 154 ------>logloss: 2.5510176918174023 ------> ------> Mse: 0.1192013689463529 \t \n",
            "Epoch: 155 ------>logloss: 2.343815774004024 ------> ------> Mse: 0.10861889872277782 \t \n",
            "Epoch: 156 ------>logloss: nan ------> ------> Mse: 0.11053892963283221 \t \n",
            "Epoch: 157 ------>logloss: 1.5327836862774582 ------> ------> Mse: 0.07570546165212862 \t \n",
            "Epoch: 158 ------>logloss: 1.834319948929305 ------> ------> Mse: 0.09174037032734782 \t \n",
            "Epoch: 159 ------>logloss: nan ------> ------> Mse: 0.12475105560668595 \t \n",
            "Epoch: 160 ------>logloss: nan ------> ------> Mse: 0.09380921041877183 \t \n",
            "Epoch: 161 ------>logloss: 2.086018615374411 ------> ------> Mse: 0.10737587331942641 \t \n",
            "Epoch: 162 ------>logloss: nan ------> ------> Mse: 0.11961064512027057 \t \n",
            "Epoch: 163 ------>logloss: 1.5230832681223019 ------> ------> Mse: 0.07746733934882677 \t \n",
            "Epoch: 164 ------>logloss: 1.5186316380455047 ------> ------> Mse: 0.07590097323827469 \t \n",
            "Epoch: 165 ------>logloss: 1.5158436821146728 ------> ------> Mse: 0.07463822131504885 \t \n",
            "Epoch: 166 ------>logloss: 1.7392863984387807 ------> ------> Mse: 0.08327089244168097 \t \n",
            "Epoch: 167 ------>logloss: 1.5186445721668744 ------> ------> Mse: 0.07548811946048874 \t \n",
            "Epoch: 168 ------>logloss: 1.7470095300341812 ------> ------> Mse: 0.08503810008686817 \t \n",
            "Epoch: 169 ------>logloss: 1.8117287556075716 ------> ------> Mse: 0.08805171097889238 \t \n",
            "Epoch: 170 ------>logloss: nan ------> ------> Mse: 0.11347675127217684 \t \n",
            "Epoch: 171 ------>logloss: 1.7318862209767132 ------> ------> Mse: 0.07844592414307451 \t \n",
            "Epoch: 172 ------>logloss: 1.7436813321641922 ------> ------> Mse: 0.08216781633886439 \t \n",
            "Epoch: 173 ------>logloss: 1.8096880214808846 ------> ------> Mse: 0.08573572493430727 \t \n",
            "Epoch: 174 ------>logloss: nan ------> ------> Mse: 0.12608394952742413 \t \n",
            "Epoch: 175 ------>logloss: nan ------> ------> Mse: 0.10314301860108237 \t \n",
            "Epoch: 176 ------>logloss: nan ------> ------> Mse: 0.12275810204317285 \t \n",
            "Epoch: 177 ------>logloss: 2.666691947719661 ------> ------> Mse: 0.1477594887840645 \t \n",
            "Epoch: 178 ------>logloss: 1.7168039379289393 ------> ------> Mse: 0.07708113912735635 \t \n",
            "Epoch: 179 ------>logloss: 2.3121941251789946 ------> ------> Mse: 0.11191464613678262 \t \n",
            "Epoch: 180 ------>logloss: nan ------> ------> Mse: 0.11082537549684297 \t \n",
            "Epoch: 181 ------>logloss: 1.5027028629151955 ------> ------> Mse: 0.07458236570986605 \t \n",
            "Epoch: 182 ------>logloss: 1.7401982496262358 ------> ------> Mse: 0.08386828550677661 \t \n",
            "Epoch: 183 ------>logloss: 1.508862710318496 ------> ------> Mse: 0.07595998159098485 \t \n",
            "Epoch: 184 ------>logloss: 1.750531813125737 ------> ------> Mse: 0.0863126313979055 \t \n",
            "Epoch: 185 ------>logloss: 1.7911912813757185 ------> ------> Mse: 0.0909131940923531 \t \n",
            "Epoch: 186 ------>logloss: nan ------> ------> Mse: 0.11384363354199818 \t \n",
            "Epoch: 187 ------>logloss: 1.731651660669486 ------> ------> Mse: 0.07886119304923876 \t \n",
            "Epoch: 188 ------>logloss: 1.7472540209951113 ------> ------> Mse: 0.08352426363391714 \t \n",
            "Epoch: 189 ------>logloss: 1.7903412661346958 ------> ------> Mse: 0.08833001442891736 \t \n",
            "Epoch: 190 ------>logloss: nan ------> ------> Mse: 0.12795721901638848 \t \n",
            "Epoch: 191 ------>logloss: nan ------> ------> Mse: 0.10345064800110328 \t \n",
            "Epoch: 192 ------>logloss: nan ------> ------> Mse: 0.09648267175771807 \t \n",
            "Epoch: 193 ------>logloss: 2.0906571581804854 ------> ------> Mse: 0.10216375671026315 \t \n",
            "Epoch: 194 ------>logloss: 2.1736444305949756 ------> ------> Mse: 0.11331830764310304 \t \n",
            "Epoch: 195 ------>logloss: nan ------> ------> Mse: 0.11914857921807769 \t \n",
            "Epoch: 196 ------>logloss: 2.2970434087322067 ------> ------> Mse: 0.11263604191338596 \t \n",
            "Epoch: 197 ------>logloss: nan ------> ------> Mse: 0.11159345098187526 \t \n",
            "Epoch: 198 ------>logloss: 1.491189676457376 ------> ------> Mse: 0.07456752163113732 \t \n",
            "Epoch: 199 ------>logloss: 1.4891337266687705 ------> ------> Mse: 0.07362416661312683 \t \n",
            "Epoch: 200 ------>logloss: 1.7323557815604937 ------> ------> Mse: 0.08218367108958949 \t \n",
            "Epoch: 201 ------>logloss: 1.49090543486238 ------> ------> Mse: 0.07364397884560789 \t \n",
            "Epoch: 202 ------>logloss: 1.7369804029748883 ------> ------> Mse: 0.08285631468442894 \t \n",
            "Epoch: 203 ------>logloss: 1.4990667343786104 ------> ------> Mse: 0.07514477185324615 \t \n",
            "Epoch: 204 ------>logloss: 1.748367412914778 ------> ------> Mse: 0.08544431379305219 \t \n",
            "Epoch: 205 ------>logloss: 1.7798653150552772 ------> ------> Mse: 0.09143229013078236 \t \n",
            "Epoch: 206 ------>logloss: nan ------> ------> Mse: 0.11322053448092549 \t \n",
            "Epoch: 207 ------>logloss: 1.7306321856806164 ------> ------> Mse: 0.07811570434450171 \t \n",
            "Epoch: 208 ------>logloss: 1.7467840278711175 ------> ------> Mse: 0.0828838826371128 \t \n",
            "Epoch: 209 ------>logloss: 1.7813556394068462 ------> ------> Mse: 0.08892294464082191 \t \n",
            "Epoch: 210 ------>logloss: nan ------> ------> Mse: 0.12858771935628205 \t \n",
            "Epoch: 211 ------>logloss: nan ------> ------> Mse: 0.10281572701141928 \t \n",
            "Epoch: 212 ------>logloss: nan ------> ------> Mse: 0.09430047462889748 \t \n",
            "Epoch: 213 ------>logloss: 2.177040734978611 ------> ------> Mse: 0.11335772147790647 \t \n",
            "Epoch: 214 ------>logloss: nan ------> ------> Mse: 0.11912186306585705 \t \n",
            "Epoch: 215 ------>logloss: nan ------> ------> Mse: 0.11363780693021758 \t \n",
            "Epoch: 216 ------>logloss: nan ------> ------> Mse: 0.11284882768928547 \t \n",
            "Epoch: 217 ------>logloss: 1.476039966282243 ------> ------> Mse: 0.07545456224033452 \t \n",
            "Epoch: 218 ------>logloss: 1.4738252350178636 ------> ------> Mse: 0.0745675354591676 \t \n",
            "Epoch: 219 ------>logloss: nan ------> ------> Mse: 0.10904540683838412 \t \n",
            "Epoch: 220 ------>logloss: 1.4881056150964906 ------> ------> Mse: 0.0745735781980074 \t \n",
            "Epoch: 221 ------>logloss: 1.7488271804765996 ------> ------> Mse: 0.08574670621404237 \t \n",
            "Epoch: 222 ------>logloss: 1.7724810086505047 ------> ------> Mse: 0.09313704454259263 \t \n",
            "Epoch: 223 ------>logloss: nan ------> ------> Mse: 0.11361766746949203 \t \n",
            "Epoch: 224 ------>logloss: 1.7297797203464031 ------> ------> Mse: 0.07847893208125067 \t \n",
            "Epoch: 225 ------>logloss: 1.7467751529295055 ------> ------> Mse: 0.08321693831685212 \t \n",
            "Epoch: 226 ------>logloss: 1.7738527597387181 ------> ------> Mse: 0.0906352666153461 \t \n",
            "Epoch: 227 ------>logloss: nan ------> ------> Mse: 0.129448968075395 \t \n",
            "Epoch: 228 ------>logloss: nan ------> ------> Mse: 0.10352208105242468 \t \n",
            "Epoch: 229 ------>logloss: nan ------> ------> Mse: 0.09285686061477769 \t \n",
            "Epoch: 230 ------>logloss: nan ------> ------> Mse: 0.1254528502507092 \t \n",
            "Epoch: 231 ------>logloss: nan ------> ------> Mse: 0.10919272774298124 \t \n",
            "Epoch: 232 ------>logloss: nan ------> ------> Mse: 0.12948984656378043 \t \n",
            "Epoch: 233 ------>logloss: nan ------> ------> Mse: 0.11846384740274962 \t \n",
            "Epoch: 234 ------>logloss: nan ------> ------> Mse: 0.11234100894448562 \t \n",
            "Epoch: 235 ------>logloss: 1.471264610384537 ------> ------> Mse: 0.07570349211165622 \t \n",
            "Epoch: 236 ------>logloss: 1.4661134549050572 ------> ------> Mse: 0.07461175914680626 \t \n",
            "Epoch: 237 ------>logloss: 1.4627235657566764 ------> ------> Mse: 0.07368494528750535 \t \n",
            "Epoch: 238 ------>logloss: 1.4606063811970071 ------> ------> Mse: 0.07295648662313516 \t \n",
            "Epoch: 239 ------>logloss: 1.7288636198339853 ------> ------> Mse: 0.08242257140815223 \t \n",
            "Epoch: 240 ------>logloss: 1.4627784983677206 ------> ------> Mse: 0.0723480816632501 \t \n",
            "Epoch: 241 ------>logloss: 1.7321788807656904 ------> ------> Mse: 0.08246546800879499 \t \n",
            "Epoch: 242 ------>logloss: 1.471832885930149 ------> ------> Mse: 0.0732307778617487 \t \n",
            "Epoch: 243 ------>logloss: 1.7426689177355945 ------> ------> Mse: 0.08432016175342617 \t \n",
            "Epoch: 244 ------>logloss: 1.769157098725859 ------> ------> Mse: 0.093662161684298 \t \n",
            "Epoch: 245 ------>logloss: nan ------> ------> Mse: 0.1133625613088711 \t \n",
            "Epoch: 246 ------>logloss: 1.7263697665615774 ------> ------> Mse: 0.07804440095244973 \t \n",
            "Epoch: 247 ------>logloss: 1.7411532894668464 ------> ------> Mse: 0.08195820397766646 \t \n",
            "Epoch: 248 ------>logloss: nan ------> ------> Mse: 0.09157207800764361 \t \n",
            "Epoch: 249 ------>logloss: nan ------> ------> Mse: 0.1292359568096296 \t \n",
            "Epoch: 250 ------>logloss: nan ------> ------> Mse: 0.10348414490242658 \t \n",
            "Epoch: 251 ------>logloss: nan ------> ------> Mse: 0.12443282716039103 \t \n",
            "Epoch: 252 ------>logloss: nan ------> ------> Mse: 0.09071320599359961 \t \n",
            "Epoch: 253 ------>logloss: nan ------> ------> Mse: 0.11855956514919591 \t \n",
            "Epoch: 254 ------>logloss: nan ------> ------> Mse: 0.11129796205337518 \t \n",
            "Epoch: 255 ------>logloss: 1.4554377382938726 ------> ------> Mse: 0.07507659592654713 \t \n",
            "Epoch: 256 ------>logloss: 1.4497778220577557 ------> ------> Mse: 0.0740797352911286 \t \n",
            "Epoch: 257 ------>logloss: 1.4458572963850347 ------> ------> Mse: 0.07322533599410304 \t \n",
            "Epoch: 258 ------>logloss: 1.442667246489553 ------> ------> Mse: 0.07254311675890034 \t \n",
            "Epoch: 259 ------>logloss: 1.441990881680848 ------> ------> Mse: 0.07206242229836302 \t \n",
            "Epoch: 260 ------>logloss: 1.7231250134680083 ------> ------> Mse: 0.08141629452167592 \t \n",
            "Epoch: 261 ------>logloss: 1.4452733115748693 ------> ------> Mse: 0.07165968233576979 \t \n",
            "Epoch: 262 ------>logloss: 1.7276201227218706 ------> ------> Mse: 0.08161295009666986 \t \n",
            "Epoch: 263 ------>logloss: 1.4573147569679794 ------> ------> Mse: 0.07315978471326366 \t \n",
            "Epoch: 264 ------>logloss: 1.740391300646124 ------> ------> Mse: 0.08388599909415181 \t \n",
            "Epoch: 265 ------>logloss: 2.568986159242282 ------> ------> Mse: 0.08927547225590245 \t \n",
            "Epoch: 266 ------>logloss: nan ------> ------> Mse: 0.11799359181255932 \t \n",
            "Epoch: 267 ------>logloss: 2.5699535020969755 ------> ------> Mse: 0.08998317249078558 \t \n",
            "Epoch: 268 ------>logloss: nan ------> ------> Mse: 0.12415231907308573 \t \n",
            "Epoch: 269 ------>logloss: nan ------> ------> Mse: 0.12700781290743046 \t \n",
            "Epoch: 270 ------>logloss: nan ------> ------> Mse: 0.10215841046536249 \t \n",
            "Epoch: 271 ------>logloss: nan ------> ------> Mse: 0.09295836931762275 \t \n",
            "Epoch: 272 ------>logloss: nan ------> ------> Mse: 0.11432984439794885 \t \n",
            "Epoch: 273 ------>logloss: nan ------> ------> Mse: 0.11296568833481756 \t \n",
            "Epoch: 274 ------>logloss: 1.4320560118892685 ------> ------> Mse: 0.07658522881649739 \t \n",
            "Epoch: 275 ------>logloss: nan ------> ------> Mse: 0.10884969482762749 \t \n",
            "Epoch: 276 ------>logloss: nan ------> ------> Mse: 0.07528039449352752 \t \n",
            "Epoch: 277 ------>logloss: nan ------> ------> Mse: 0.0742181571264843 \t \n",
            "Epoch: 278 ------>logloss: nan ------> ------> Mse: 0.0733516987668176 \t \n",
            "Epoch: 279 ------>logloss: 1.4382872123938433 ------> ------> Mse: 0.07270643793112955 \t \n",
            "Epoch: 280 ------>logloss: 1.7315905655801584 ------> ------> Mse: 0.08336417591504398 \t \n",
            "Epoch: 281 ------>logloss: 2.577592199886897 ------> ------> Mse: 0.09008875144475981 \t \n",
            "Epoch: 282 ------>logloss: nan ------> ------> Mse: 0.11731342110140734 \t \n",
            "Epoch: 283 ------>logloss: 2.578195272759515 ------> ------> Mse: 0.09073944853140418 \t \n",
            "Epoch: 284 ------>logloss: nan ------> ------> Mse: 0.11747155671322976 \t \n",
            "Epoch: 285 ------>logloss: 2.5795350520639304 ------> ------> Mse: 0.09135398812994047 \t \n",
            "Epoch: 286 ------>logloss: nan ------> ------> Mse: 0.12470401464848514 \t \n",
            "Epoch: 287 ------>logloss: nan ------> ------> Mse: 0.12578246467694496 \t \n",
            "Epoch: 288 ------>logloss: nan ------> ------> Mse: 0.091500369719431 \t \n",
            "Epoch: 289 ------>logloss: nan ------> ------> Mse: 0.12534790057999057 \t \n",
            "Epoch: 290 ------>logloss: nan ------> ------> Mse: 0.11580863068532833 \t \n",
            "Epoch: 291 ------>logloss: nan ------> ------> Mse: 0.10997123923268069 \t \n",
            "Epoch: 292 ------>logloss: nan ------> ------> Mse: 0.07523640708407911 \t \n",
            "Epoch: 293 ------>logloss: nan ------> ------> Mse: 0.07450801121387252 \t \n",
            "Epoch: 294 ------>logloss: nan ------> ------> Mse: 0.07390685976981495 \t \n",
            "Epoch: 295 ------>logloss: 1.420326290244733 ------> ------> Mse: 0.07345787206881808 \t \n",
            "Epoch: 296 ------>logloss: nan ------> ------> Mse: 0.1301880611327491 \t \n",
            "Epoch: 297 ------>logloss: nan ------> ------> Mse: 0.11157916090214318 \t \n",
            "Epoch: 298 ------>logloss: 2.653437989487106 ------> ------> Mse: 0.09353491318346785 \t \n",
            "Epoch: 299 ------>logloss: nan ------> ------> Mse: 0.11179977341669924 \t \n",
            "Epoch: 300 ------>logloss: 2.654152594593782 ------> ------> Mse: 0.0947488313815607 \t \n",
            "Epoch: 301 ------>logloss: nan ------> ------> Mse: 0.11196290101749354 \t \n",
            "Epoch: 302 ------>logloss: 2.6565979597034812 ------> ------> Mse: 0.09622757658381263 \t \n",
            "Epoch: 303 ------>logloss: nan ------> ------> Mse: 0.11222422011250538 \t \n",
            "Epoch: 304 ------>logloss: 2.7113663423830396 ------> ------> Mse: 0.10177788440439864 \t \n",
            "Epoch: 305 ------>logloss: nan ------> ------> Mse: 0.09166107667541588 \t \n",
            "Epoch: 306 ------>logloss: nan ------> ------> Mse: 0.12017957017983613 \t \n",
            "Epoch: 307 ------>logloss: nan ------> ------> Mse: 0.11184577821040398 \t \n",
            "Epoch: 308 ------>logloss: nan ------> ------> Mse: 0.11087180991256508 \t \n",
            "Epoch: 309 ------>logloss: nan ------> ------> Mse: 0.10861845460327457 \t \n",
            "Epoch: 310 ------>logloss: 2.2776993232281124 ------> ------> Mse: 0.08783289903884567 \t \n",
            "Epoch: 311 ------>logloss: nan ------> ------> Mse: 0.10690168085010862 \t \n",
            "Epoch: 312 ------>logloss: nan ------> ------> Mse: 0.13083066291150527 \t \n",
            "Epoch: 313 ------>logloss: nan ------> ------> Mse: 0.11118823786521258 \t \n",
            "Epoch: 314 ------>logloss: 2.662936048479927 ------> ------> Mse: 0.09457414740541609 \t \n",
            "Epoch: 315 ------>logloss: nan ------> ------> Mse: 0.11159323451195635 \t \n",
            "Epoch: 316 ------>logloss: 2.663977864204701 ------> ------> Mse: 0.09579306023157108 \t \n",
            "Epoch: 317 ------>logloss: nan ------> ------> Mse: 0.11193568716252779 \t \n",
            "Epoch: 318 ------>logloss: 2.666682797609132 ------> ------> Mse: 0.09720301526839029 \t \n",
            "Epoch: 319 ------>logloss: nan ------> ------> Mse: 0.11236154036042337 \t \n",
            "Epoch: 320 ------>logloss: 2.712488441867837 ------> ------> Mse: 0.10226737918354917 \t \n",
            "Epoch: 321 ------>logloss: nan ------> ------> Mse: 0.0912752479669133 \t \n",
            "Epoch: 322 ------>logloss: nan ------> ------> Mse: 0.11357883500577126 \t \n",
            "Epoch: 323 ------>logloss: nan ------> ------> Mse: 0.08932671744893388 \t \n",
            "Epoch: 324 ------>logloss: nan ------> ------> Mse: 0.07415637210241617 \t \n",
            "Epoch: 325 ------>logloss: nan ------> ------> Mse: 0.10738811074356269 \t \n",
            "Epoch: 326 ------>logloss: nan ------> ------> Mse: 0.10840931514376817 \t \n",
            "Epoch: 327 ------>logloss: nan ------> ------> Mse: 0.10656951085794224 \t \n",
            "Epoch: 328 ------>logloss: 2.5988311691719996 ------> ------> Mse: 0.09442560383427631 \t \n",
            "Epoch: 329 ------>logloss: nan ------> ------> Mse: 0.10575445394357139 \t \n",
            "Epoch: 330 ------>logloss: 2.603176445688693 ------> ------> Mse: 0.08985865315107823 \t \n",
            "Epoch: 331 ------>logloss: nan ------> ------> Mse: 0.11616915728603103 \t \n",
            "Epoch: 332 ------>logloss: 2.6030638246280042 ------> ------> Mse: 0.09047661579861731 \t \n",
            "Epoch: 333 ------>logloss: nan ------> ------> Mse: 0.11622672041020828 \t \n",
            "Epoch: 334 ------>logloss: 2.6036354620669937 ------> ------> Mse: 0.09106836653640284 \t \n",
            "Epoch: 335 ------>logloss: nan ------> ------> Mse: 0.11630278159287148 \t \n",
            "Epoch: 336 ------>logloss: 2.60481607363225 ------> ------> Mse: 0.09157800450238834 \t \n",
            "Epoch: 337 ------>logloss: nan ------> ------> Mse: 0.11650925002295107 \t \n",
            "Epoch: 338 ------>logloss: 2.6064345807283513 ------> ------> Mse: 0.09197534187787075 \t \n",
            "Epoch: 339 ------>logloss: nan ------> ------> Mse: 0.11696909705736071 \t \n",
            "Epoch: 340 ------>logloss: 2.6089344704938537 ------> ------> Mse: 0.09225486847456242 \t \n",
            "Epoch: 341 ------>logloss: nan ------> ------> Mse: 0.11778980769817984 \t \n",
            "Epoch: 342 ------>logloss: 2.611034338517089 ------> ------> Mse: 0.0924302027723286 \t \n",
            "Epoch: 343 ------>logloss: 2.664164355596179 ------> ------> Mse: 0.09243526594543565 \t \n",
            "Epoch: 344 ------>logloss: nan ------> ------> Mse: 0.11038447414704673 \t \n",
            "Epoch: 345 ------>logloss: 2.663395122459596 ------> ------> Mse: 0.09329803943770712 \t \n",
            "Epoch: 346 ------>logloss: nan ------> ------> Mse: 0.1108739289981583 \t \n",
            "Epoch: 347 ------>logloss: 2.6642253837110252 ------> ------> Mse: 0.09445237177348642 \t \n",
            "Epoch: 348 ------>logloss: nan ------> ------> Mse: 0.1274325706224599 \t \n",
            "Epoch: 349 ------>logloss: nan ------> ------> Mse: 0.10408710373398272 \t \n",
            "Epoch: 350 ------>logloss: nan ------> ------> Mse: 0.12331739113347157 \t \n",
            "Epoch: 351 ------>logloss: nan ------> ------> Mse: 0.10211461970199921 \t \n",
            "Epoch: 352 ------>logloss: nan ------> ------> Mse: 0.10503444781875074 \t \n",
            "Epoch: 353 ------>logloss: nan ------> ------> Mse: 0.10722052552781441 \t \n",
            "Epoch: 354 ------>logloss: nan ------> ------> Mse: 0.1063287671240975 \t \n",
            "Epoch: 355 ------>logloss: 2.6032011275262317 ------> ------> Mse: 0.09267073306319049 \t \n",
            "Epoch: 356 ------>logloss: nan ------> ------> Mse: 0.1055886940193189 \t \n",
            "Epoch: 357 ------>logloss: 2.6098531840517594 ------> ------> Mse: 0.08834491416315171 \t \n",
            "Epoch: 358 ------>logloss: nan ------> ------> Mse: 0.114523525726533 \t \n",
            "Epoch: 359 ------>logloss: 2.6089637822947824 ------> ------> Mse: 0.08892968270020254 \t \n",
            "Epoch: 360 ------>logloss: nan ------> ------> Mse: 0.11477578878640633 \t \n",
            "Epoch: 361 ------>logloss: 2.609042792464124 ------> ------> Mse: 0.08956461419204476 \t \n",
            "Epoch: 362 ------>logloss: nan ------> ------> Mse: 0.11495791298176963 \t \n",
            "Epoch: 363 ------>logloss: 2.609544073009988 ------> ------> Mse: 0.0901757631503729 \t \n",
            "Epoch: 364 ------>logloss: nan ------> ------> Mse: 0.11513343533829379 \t \n",
            "Epoch: 365 ------>logloss: 2.610800728663745 ------> ------> Mse: 0.09070745723119182 \t \n",
            "Epoch: 366 ------>logloss: nan ------> ------> Mse: 0.11540195835546072 \t \n",
            "Epoch: 367 ------>logloss: 2.613083510221426 ------> ------> Mse: 0.09112954191174565 \t \n",
            "Epoch: 368 ------>logloss: nan ------> ------> Mse: 0.11588078388789981 \t \n",
            "Epoch: 369 ------>logloss: 2.615174092828037 ------> ------> Mse: 0.0914359527144148 \t \n",
            "Epoch: 370 ------>logloss: nan ------> ------> Mse: 0.11667908233909012 \t \n",
            "Epoch: 371 ------>logloss: nan ------> ------> Mse: 0.10643923146264618 \t \n",
            "Epoch: 372 ------>logloss: nan ------> ------> Mse: 0.09239801167819695 \t \n",
            "Epoch: 373 ------>logloss: nan ------> ------> Mse: 0.12309360635776463 \t \n",
            "Epoch: 374 ------>logloss: nan ------> ------> Mse: 0.11951782499681289 \t \n",
            "Epoch: 375 ------>logloss: nan ------> ------> Mse: 0.10744089927140467 \t \n",
            "Epoch: 376 ------>logloss: nan ------> ------> Mse: 0.1087061948744043 \t \n",
            "Epoch: 377 ------>logloss: nan ------> ------> Mse: 0.09626579098171013 \t \n",
            "Epoch: 378 ------>logloss: nan ------> ------> Mse: 0.07932913314560817 \t \n",
            "Epoch: 379 ------>logloss: nan ------> ------> Mse: 0.09038711851778605 \t \n",
            "Epoch: 380 ------>logloss: 2.6038229948398275 ------> ------> Mse: 0.09611587885594534 \t \n",
            "Epoch: 381 ------>logloss: nan ------> ------> Mse: 0.10574471818458774 \t \n",
            "Epoch: 382 ------>logloss: 2.6053997998792116 ------> ------> Mse: 0.09135231310876589 \t \n",
            "Epoch: 383 ------>logloss: nan ------> ------> Mse: 0.11759434929772557 \t \n",
            "Epoch: 384 ------>logloss: 2.6048789896940647 ------> ------> Mse: 0.09195815657821943 \t \n",
            "Epoch: 385 ------>logloss: nan ------> ------> Mse: 0.11764298501442877 \t \n",
            "Epoch: 386 ------>logloss: 2.6050990141103383 ------> ------> Mse: 0.0925299294056905 \t \n",
            "Epoch: 387 ------>logloss: nan ------> ------> Mse: 0.11770517475258829 \t \n",
            "Epoch: 388 ------>logloss: 2.6060001532811055 ------> ------> Mse: 0.09301177894624411 \t \n",
            "Epoch: 389 ------>logloss: nan ------> ------> Mse: 0.11789439249766465 \t \n",
            "Epoch: 390 ------>logloss: nan ------> ------> Mse: 0.09337355563213948 \t \n",
            "Epoch: 391 ------>logloss: nan ------> ------> Mse: 0.11833912833633523 \t \n",
            "Epoch: 392 ------>logloss: nan ------> ------> Mse: 0.09360976239471878 \t \n",
            "Epoch: 393 ------>logloss: nan ------> ------> Mse: 0.11915605845303151 \t \n",
            "Epoch: 394 ------>logloss: nan ------> ------> Mse: 0.09373399132725654 \t \n",
            "Epoch: 395 ------>logloss: 2.667974138054045 ------> ------> Mse: 0.09392017728948654 \t \n",
            "Epoch: 396 ------>logloss: nan ------> ------> Mse: 0.11143941133575502 \t \n",
            "Epoch: 397 ------>logloss: 2.667102035414828 ------> ------> Mse: 0.09482946544630261 \t \n",
            "Epoch: 398 ------>logloss: nan ------> ------> Mse: 0.11188983374656947 \t \n",
            "Epoch: 399 ------>logloss: 2.6678914141251724 ------> ------> Mse: 0.09602402902860027 \t \n",
            "Epoch: 400 ------>logloss: nan ------> ------> Mse: 0.11224533018605201 \t \n",
            "Epoch: 401 ------>logloss: 2.670578844941715 ------> ------> Mse: 0.09742792596373683 \t \n",
            "Epoch: 402 ------>logloss: nan ------> ------> Mse: 0.11263353734575655 \t \n",
            "Epoch: 403 ------>logloss: 2.705690077403631 ------> ------> Mse: 0.10178168946200818 \t \n",
            "Epoch: 404 ------>logloss: nan ------> ------> Mse: 0.09104401863790594 \t \n",
            "Epoch: 405 ------>logloss: nan ------> ------> Mse: 0.11864084631210076 \t \n",
            "Epoch: 406 ------>logloss: nan ------> ------> Mse: 0.10693639324458629 \t \n",
            "Epoch: 407 ------>logloss: nan ------> ------> Mse: 0.10860612713286842 \t \n",
            "Epoch: 408 ------>logloss: nan ------> ------> Mse: 0.09543885138965573 \t \n",
            "Epoch: 409 ------>logloss: nan ------> ------> Mse: 0.09007824979791351 \t \n",
            "Epoch: 410 ------>logloss: 2.6023260306333893 ------> ------> Mse: 0.0951376375899972 \t \n",
            "Epoch: 411 ------>logloss: nan ------> ------> Mse: 0.10551114823946103 \t \n",
            "Epoch: 412 ------>logloss: 2.604935072957026 ------> ------> Mse: 0.09042410278088173 \t \n",
            "Epoch: 413 ------>logloss: nan ------> ------> Mse: 0.1171280448832673 \t \n",
            "Epoch: 414 ------>logloss: 2.6044725290356423 ------> ------> Mse: 0.09103873578367148 \t \n",
            "Epoch: 415 ------>logloss: nan ------> ------> Mse: 0.11715272256443104 \t \n",
            "Epoch: 416 ------>logloss: 2.6046428658135636 ------> ------> Mse: 0.0916505200276366 \t \n",
            "Epoch: 417 ------>logloss: nan ------> ------> Mse: 0.11717814768430082 \t \n",
            "Epoch: 418 ------>logloss: 2.6057752615912864 ------> ------> Mse: 0.09219465891019747 \t \n",
            "Epoch: 419 ------>logloss: nan ------> ------> Mse: 0.11731883432329392 \t \n",
            "Epoch: 420 ------>logloss: nan ------> ------> Mse: 0.09263006504872619 \t \n",
            "Epoch: 421 ------>logloss: nan ------> ------> Mse: 0.11771036835955066 \t \n",
            "Epoch: 422 ------>logloss: nan ------> ------> Mse: 0.09294189484412647 \t \n",
            "Epoch: 423 ------>logloss: nan ------> ------> Mse: 0.11848433462834296 \t \n",
            "Epoch: 424 ------>logloss: nan ------> ------> Mse: 0.09313759285870743 \t \n",
            "Epoch: 425 ------>logloss: nan ------> ------> Mse: 0.11973632046727598 \t \n",
            "Epoch: 426 ------>logloss: nan ------> ------> Mse: 0.09324114680119623 \t \n",
            "Epoch: 427 ------>logloss: 2.6655685377145373 ------> ------> Mse: 0.09357275428897027 \t \n",
            "Epoch: 428 ------>logloss: nan ------> ------> Mse: 0.11143749286221377 \t \n",
            "Epoch: 429 ------>logloss: 2.6659222813631467 ------> ------> Mse: 0.09470186982201029 \t \n",
            "Epoch: 430 ------>logloss: nan ------> ------> Mse: 0.11179580725197329 \t \n",
            "Epoch: 431 ------>logloss: 2.667860111221191 ------> ------> Mse: 0.09608725496963076 \t \n",
            "Epoch: 432 ------>logloss: nan ------> ------> Mse: 0.11215192748238668 \t \n",
            "Epoch: 433 ------>logloss: 2.7069597027563974 ------> ------> Mse: 0.10089022274707173 \t \n",
            "Epoch: 434 ------>logloss: nan ------> ------> Mse: 0.09072612682763147 \t \n",
            "Epoch: 435 ------>logloss: nan ------> ------> Mse: 0.1182009679159193 \t \n",
            "Epoch: 436 ------>logloss: nan ------> ------> Mse: 0.10650900055300015 \t \n",
            "Epoch: 437 ------>logloss: nan ------> ------> Mse: 0.1083945106729971 \t \n",
            "Epoch: 438 ------>logloss: nan ------> ------> Mse: 0.10613417067503121 \t \n",
            "Epoch: 439 ------>logloss: 2.6029329121862155 ------> ------> Mse: 0.09520267451809929 \t \n",
            "Epoch: 440 ------>logloss: nan ------> ------> Mse: 0.10516566067509593 \t \n",
            "Epoch: 441 ------>logloss: 2.6056654318265857 ------> ------> Mse: 0.09050466741182672 \t \n",
            "Epoch: 442 ------>logloss: nan ------> ------> Mse: 0.11708385409965155 \t \n",
            "Epoch: 443 ------>logloss: 2.6053667217810363 ------> ------> Mse: 0.09112929598051779 \t \n",
            "Epoch: 444 ------>logloss: nan ------> ------> Mse: 0.11710431586330003 \t \n",
            "Epoch: 445 ------>logloss: 2.605535039228483 ------> ------> Mse: 0.0917345256158911 \t \n",
            "Epoch: 446 ------>logloss: nan ------> ------> Mse: 0.11715418546246048 \t \n",
            "Epoch: 447 ------>logloss: nan ------> ------> Mse: 0.0922602174576651 \t \n",
            "Epoch: 448 ------>logloss: nan ------> ------> Mse: 0.11735763679823269 \t \n",
            "Epoch: 449 ------>logloss: nan ------> ------> Mse: 0.09267130189692051 \t \n",
            "Epoch: 450 ------>logloss: nan ------> ------> Mse: 0.1178557397927105 \t \n",
            "Epoch: 451 ------>logloss: nan ------> ------> Mse: 0.0929585379474864 \t \n",
            "Epoch: 452 ------>logloss: nan ------> ------> Mse: 0.11877849870484872 \t \n",
            "Epoch: 453 ------>logloss: nan ------> ------> Mse: 0.09313383204378771 \t \n",
            "Epoch: 454 ------>logloss: 2.6667692093269553 ------> ------> Mse: 0.09294996741573021 \t \n",
            "Epoch: 455 ------>logloss: nan ------> ------> Mse: 0.11117767800076198 \t \n",
            "Epoch: 456 ------>logloss: 2.666084544824656 ------> ------> Mse: 0.09388270589706033 \t \n",
            "Epoch: 457 ------>logloss: nan ------> ------> Mse: 0.11160161456278407 \t \n",
            "Epoch: 458 ------>logloss: 2.66722032247619 ------> ------> Mse: 0.09512482396111414 \t \n",
            "Epoch: 459 ------>logloss: nan ------> ------> Mse: 0.11194338810048629 \t \n",
            "Epoch: 460 ------>logloss: 2.6698145783313127 ------> ------> Mse: 0.0965951269705819 \t \n",
            "Epoch: 461 ------>logloss: nan ------> ------> Mse: 0.11234768419315516 \t \n",
            "Epoch: 462 ------>logloss: 2.705386715260667 ------> ------> Mse: 0.10135496847936591 \t \n",
            "Epoch: 463 ------>logloss: nan ------> ------> Mse: 0.09048657058571649 \t \n",
            "Epoch: 464 ------>logloss: nan ------> ------> Mse: 0.11871024773273789 \t \n",
            "Epoch: 465 ------>logloss: nan ------> ------> Mse: 0.10657213855707139 \t \n",
            "Epoch: 466 ------>logloss: nan ------> ------> Mse: 0.10813436517849631 \t \n",
            "Epoch: 467 ------>logloss: nan ------> ------> Mse: 0.0948122543813538 \t \n",
            "Epoch: 468 ------>logloss: nan ------> ------> Mse: 0.08949155927184843 \t \n",
            "Epoch: 469 ------>logloss: 2.6019998855133175 ------> ------> Mse: 0.09423341082074763 \t \n",
            "Epoch: 470 ------>logloss: nan ------> ------> Mse: 0.10495825950467713 \t \n",
            "Epoch: 471 ------>logloss: 2.6052550427534538 ------> ------> Mse: 0.08960000782008518 \t \n",
            "Epoch: 472 ------>logloss: nan ------> ------> Mse: 0.11664027122642164 \t \n",
            "Epoch: 473 ------>logloss: 2.6050202280765404 ------> ------> Mse: 0.09022630448632041 \t \n",
            "Epoch: 474 ------>logloss: nan ------> ------> Mse: 0.11664543043828592 \t \n",
            "Epoch: 475 ------>logloss: 2.6051460197959595 ------> ------> Mse: 0.090865900337565 \t \n",
            "Epoch: 476 ------>logloss: nan ------> ------> Mse: 0.11667083030417517 \t \n",
            "Epoch: 477 ------>logloss: nan ------> ------> Mse: 0.09145077380538598 \t \n",
            "Epoch: 478 ------>logloss: nan ------> ------> Mse: 0.1168421265953068 \t \n",
            "Epoch: 479 ------>logloss: nan ------> ------> Mse: 0.09193501901236016 \t \n",
            "Epoch: 480 ------>logloss: nan ------> ------> Mse: 0.11730707480014346 \t \n",
            "Epoch: 481 ------>logloss: nan ------> ------> Mse: 0.09229955156652778 \t \n",
            "Epoch: 482 ------>logloss: nan ------> ------> Mse: 0.1182088006732139 \t \n",
            "Epoch: 483 ------>logloss: nan ------> ------> Mse: 0.0925495147593651 \t \n",
            "Epoch: 484 ------>logloss: nan ------> ------> Mse: 0.11964893708964006 \t \n",
            "Epoch: 485 ------>logloss: nan ------> ------> Mse: 0.09270908479010943 \t \n",
            "Epoch: 486 ------>logloss: 2.6647194192558668 ------> ------> Mse: 0.09262644656168233 \t \n",
            "Epoch: 487 ------>logloss: nan ------> ------> Mse: 0.1111878509941919 \t \n",
            "Epoch: 488 ------>logloss: 2.665172580989601 ------> ------> Mse: 0.09379160664137556 \t \n",
            "Epoch: 489 ------>logloss: nan ------> ------> Mse: 0.11153886911072107 \t \n",
            "Epoch: 490 ------>logloss: 2.6675134375565106 ------> ------> Mse: 0.09523516554828139 \t \n",
            "Epoch: 491 ------>logloss: nan ------> ------> Mse: 0.1264109535106959 \t \n",
            "Epoch: 492 ------>logloss: nan ------> ------> Mse: 0.10315821965405403 \t \n",
            "Epoch: 493 ------>logloss: nan ------> ------> Mse: 0.12366983544928581 \t \n",
            "Epoch: 494 ------>logloss: nan ------> ------> Mse: 0.0992600802946833 \t \n",
            "Epoch: 495 ------>logloss: nan ------> ------> Mse: 0.0895445075307255 \t \n",
            "Epoch: 496 ------>logloss: nan ------> ------> Mse: 0.1065241839814152 \t \n",
            "Epoch: 497 ------>logloss: nan ------> ------> Mse: 0.10757098885792994 \t \n",
            "Epoch: 498 ------>logloss: nan ------> ------> Mse: 0.09444662823218652 \t \n",
            "Epoch: 499 ------>logloss: nan ------> ------> Mse: 0.07792131266987143 \t \n",
            "Epoch: 500 ------>logloss: nan ------> ------> Mse: 0.08890381874909345 \t \n",
            "Epoch: 501 ------>logloss: nan ------> ------> Mse: 0.09288328344548484 \t \n",
            "Epoch: 502 ------>logloss: nan ------> ------> Mse: 0.10461100848391187 \t \n",
            "Epoch: 503 ------>logloss: 2.6057561845979653 ------> ------> Mse: 0.08839200890937308 \t \n",
            "Epoch: 504 ------>logloss: nan ------> ------> Mse: 0.11590538244984482 \t \n",
            "Epoch: 505 ------>logloss: 2.6052148248715827 ------> ------> Mse: 0.08901496801474955 \t \n",
            "Epoch: 506 ------>logloss: nan ------> ------> Mse: 0.11591138526986973 \t \n",
            "Epoch: 507 ------>logloss: 2.6055350732959552 ------> ------> Mse: 0.08968512969975069 \t \n",
            "Epoch: 508 ------>logloss: nan ------> ------> Mse: 0.1159392806392462 \t \n",
            "Epoch: 509 ------>logloss: nan ------> ------> Mse: 0.09032956814557468 \t \n",
            "Epoch: 510 ------>logloss: nan ------> ------> Mse: 0.11611809339014131 \t \n",
            "Epoch: 511 ------>logloss: nan ------> ------> Mse: 0.09089282677753276 \t \n",
            "Epoch: 512 ------>logloss: nan ------> ------> Mse: 0.11660160561268312 \t \n",
            "Epoch: 513 ------>logloss: nan ------> ------> Mse: 0.09134586081252856 \t \n",
            "Epoch: 514 ------>logloss: nan ------> ------> Mse: 0.11754189212678025 \t \n",
            "Epoch: 515 ------>logloss: nan ------> ------> Mse: 0.09168637532840612 \t \n",
            "Epoch: 516 ------>logloss: nan ------> ------> Mse: 0.11904979884738827 \t \n",
            "Epoch: 517 ------>logloss: nan ------> ------> Mse: 0.09193471802073745 \t \n",
            "Epoch: 518 ------>logloss: 2.6635231600499916 ------> ------> Mse: 0.09122662016585023 \t \n",
            "Epoch: 519 ------>logloss: nan ------> ------> Mse: 0.12572671167485747 \t \n",
            "Epoch: 520 ------>logloss: nan ------> ------> Mse: 0.10314324619164472 \t \n",
            "Epoch: 521 ------>logloss: nan ------> ------> Mse: 0.12087146757758015 \t \n",
            "Epoch: 522 ------>logloss: nan ------> ------> Mse: 0.10155863576479944 \t \n",
            "Epoch: 523 ------>logloss: nan ------> ------> Mse: 0.07513823008751791 \t \n",
            "Epoch: 524 ------>logloss: nan ------> ------> Mse: 0.10716235320481239 \t \n",
            "Epoch: 525 ------>logloss: nan ------> ------> Mse: 0.10943157452713541 \t \n",
            "Epoch: 526 ------>logloss: nan ------> ------> Mse: 0.0957346335975345 \t \n",
            "Epoch: 527 ------>logloss: nan ------> ------> Mse: 0.07977855399958823 \t \n",
            "Epoch: 528 ------>logloss: nan ------> ------> Mse: 0.09076036299274595 \t \n",
            "Epoch: 529 ------>logloss: nan ------> ------> Mse: 0.0848833273340289 \t \n",
            "Epoch: 530 ------>logloss: nan ------> ------> Mse: 0.10564091706519106 \t \n",
            "Epoch: 531 ------>logloss: nan ------> ------> Mse: 0.10384918298021396 \t \n",
            "Epoch: 532 ------>logloss: nan ------> ------> Mse: 0.09151714957532213 \t \n",
            "Epoch: 533 ------>logloss: nan ------> ------> Mse: 0.11719926182999627 \t \n",
            "Epoch: 534 ------>logloss: nan ------> ------> Mse: 0.09205751051556682 \t \n",
            "Epoch: 535 ------>logloss: nan ------> ------> Mse: 0.11755846556002945 \t \n",
            "Epoch: 536 ------>logloss: nan ------> ------> Mse: 0.092484190889496 \t \n",
            "Epoch: 537 ------>logloss: nan ------> ------> Mse: 0.11832507460821086 \t \n",
            "Epoch: 538 ------>logloss: nan ------> ------> Mse: 0.09278998595501603 \t \n",
            "Epoch: 539 ------>logloss: nan ------> ------> Mse: 0.1196290573750474 \t \n",
            "Epoch: 540 ------>logloss: nan ------> ------> Mse: 0.09299052617044128 \t \n",
            "Epoch: 541 ------>logloss: 2.6664699872622175 ------> ------> Mse: 0.09261156096749086 \t \n",
            "Epoch: 542 ------>logloss: nan ------> ------> Mse: 0.1114293904089408 \t \n",
            "Epoch: 543 ------>logloss: 2.666376962770057 ------> ------> Mse: 0.09366006504893844 \t \n",
            "Epoch: 544 ------>logloss: nan ------> ------> Mse: 0.11179618483941334 \t \n",
            "Epoch: 545 ------>logloss: 2.668229030075474 ------> ------> Mse: 0.09502992878879331 \t \n",
            "Epoch: 546 ------>logloss: nan ------> ------> Mse: 0.11214768711005224 \t \n",
            "Epoch: 547 ------>logloss: nan ------> ------> Mse: 0.09662446330435838 \t \n",
            "Epoch: 548 ------>logloss: nan ------> ------> Mse: 0.11267366912341084 \t \n",
            "Epoch: 549 ------>logloss: nan ------> ------> Mse: 0.10132206728355043 \t \n",
            "Epoch: 550 ------>logloss: nan ------> ------> Mse: 0.09016663998515168 \t \n",
            "Epoch: 551 ------>logloss: nan ------> ------> Mse: 0.11937082943112316 \t \n",
            "Epoch: 552 ------>logloss: nan ------> ------> Mse: 0.10619751177924056 \t \n",
            "Epoch: 553 ------>logloss: nan ------> ------> Mse: 0.1075846401288381 \t \n",
            "Epoch: 554 ------>logloss: nan ------> ------> Mse: 0.09430375822504189 \t \n",
            "Epoch: 555 ------>logloss: nan ------> ------> Mse: 0.07793784943250472 \t \n",
            "Epoch: 556 ------>logloss: nan ------> ------> Mse: 0.08888194337181259 \t \n",
            "Epoch: 557 ------>logloss: nan ------> ------> Mse: 0.09276318843232373 \t \n",
            "Epoch: 558 ------>logloss: nan ------> ------> Mse: 0.10444560197691138 \t \n",
            "Epoch: 559 ------>logloss: 2.6059454141267775 ------> ------> Mse: 0.08827517946486256 \t \n",
            "Epoch: 560 ------>logloss: nan ------> ------> Mse: 0.11621066170113452 \t \n",
            "Epoch: 561 ------>logloss: nan ------> ------> Mse: 0.08886620145942732 \t \n",
            "Epoch: 562 ------>logloss: nan ------> ------> Mse: 0.11621356524297763 \t \n",
            "Epoch: 563 ------>logloss: nan ------> ------> Mse: 0.08953148381723197 \t \n",
            "Epoch: 564 ------>logloss: nan ------> ------> Mse: 0.11625309752078782 \t \n",
            "Epoch: 565 ------>logloss: nan ------> ------> Mse: 0.09019648905301571 \t \n",
            "Epoch: 566 ------>logloss: nan ------> ------> Mse: 0.11646516381299925 \t \n",
            "Epoch: 567 ------>logloss: nan ------> ------> Mse: 0.09079859025888043 \t \n",
            "Epoch: 568 ------>logloss: nan ------> ------> Mse: 0.11701017562136627 \t \n",
            "Epoch: 569 ------>logloss: nan ------> ------> Mse: 0.09129996642200336 \t \n",
            "Epoch: 570 ------>logloss: nan ------> ------> Mse: 0.11804393980618517 \t \n",
            "Epoch: 571 ------>logloss: nan ------> ------> Mse: 0.09169140241661537 \t \n",
            "Epoch: 572 ------>logloss: nan ------> ------> Mse: 0.11967399389860485 \t \n",
            "Epoch: 573 ------>logloss: nan ------> ------> Mse: 0.09199003320181122 \t \n",
            "Epoch: 574 ------>logloss: nan ------> ------> Mse: 0.1255982961527145 \t \n",
            "Epoch: 575 ------>logloss: nan ------> ------> Mse: 0.12302294256623611 \t \n",
            "Epoch: 576 ------>logloss: nan ------> ------> Mse: 0.09666036378628008 \t \n",
            "Epoch: 577 ------>logloss: nan ------> ------> Mse: 0.1283793127814921 \t \n",
            "Epoch: 578 ------>logloss: nan ------> ------> Mse: 0.09441487960258173 \t \n",
            "Epoch: 579 ------>logloss: nan ------> ------> Mse: 0.08909177222023258 \t \n",
            "Epoch: 580 ------>logloss: nan ------> ------> Mse: 0.09289467790947516 \t \n",
            "Epoch: 581 ------>logloss: nan ------> ------> Mse: 0.10491302163144361 \t \n",
            "Epoch: 582 ------>logloss: nan ------> ------> Mse: 0.1302531993329632 \t \n",
            "Epoch: 583 ------>logloss: nan ------> ------> Mse: 0.11194615744553799 \t \n",
            "Epoch: 584 ------>logloss: nan ------> ------> Mse: 0.09512958868114282 \t \n",
            "Epoch: 585 ------>logloss: nan ------> ------> Mse: 0.11238088941172679 \t \n",
            "Epoch: 586 ------>logloss: nan ------> ------> Mse: 0.09652627951029784 \t \n",
            "Epoch: 587 ------>logloss: nan ------> ------> Mse: 0.11281108880312031 \t \n",
            "Epoch: 588 ------>logloss: nan ------> ------> Mse: 0.09995623846370846 \t \n",
            "Epoch: 589 ------>logloss: nan ------> ------> Mse: 0.09036113928577708 \t \n",
            "Epoch: 590 ------>logloss: nan ------> ------> Mse: 0.08244914359495796 \t \n",
            "Epoch: 591 ------>logloss: nan ------> ------> Mse: 0.08267360227515777 \t \n",
            "Epoch: 592 ------>logloss: nan ------> ------> Mse: 0.08290758406839127 \t \n",
            "Epoch: 593 ------>logloss: nan ------> ------> Mse: 0.08315465982441547 \t \n",
            "Epoch: 594 ------>logloss: nan ------> ------> Mse: 0.10732746172130736 \t \n",
            "Epoch: 595 ------>logloss: nan ------> ------> Mse: 0.08889387148121818 \t \n",
            "Epoch: 596 ------>logloss: nan ------> ------> Mse: 0.07278817593456222 \t \n",
            "Epoch: 597 ------>logloss: nan ------> ------> Mse: 0.07656743580569028 \t \n",
            "Epoch: 598 ------>logloss: nan ------> ------> Mse: 0.12036621673821558 \t \n",
            "Epoch: 599 ------>logloss: nan ------> ------> Mse: 0.10533219841317706 \t \n",
            "Epoch: 600 ------>logloss: nan ------> ------> Mse: 0.08937370904982547 \t \n",
            "Epoch: 601 ------>logloss: nan ------> ------> Mse: 0.07139348192224101 \t \n",
            "Epoch: 602 ------>logloss: nan ------> ------> Mse: 0.07440946065977158 \t \n",
            "Epoch: 603 ------>logloss: nan ------> ------> Mse: 0.10560386652032867 \t \n",
            "Epoch: 604 ------>logloss: nan ------> ------> Mse: 0.10950383288388592 \t \n",
            "Epoch: 605 ------>logloss: nan ------> ------> Mse: 0.09510420794216794 \t \n",
            "Epoch: 606 ------>logloss: nan ------> ------> Mse: 0.07899879599942206 \t \n",
            "Epoch: 607 ------>logloss: nan ------> ------> Mse: 0.08991087946353615 \t \n",
            "Epoch: 608 ------>logloss: nan ------> ------> Mse: 0.071236552967304 \t \n",
            "Epoch: 609 ------>logloss: nan ------> ------> Mse: 0.0706454336543021 \t \n",
            "Epoch: 610 ------>logloss: nan ------> ------> Mse: 0.07027138927524974 \t \n",
            "Epoch: 611 ------>logloss: nan ------> ------> Mse: 0.07013566802226116 \t \n",
            "Epoch: 612 ------>logloss: nan ------> ------> Mse: 0.1282307687300483 \t \n",
            "Epoch: 613 ------>logloss: nan ------> ------> Mse: 0.11136259880813501 \t \n",
            "Epoch: 614 ------>logloss: nan ------> ------> Mse: 0.09270988467445543 \t \n",
            "Epoch: 615 ------>logloss: nan ------> ------> Mse: 0.11182297158676724 \t \n",
            "Epoch: 616 ------>logloss: nan ------> ------> Mse: 0.09412088372850827 \t \n",
            "Epoch: 617 ------>logloss: nan ------> ------> Mse: 0.11234333600475098 \t \n",
            "Epoch: 618 ------>logloss: nan ------> ------> Mse: 0.0987249642764002 \t \n",
            "Epoch: 619 ------>logloss: nan ------> ------> Mse: 0.10065615941405828 \t \n",
            "Epoch: 620 ------>logloss: nan ------> ------> Mse: 0.07335461394040332 \t \n",
            "Epoch: 621 ------>logloss: nan ------> ------> Mse: 0.08843244360272 \t \n",
            "Epoch: 622 ------>logloss: nan ------> ------> Mse: 0.07484490541539038 \t \n",
            "Epoch: 623 ------>logloss: nan ------> ------> Mse: 0.10589921958250588 \t \n",
            "Epoch: 624 ------>logloss: nan ------> ------> Mse: 0.0905871238944525 \t \n",
            "Epoch: 625 ------>logloss: nan ------> ------> Mse: 0.07275884641987775 \t \n",
            "Epoch: 626 ------>logloss: nan ------> ------> Mse: 0.07483093823598853 \t \n",
            "Epoch: 627 ------>logloss: nan ------> ------> Mse: 0.10604676117749907 \t \n",
            "Epoch: 628 ------>logloss: nan ------> ------> Mse: 0.09042258037820793 \t \n",
            "Epoch: 629 ------>logloss: nan ------> ------> Mse: 0.0724329410752475 \t \n",
            "Epoch: 630 ------>logloss: nan ------> ------> Mse: 0.07491723829122775 \t \n",
            "Epoch: 631 ------>logloss: nan ------> ------> Mse: 0.10626881211828125 \t \n",
            "Epoch: 632 ------>logloss: nan ------> ------> Mse: 0.0902393130866064 \t \n",
            "Epoch: 633 ------>logloss: nan ------> ------> Mse: 0.07213003447236632 \t \n",
            "Epoch: 634 ------>logloss: nan ------> ------> Mse: 0.0751087248547211 \t \n",
            "Epoch: 635 ------>logloss: nan ------> ------> Mse: 0.10656043008926669 \t \n",
            "Epoch: 636 ------>logloss: nan ------> ------> Mse: 0.09003168441396815 \t \n",
            "Epoch: 637 ------>logloss: nan ------> ------> Mse: 0.07185675063333831 \t \n",
            "Epoch: 638 ------>logloss: nan ------> ------> Mse: 0.07541046388321866 \t \n",
            "Epoch: 639 ------>logloss: nan ------> ------> Mse: 0.10691225400432887 \t \n",
            "Epoch: 640 ------>logloss: nan ------> ------> Mse: 0.08979777568698674 \t \n",
            "Epoch: 641 ------>logloss: nan ------> ------> Mse: 0.07162185135964537 \t \n",
            "Epoch: 642 ------>logloss: nan ------> ------> Mse: 0.07582678705531504 \t \n",
            "Epoch: 643 ------>logloss: nan ------> ------> Mse: 0.12012758161553005 \t \n",
            "Epoch: 644 ------>logloss: nan ------> ------> Mse: 0.10467275112983222 \t \n",
            "Epoch: 645 ------>logloss: nan ------> ------> Mse: 0.110253425320378 \t \n",
            "Epoch: 646 ------>logloss: nan ------> ------> Mse: 0.10677002355741406 \t \n",
            "Epoch: 647 ------>logloss: nan ------> ------> Mse: 0.07081406127516418 \t \n",
            "Epoch: 648 ------>logloss: nan ------> ------> Mse: 0.07016078827025525 \t \n",
            "Epoch: 649 ------>logloss: nan ------> ------> Mse: 0.06972022271207096 \t \n",
            "Epoch: 650 ------>logloss: nan ------> ------> Mse: 0.06951817893932295 \t \n",
            "Epoch: 651 ------>logloss: nan ------> ------> Mse: 0.12834576020270133 \t \n",
            "Epoch: 652 ------>logloss: nan ------> ------> Mse: 0.1169700456982939 \t \n",
            "Epoch: 653 ------>logloss: nan ------> ------> Mse: 0.09293042463907977 \t \n",
            "Epoch: 654 ------>logloss: nan ------> ------> Mse: 0.1187488636921404 \t \n",
            "Epoch: 655 ------>logloss: nan ------> ------> Mse: 0.09091227522815443 \t \n",
            "Epoch: 656 ------>logloss: nan ------> ------> Mse: 0.11592131582313757 \t \n",
            "Epoch: 657 ------>logloss: nan ------> ------> Mse: 0.10145205016667909 \t \n",
            "Epoch: 658 ------>logloss: nan ------> ------> Mse: 0.09916908908480154 \t \n",
            "Epoch: 659 ------>logloss: nan ------> ------> Mse: 0.08917792028470257 \t \n",
            "Epoch: 660 ------>logloss: nan ------> ------> Mse: 0.08710610039154335 \t \n",
            "Epoch: 661 ------>logloss: nan ------> ------> Mse: 0.07377876181086149 \t \n",
            "Epoch: 662 ------>logloss: nan ------> ------> Mse: 0.08852100515491844 \t \n",
            "Epoch: 663 ------>logloss: nan ------> ------> Mse: 0.07528328863050632 \t \n",
            "Epoch: 664 ------>logloss: nan ------> ------> Mse: 0.09089221967793569 \t \n",
            "Epoch: 665 ------>logloss: nan ------> ------> Mse: 0.0786982428108447 \t \n",
            "Epoch: 666 ------>logloss: nan ------> ------> Mse: 0.11782805271164756 \t \n",
            "Epoch: 667 ------>logloss: nan ------> ------> Mse: 0.07832601426034153 \t \n",
            "Epoch: 668 ------>logloss: nan ------> ------> Mse: 0.11536717154604301 \t \n",
            "Epoch: 669 ------>logloss: nan ------> ------> Mse: 0.09019761143626888 \t \n",
            "Epoch: 670 ------>logloss: nan ------> ------> Mse: 0.07632122678951052 \t \n",
            "Epoch: 671 ------>logloss: nan ------> ------> Mse: 0.1157826278956522 \t \n",
            "Epoch: 672 ------>logloss: nan ------> ------> Mse: 0.0769856430532465 \t \n",
            "Epoch: 673 ------>logloss: nan ------> ------> Mse: 0.11286020971944613 \t \n",
            "Epoch: 674 ------>logloss: nan ------> ------> Mse: 0.07467098793175508 \t \n",
            "Epoch: 675 ------>logloss: nan ------> ------> Mse: 0.10692003726562768 \t \n",
            "Epoch: 676 ------>logloss: nan ------> ------> Mse: 0.09193982013074099 \t \n",
            "Epoch: 677 ------>logloss: nan ------> ------> Mse: 0.07131808887980745 \t \n",
            "Epoch: 678 ------>logloss: nan ------> ------> Mse: 0.07474801482051321 \t \n",
            "Epoch: 679 ------>logloss: nan ------> ------> Mse: 0.10713933474628763 \t \n",
            "Epoch: 680 ------>logloss: nan ------> ------> Mse: 0.09173835926678152 \t \n",
            "Epoch: 681 ------>logloss: nan ------> ------> Mse: 0.07109062089297861 \t \n",
            "Epoch: 682 ------>logloss: nan ------> ------> Mse: 0.07495605141583722 \t \n",
            "Epoch: 683 ------>logloss: nan ------> ------> Mse: 0.10744065125255202 \t \n",
            "Epoch: 684 ------>logloss: nan ------> ------> Mse: 0.09149347103577836 \t \n",
            "Epoch: 685 ------>logloss: nan ------> ------> Mse: 0.07089683706777405 \t \n",
            "Epoch: 686 ------>logloss: nan ------> ------> Mse: 0.07529812251396185 \t \n",
            "Epoch: 687 ------>logloss: nan ------> ------> Mse: 0.12347306164224714 \t \n",
            "Epoch: 688 ------>logloss: nan ------> ------> Mse: 0.08970514635140567 \t \n",
            "Epoch: 689 ------>logloss: nan ------> ------> Mse: 0.07385234083347318 \t \n",
            "Epoch: 690 ------>logloss: nan ------> ------> Mse: 0.09209729027852932 \t \n",
            "Epoch: 691 ------>logloss: nan ------> ------> Mse: 0.1212985995582393 \t \n",
            "Epoch: 692 ------>logloss: nan ------> ------> Mse: 0.12192530570529087 \t \n",
            "Epoch: 693 ------>logloss: nan ------> ------> Mse: 0.12276611404133779 \t \n",
            "Epoch: 694 ------>logloss: nan ------> ------> Mse: 0.1328810857139933 \t \n",
            "Epoch: 695 ------>logloss: nan ------> ------> Mse: 0.1089614442864681 \t \n",
            "Epoch: 696 ------>logloss: nan ------> ------> Mse: 0.11475490447945999 \t \n",
            "Epoch: 697 ------>logloss: nan ------> ------> Mse: 0.10606898680994738 \t \n",
            "Epoch: 698 ------>logloss: nan ------> ------> Mse: 0.13063533077919542 \t \n",
            "Epoch: 699 ------>logloss: nan ------> ------> Mse: 0.12788838020721768 \t \n",
            "Epoch: 700 ------>logloss: nan ------> ------> Mse: 0.12567384685384678 \t \n",
            "Epoch: 701 ------>logloss: nan ------> ------> Mse: 0.11948141118701268 \t \n",
            "Epoch: 702 ------>logloss: nan ------> ------> Mse: 0.10266588245228968 \t \n",
            "Epoch: 703 ------>logloss: nan ------> ------> Mse: 0.09985188568451712 \t \n",
            "Epoch: 704 ------>logloss: nan ------> ------> Mse: 0.08868243582904121 \t \n",
            "Epoch: 705 ------>logloss: nan ------> ------> Mse: 0.08546472345159187 \t \n",
            "Epoch: 706 ------>logloss: nan ------> ------> Mse: 0.07058047613078543 \t \n",
            "Epoch: 707 ------>logloss: nan ------> ------> Mse: 0.08650396769449996 \t \n",
            "Epoch: 708 ------>logloss: nan ------> ------> Mse: 0.07183514388778832 \t \n",
            "Epoch: 709 ------>logloss: nan ------> ------> Mse: 0.08907587198955408 \t \n",
            "Epoch: 710 ------>logloss: nan ------> ------> Mse: 0.1186091134060412 \t \n",
            "Epoch: 711 ------>logloss: nan ------> ------> Mse: 0.11949467336183016 \t \n",
            "Epoch: 712 ------>logloss: nan ------> ------> Mse: 0.11804777036859768 \t \n",
            "Epoch: 713 ------>logloss: nan ------> ------> Mse: 0.058774592667481834 \t \n",
            "Epoch: 714 ------>logloss: nan ------> ------> Mse: 0.07063909313922433 \t \n",
            "Epoch: 715 ------>logloss: nan ------> ------> Mse: 0.11373233517414248 \t \n",
            "Epoch: 716 ------>logloss: nan ------> ------> Mse: 0.07065675233080757 \t \n",
            "Epoch: 717 ------>logloss: nan ------> ------> Mse: 0.08839600738521151 \t \n",
            "Epoch: 718 ------>logloss: nan ------> ------> Mse: 0.11717375835864584 \t \n",
            "Epoch: 719 ------>logloss: nan ------> ------> Mse: 0.11795760275704972 \t \n",
            "Epoch: 720 ------>logloss: nan ------> ------> Mse: 0.11665356843449644 \t \n",
            "Epoch: 721 ------>logloss: nan ------> ------> Mse: 0.058440297432503195 \t \n",
            "Epoch: 722 ------>logloss: nan ------> ------> Mse: 0.10675832215807841 \t \n",
            "Epoch: 723 ------>logloss: nan ------> ------> Mse: 0.06895840641224289 \t \n",
            "Epoch: 724 ------>logloss: nan ------> ------> Mse: 0.08587276911558824 \t \n",
            "Epoch: 725 ------>logloss: nan ------> ------> Mse: 0.07091953265777017 \t \n",
            "Epoch: 726 ------>logloss: nan ------> ------> Mse: 0.10334433440841981 \t \n",
            "Epoch: 727 ------>logloss: nan ------> ------> Mse: 0.08818319773929931 \t \n",
            "Epoch: 728 ------>logloss: nan ------> ------> Mse: 0.056404356182090096 \t \n",
            "Epoch: 729 ------>logloss: nan ------> ------> Mse: 0.06899582023774035 \t \n",
            "Epoch: 730 ------>logloss: nan ------> ------> Mse: 0.08638160606158636 \t \n",
            "Epoch: 731 ------>logloss: nan ------> ------> Mse: 0.0713637193247741 \t \n",
            "Epoch: 732 ------>logloss: nan ------> ------> Mse: 0.10375894191620218 \t \n",
            "Epoch: 733 ------>logloss: nan ------> ------> Mse: 0.08874128641790467 \t \n",
            "Epoch: 734 ------>logloss: nan ------> ------> Mse: 0.0563995955218961 \t \n",
            "Epoch: 735 ------>logloss: nan ------> ------> Mse: 0.06908953661714247 \t \n",
            "Epoch: 736 ------>logloss: nan ------> ------> Mse: 0.08697337512697881 \t \n",
            "Epoch: 737 ------>logloss: nan ------> ------> Mse: 0.08531817303477586 \t \n",
            "Epoch: 738 ------>logloss: nan ------> ------> Mse: 0.08922165912820645 \t \n",
            "Epoch: 739 ------>logloss: nan ------> ------> Mse: 0.0713718562387783 \t \n",
            "Epoch: 740 ------>logloss: nan ------> ------> Mse: 0.11225902419389099 \t \n",
            "Epoch: 741 ------>logloss: nan ------> ------> Mse: 0.08460149717454023 \t \n",
            "Epoch: 742 ------>logloss: nan ------> ------> Mse: 0.08149073683302852 \t \n",
            "Epoch: 743 ------>logloss: nan ------> ------> Mse: 0.08751468615417782 \t \n",
            "Epoch: 744 ------>logloss: nan ------> ------> Mse: 0.06932819295601692 \t \n",
            "Epoch: 745 ------>logloss: nan ------> ------> Mse: 0.10826161638701365 \t \n",
            "Epoch: 746 ------>logloss: nan ------> ------> Mse: 0.07682395666376735 \t \n",
            "Epoch: 747 ------>logloss: nan ------> ------> Mse: 0.08637597324614282 \t \n",
            "Epoch: 748 ------>logloss: nan ------> ------> Mse: 0.05678922334210881 \t \n",
            "Epoch: 749 ------>logloss: nan ------> ------> Mse: 0.07601355802575226 \t \n",
            "Epoch: 750 ------>logloss: nan ------> ------> Mse: 0.08546564020385602 \t \n",
            "Epoch: 751 ------>logloss: nan ------> ------> Mse: 0.09945162684713751 \t \n",
            "Epoch: 752 ------>logloss: nan ------> ------> Mse: 0.08520581874601334 \t \n",
            "Epoch: 753 ------>logloss: nan ------> ------> Mse: 0.055200667603099135 \t \n",
            "Epoch: 754 ------>logloss: nan ------> ------> Mse: 0.0678297572357049 \t \n",
            "Epoch: 755 ------>logloss: nan ------> ------> Mse: 0.08527351150914736 \t \n",
            "Epoch: 756 ------>logloss: nan ------> ------> Mse: 0.06876157276290032 \t \n",
            "Epoch: 757 ------>logloss: nan ------> ------> Mse: 0.08715402091477843 \t \n",
            "Epoch: 758 ------>logloss: nan ------> ------> Mse: 0.09624939729626047 \t \n",
            "Epoch: 759 ------>logloss: nan ------> ------> Mse: 0.07601038604260671 \t \n",
            "Epoch: 760 ------>logloss: nan ------> ------> Mse: 0.08565439019360503 \t \n",
            "Epoch: 761 ------>logloss: nan ------> ------> Mse: 0.08853771475061213 \t \n",
            "Epoch: 762 ------>logloss: nan ------> ------> Mse: 0.08645015377685712 \t \n",
            "Epoch: 763 ------>logloss: nan ------> ------> Mse: 0.06935616889421785 \t \n",
            "Epoch: 764 ------>logloss: nan ------> ------> Mse: 0.07752211075276627 \t \n",
            "Epoch: 765 ------>logloss: nan ------> ------> Mse: 0.07762275867060191 \t \n",
            "Epoch: 766 ------>logloss: nan ------> ------> Mse: 0.11087886564041649 \t \n",
            "Epoch: 767 ------>logloss: nan ------> ------> Mse: 0.08161644127583828 \t \n",
            "Epoch: 768 ------>logloss: nan ------> ------> Mse: 0.08073989413462505 \t \n",
            "Epoch: 769 ------>logloss: nan ------> ------> Mse: 0.08408407239479775 \t \n",
            "Epoch: 770 ------>logloss: nan ------> ------> Mse: 0.07664706657767868 \t \n",
            "Epoch: 771 ------>logloss: nan ------> ------> Mse: 0.08564327874038576 \t \n",
            "Epoch: 772 ------>logloss: nan ------> ------> Mse: 0.055745182410108104 \t \n",
            "Epoch: 773 ------>logloss: nan ------> ------> Mse: 0.07586409732135696 \t \n",
            "Epoch: 774 ------>logloss: nan ------> ------> Mse: 0.08473864975565999 \t \n",
            "Epoch: 775 ------>logloss: nan ------> ------> Mse: 0.05563597325978975 \t \n",
            "Epoch: 776 ------>logloss: nan ------> ------> Mse: 0.07510680184728322 \t \n",
            "Epoch: 777 ------>logloss: nan ------> ------> Mse: 0.08387785323694083 \t \n",
            "Epoch: 778 ------>logloss: nan ------> ------> Mse: 0.09928575325364723 \t \n",
            "Epoch: 779 ------>logloss: nan ------> ------> Mse: 0.07304633802502006 \t \n",
            "Epoch: 780 ------>logloss: nan ------> ------> Mse: 0.08215891780221639 \t \n",
            "Epoch: 781 ------>logloss: nan ------> ------> Mse: 0.09901770793923045 \t \n",
            "Epoch: 782 ------>logloss: nan ------> ------> Mse: 0.0711298409423367 \t \n",
            "Epoch: 783 ------>logloss: nan ------> ------> Mse: 0.06824607294174516 \t \n",
            "Epoch: 784 ------>logloss: nan ------> ------> Mse: 0.06601435689551013 \t \n",
            "Epoch: 785 ------>logloss: nan ------> ------> Mse: 0.08211705228338581 \t \n",
            "Epoch: 786 ------>logloss: nan ------> ------> Mse: 0.07489552221854057 \t \n",
            "Epoch: 787 ------>logloss: nan ------> ------> Mse: 0.07229875439762996 \t \n",
            "Epoch: 788 ------>logloss: nan ------> ------> Mse: 0.06751299059718523 \t \n",
            "Epoch: 789 ------>logloss: nan ------> ------> Mse: 0.07330028129125575 \t \n",
            "Epoch: 790 ------>logloss: nan ------> ------> Mse: 0.06886628369314916 \t \n",
            "Epoch: 791 ------>logloss: nan ------> ------> Mse: 0.0668982473168181 \t \n",
            "Epoch: 792 ------>logloss: nan ------> ------> Mse: 0.07362475500983683 \t \n",
            "Epoch: 793 ------>logloss: nan ------> ------> Mse: 0.07369186124123747 \t \n",
            "Epoch: 794 ------>logloss: nan ------> ------> Mse: 0.07381304471959911 \t \n",
            "Epoch: 795 ------>logloss: nan ------> ------> Mse: 0.07399925655270567 \t \n",
            "Epoch: 796 ------>logloss: nan ------> ------> Mse: 0.09920307921304193 \t \n",
            "Epoch: 797 ------>logloss: nan ------> ------> Mse: 0.08352951517032425 \t \n",
            "Epoch: 798 ------>logloss: nan ------> ------> Mse: 0.09910722372391019 \t \n",
            "Epoch: 799 ------>logloss: nan ------> ------> Mse: 0.0721198522951473 \t \n",
            "Epoch: 800 ------>logloss: nan ------> ------> Mse: 0.06805086806400326 \t \n",
            "Epoch: 801 ------>logloss: nan ------> ------> Mse: 0.07316239070691212 \t \n",
            "Epoch: 802 ------>logloss: nan ------> ------> Mse: 0.07109088663456387 \t \n",
            "Epoch: 803 ------>logloss: nan ------> ------> Mse: 0.0666004753115138 \t \n",
            "Epoch: 804 ------>logloss: nan ------> ------> Mse: 0.07177950991717068 \t \n",
            "Epoch: 805 ------>logloss: nan ------> ------> Mse: 0.06762169565892523 \t \n",
            "Epoch: 806 ------>logloss: nan ------> ------> Mse: 0.07290551681012596 \t \n",
            "Epoch: 807 ------>logloss: nan ------> ------> Mse: 0.06374588161214467 \t \n",
            "Epoch: 808 ------>logloss: nan ------> ------> Mse: 0.06961208350403461 \t \n",
            "Epoch: 809 ------>logloss: nan ------> ------> Mse: 0.06701055317974418 \t \n",
            "Epoch: 810 ------>logloss: nan ------> ------> Mse: 0.0706392704119377 \t \n",
            "Epoch: 811 ------>logloss: nan ------> ------> Mse: 0.06852883299522056 \t \n",
            "Epoch: 812 ------>logloss: nan ------> ------> Mse: 0.06599372734052092 \t \n",
            "Epoch: 813 ------>logloss: nan ------> ------> Mse: 0.07203259375417476 \t \n",
            "Epoch: 814 ------>logloss: nan ------> ------> Mse: 0.07184426652818325 \t \n",
            "Epoch: 815 ------>logloss: nan ------> ------> Mse: 0.07166368314192882 \t \n",
            "Epoch: 816 ------>logloss: nan ------> ------> Mse: 0.07150543696000082 \t \n",
            "Epoch: 817 ------>logloss: nan ------> ------> Mse: 0.0713852208800676 \t \n",
            "Epoch: 818 ------>logloss: nan ------> ------> Mse: 0.07131898101992423 \t \n",
            "Epoch: 819 ------>logloss: nan ------> ------> Mse: 0.07132192929287635 \t \n",
            "Epoch: 820 ------>logloss: nan ------> ------> Mse: 0.07140752255036754 \t \n",
            "Epoch: 821 ------>logloss: nan ------> ------> Mse: 0.08779503352758725 \t \n",
            "Epoch: 822 ------>logloss: nan ------> ------> Mse: 0.08869716066670226 \t \n",
            "Epoch: 823 ------>logloss: nan ------> ------> Mse: 0.0711752628761504 \t \n",
            "Epoch: 824 ------>logloss: nan ------> ------> Mse: 0.07105431720010713 \t \n",
            "Epoch: 825 ------>logloss: nan ------> ------> Mse: 0.07099687803784678 \t \n",
            "Epoch: 826 ------>logloss: nan ------> ------> Mse: 0.08681931388242328 \t \n",
            "Epoch: 827 ------>logloss: nan ------> ------> Mse: 0.08872988529125865 \t \n",
            "Epoch: 828 ------>logloss: nan ------> ------> Mse: 0.07138188709277997 \t \n",
            "Epoch: 829 ------>logloss: nan ------> ------> Mse: 0.08161797822089532 \t \n",
            "Epoch: 830 ------>logloss: nan ------> ------> Mse: 0.07518317093824163 \t \n",
            "Epoch: 831 ------>logloss: nan ------> ------> Mse: 0.07323682738391327 \t \n",
            "Epoch: 832 ------>logloss: nan ------> ------> Mse: 0.0832172196528932 \t \n",
            "Epoch: 833 ------>logloss: nan ------> ------> Mse: 0.09938247373611718 \t \n",
            "Epoch: 834 ------>logloss: nan ------> ------> Mse: 0.0712273270128764 \t \n",
            "Epoch: 835 ------>logloss: nan ------> ------> Mse: 0.06721784808549394 \t \n",
            "Epoch: 836 ------>logloss: nan ------> ------> Mse: 0.07175956745862987 \t \n",
            "Epoch: 837 ------>logloss: nan ------> ------> Mse: 0.08162999307711526 \t \n",
            "Epoch: 838 ------>logloss: nan ------> ------> Mse: 0.09924808497161233 \t \n",
            "Epoch: 839 ------>logloss: nan ------> ------> Mse: 0.06979855429689209 \t \n",
            "Epoch: 840 ------>logloss: nan ------> ------> Mse: 0.06631983600430004 \t \n",
            "Epoch: 841 ------>logloss: nan ------> ------> Mse: 0.07043864959182387 \t \n",
            "Epoch: 842 ------>logloss: nan ------> ------> Mse: 0.06259772536754979 \t \n",
            "Epoch: 843 ------>logloss: nan ------> ------> Mse: 0.06778223535802283 \t \n",
            "Epoch: 844 ------>logloss: nan ------> ------> Mse: 0.06561036054482555 \t \n",
            "Epoch: 845 ------>logloss: nan ------> ------> Mse: 0.06829537684798166 \t \n",
            "Epoch: 846 ------>logloss: nan ------> ------> Mse: 0.06672010095166891 \t \n",
            "Epoch: 847 ------>logloss: nan ------> ------> Mse: 0.0692401744928889 \t \n",
            "Epoch: 848 ------>logloss: nan ------> ------> Mse: 0.0673145253800988 \t \n",
            "Epoch: 849 ------>logloss: nan ------> ------> Mse: 0.06519316779566094 \t \n",
            "Epoch: 850 ------>logloss: nan ------> ------> Mse: 0.06790956953322669 \t \n",
            "Epoch: 851 ------>logloss: nan ------> ------> Mse: 0.06143900513051083 \t \n",
            "Epoch: 852 ------>logloss: nan ------> ------> Mse: 0.08512710933457507 \t \n",
            "Epoch: 853 ------>logloss: nan ------> ------> Mse: 0.09254786250515072 \t \n",
            "Epoch: 854 ------>logloss: nan ------> ------> Mse: 0.08057782232524477 \t \n",
            "Epoch: 855 ------>logloss: nan ------> ------> Mse: 0.08952021851943294 \t \n",
            "Epoch: 856 ------>logloss: nan ------> ------> Mse: 0.06474337067155161 \t \n",
            "Epoch: 857 ------>logloss: nan ------> ------> Mse: 0.06427640881433185 \t \n",
            "Epoch: 858 ------>logloss: nan ------> ------> Mse: 0.09732517488437653 \t \n",
            "Epoch: 859 ------>logloss: nan ------> ------> Mse: 0.10745779610216075 \t \n",
            "Epoch: 860 ------>logloss: nan ------> ------> Mse: 0.11129193806449378 \t \n",
            "Epoch: 861 ------>logloss: nan ------> ------> Mse: 0.10791979152884931 \t \n",
            "Epoch: 862 ------>logloss: nan ------> ------> Mse: 0.11455600599914494 \t \n",
            "Epoch: 863 ------>logloss: nan ------> ------> Mse: 0.10298047302595824 \t \n",
            "Epoch: 864 ------>logloss: nan ------> ------> Mse: 0.11180765743495266 \t \n",
            "Epoch: 865 ------>logloss: nan ------> ------> Mse: 0.09356087933336224 \t \n",
            "Epoch: 866 ------>logloss: nan ------> ------> Mse: 0.11571336166453917 \t \n",
            "Epoch: 867 ------>logloss: nan ------> ------> Mse: 0.08693045384325417 \t \n",
            "Epoch: 868 ------>logloss: nan ------> ------> Mse: 0.11405575655356046 \t \n",
            "Epoch: 869 ------>logloss: nan ------> ------> Mse: 0.11267310469172978 \t \n",
            "Epoch: 870 ------>logloss: nan ------> ------> Mse: 0.07707536797561604 \t \n",
            "Epoch: 871 ------>logloss: nan ------> ------> Mse: 0.06212021301988328 \t \n",
            "Epoch: 872 ------>logloss: nan ------> ------> Mse: 0.07848303977707334 \t \n",
            "Epoch: 873 ------>logloss: nan ------> ------> Mse: 0.06711238456763079 \t \n",
            "Epoch: 874 ------>logloss: nan ------> ------> Mse: 0.060707838964896864 \t \n",
            "Epoch: 875 ------>logloss: nan ------> ------> Mse: 0.060609807036507916 \t \n",
            "Epoch: 876 ------>logloss: nan ------> ------> Mse: 0.06713248653538621 \t \n",
            "Epoch: 877 ------>logloss: nan ------> ------> Mse: 0.09590060188062145 \t \n",
            "Epoch: 878 ------>logloss: nan ------> ------> Mse: 0.10547036959349403 \t \n",
            "Epoch: 879 ------>logloss: nan ------> ------> Mse: 0.10987132039799236 \t \n",
            "Epoch: 880 ------>logloss: nan ------> ------> Mse: 0.10567455282400345 \t \n",
            "Epoch: 881 ------>logloss: nan ------> ------> Mse: 0.07577616793148213 \t \n",
            "Epoch: 882 ------>logloss: nan ------> ------> Mse: 0.06902595969688448 \t \n",
            "Epoch: 883 ------>logloss: nan ------> ------> Mse: 0.06809971391194497 \t \n",
            "Epoch: 884 ------>logloss: nan ------> ------> Mse: 0.06723763005655439 \t \n",
            "Epoch: 885 ------>logloss: nan ------> ------> Mse: 0.06644961145404647 \t \n",
            "Epoch: 886 ------>logloss: nan ------> ------> Mse: 0.06575309603811179 \t \n",
            "Epoch: 887 ------>logloss: nan ------> ------> Mse: 0.09484536257287858 \t \n",
            "Epoch: 888 ------>logloss: nan ------> ------> Mse: 0.09690680770838536 \t \n",
            "Epoch: 889 ------>logloss: nan ------> ------> Mse: 0.11861060173440588 \t \n",
            "Epoch: 890 ------>logloss: nan ------> ------> Mse: 0.09201136496004085 \t \n",
            "Epoch: 891 ------>logloss: nan ------> ------> Mse: 0.11749050533164662 \t \n",
            "Epoch: 892 ------>logloss: nan ------> ------> Mse: 0.09301050064175749 \t \n",
            "Epoch: 893 ------>logloss: nan ------> ------> Mse: 0.11632137121884178 \t \n",
            "Epoch: 894 ------>logloss: nan ------> ------> Mse: 0.09713650224929267 \t \n",
            "Epoch: 895 ------>logloss: nan ------> ------> Mse: 0.11315439943310449 \t \n",
            "Epoch: 896 ------>logloss: nan ------> ------> Mse: 0.06692258424038333 \t \n",
            "Epoch: 897 ------>logloss: nan ------> ------> Mse: 0.07638640042700445 \t \n",
            "Epoch: 898 ------>logloss: nan ------> ------> Mse: 0.062027792169777225 \t \n",
            "Epoch: 899 ------>logloss: nan ------> ------> Mse: 0.06808922343070513 \t \n",
            "Epoch: 900 ------>logloss: nan ------> ------> Mse: 0.07701518467237832 \t \n",
            "Epoch: 901 ------>logloss: nan ------> ------> Mse: 0.06235052738498064 \t \n",
            "Epoch: 902 ------>logloss: nan ------> ------> Mse: 0.08670467353346936 \t \n",
            "Epoch: 903 ------>logloss: nan ------> ------> Mse: 0.09253823568862586 \t \n",
            "Epoch: 904 ------>logloss: nan ------> ------> Mse: 0.07901546122927018 \t \n",
            "Epoch: 905 ------>logloss: nan ------> ------> Mse: 0.1263433504308727 \t \n",
            "Epoch: 906 ------>logloss: nan ------> ------> Mse: 0.105606832164811 \t \n",
            "Epoch: 907 ------>logloss: nan ------> ------> Mse: 0.07647622264241409 \t \n",
            "Epoch: 908 ------>logloss: nan ------> ------> Mse: 0.0692691411143789 \t \n",
            "Epoch: 909 ------>logloss: nan ------> ------> Mse: 0.0684537879619041 \t \n",
            "Epoch: 910 ------>logloss: nan ------> ------> Mse: 0.06769217914654134 \t \n",
            "Epoch: 911 ------>logloss: nan ------> ------> Mse: 0.06699468942446614 \t \n",
            "Epoch: 912 ------>logloss: nan ------> ------> Mse: 0.06637913723144345 \t \n",
            "Epoch: 913 ------>logloss: nan ------> ------> Mse: 0.09521979534611802 \t \n",
            "Epoch: 914 ------>logloss: nan ------> ------> Mse: 0.09637524947259739 \t \n",
            "Epoch: 915 ------>logloss: nan ------> ------> Mse: 0.1188066667811899 \t \n",
            "Epoch: 916 ------>logloss: nan ------> ------> Mse: 0.09176477936722455 \t \n",
            "Epoch: 917 ------>logloss: nan ------> ------> Mse: 0.11750992033578471 \t \n",
            "Epoch: 918 ------>logloss: nan ------> ------> Mse: 0.10296487381571102 \t \n",
            "Epoch: 919 ------>logloss: nan ------> ------> Mse: 0.11881570512372609 \t \n",
            "Epoch: 920 ------>logloss: nan ------> ------> Mse: 0.11906137836263052 \t \n",
            "Epoch: 921 ------>logloss: nan ------> ------> Mse: 0.09328290427756615 \t \n",
            "Epoch: 922 ------>logloss: nan ------> ------> Mse: 0.11869389231905338 \t \n",
            "Epoch: 923 ------>logloss: nan ------> ------> Mse: 0.08643047190035566 \t \n",
            "Epoch: 924 ------>logloss: nan ------> ------> Mse: 0.09974061737577297 \t \n",
            "Epoch: 925 ------>logloss: nan ------> ------> Mse: 0.0921913285699798 \t \n",
            "Epoch: 926 ------>logloss: nan ------> ------> Mse: 0.0706259301879964 \t \n",
            "Epoch: 927 ------>logloss: nan ------> ------> Mse: 0.07002829549204036 \t \n",
            "Epoch: 928 ------>logloss: nan ------> ------> Mse: 0.06947761836392716 \t \n",
            "Epoch: 929 ------>logloss: nan ------> ------> Mse: 0.08009597765013174 \t \n",
            "Epoch: 930 ------>logloss: nan ------> ------> Mse: 0.12686870564961922 \t \n",
            "Epoch: 931 ------>logloss: nan ------> ------> Mse: 0.10549100903007433 \t \n",
            "Epoch: 932 ------>logloss: nan ------> ------> Mse: 0.07776147692313376 \t \n",
            "Epoch: 933 ------>logloss: nan ------> ------> Mse: 0.07056788755203997 \t \n",
            "Epoch: 934 ------>logloss: nan ------> ------> Mse: 0.06975752322481976 \t \n",
            "Epoch: 935 ------>logloss: nan ------> ------> Mse: 0.06899097504260714 \t \n",
            "Epoch: 936 ------>logloss: nan ------> ------> Mse: 0.06827165596128598 \t \n",
            "Epoch: 937 ------>logloss: nan ------> ------> Mse: 0.07871005168649796 \t \n",
            "Epoch: 938 ------>logloss: nan ------> ------> Mse: 0.1283626905260044 \t \n",
            "Epoch: 939 ------>logloss: nan ------> ------> Mse: 0.10793517102011206 \t \n",
            "Epoch: 940 ------>logloss: nan ------> ------> Mse: 0.11104814605263458 \t \n",
            "Epoch: 941 ------>logloss: nan ------> ------> Mse: 0.1186306613020087 \t \n",
            "Epoch: 942 ------>logloss: nan ------> ------> Mse: 0.09791558771699933 \t \n",
            "Epoch: 943 ------>logloss: nan ------> ------> Mse: 0.11824934617600175 \t \n",
            "Epoch: 944 ------>logloss: nan ------> ------> Mse: 0.09026013618554843 \t \n",
            "Epoch: 945 ------>logloss: nan ------> ------> Mse: 0.11732854080663697 \t \n",
            "Epoch: 946 ------>logloss: nan ------> ------> Mse: 0.07352256354420232 \t \n",
            "Epoch: 947 ------>logloss: nan ------> ------> Mse: 0.07107656691422913 \t \n",
            "Epoch: 948 ------>logloss: nan ------> ------> Mse: 0.08172293511472123 \t \n",
            "Epoch: 949 ------>logloss: nan ------> ------> Mse: 0.09272993537557234 \t \n",
            "Epoch: 950 ------>logloss: nan ------> ------> Mse: 0.07454471837652586 \t \n",
            "Epoch: 951 ------>logloss: nan ------> ------> Mse: 0.07360380303041891 \t \n",
            "Epoch: 952 ------>logloss: nan ------> ------> Mse: 0.07271208442862241 \t \n",
            "Epoch: 953 ------>logloss: nan ------> ------> Mse: 0.07186101730635236 \t \n",
            "Epoch: 954 ------>logloss: nan ------> ------> Mse: 0.07105006224758535 \t \n",
            "Epoch: 955 ------>logloss: nan ------> ------> Mse: 0.07028800384129937 \t \n",
            "Epoch: 956 ------>logloss: nan ------> ------> Mse: 0.06959215463976223 \t \n",
            "Epoch: 957 ------>logloss: nan ------> ------> Mse: 0.08007846637098541 \t \n",
            "Epoch: 958 ------>logloss: nan ------> ------> Mse: 0.1297169277729998 \t \n",
            "Epoch: 959 ------>logloss: nan ------> ------> Mse: 0.10424500729537087 \t \n",
            "Epoch: 960 ------>logloss: nan ------> ------> Mse: 0.11186116601988541 \t \n",
            "Epoch: 961 ------>logloss: nan ------> ------> Mse: 0.11882881204857274 \t \n",
            "Epoch: 962 ------>logloss: nan ------> ------> Mse: 0.09272348717860414 \t \n",
            "Epoch: 963 ------>logloss: nan ------> ------> Mse: 0.117812284840574 \t \n",
            "Epoch: 964 ------>logloss: nan ------> ------> Mse: 0.09453602972197717 \t \n",
            "Epoch: 965 ------>logloss: nan ------> ------> Mse: 0.11684670119609719 \t \n",
            "Epoch: 966 ------>logloss: nan ------> ------> Mse: 0.08788936754451922 \t \n",
            "Epoch: 967 ------>logloss: nan ------> ------> Mse: 0.11551811418196992 \t \n",
            "Epoch: 968 ------>logloss: nan ------> ------> Mse: 0.1011540531758007 \t \n",
            "Epoch: 969 ------>logloss: nan ------> ------> Mse: 0.09245770699176763 \t \n",
            "Epoch: 970 ------>logloss: nan ------> ------> Mse: 0.07139489204617773 \t \n",
            "Epoch: 971 ------>logloss: nan ------> ------> Mse: 0.07089446942701726 \t \n",
            "Epoch: 972 ------>logloss: nan ------> ------> Mse: 0.08150024516886972 \t \n",
            "Epoch: 973 ------>logloss: nan ------> ------> Mse: 0.13013501361266266 \t \n",
            "Epoch: 974 ------>logloss: nan ------> ------> Mse: 0.09076298388041908 \t \n",
            "Epoch: 975 ------>logloss: nan ------> ------> Mse: 0.072180720873097 \t \n",
            "Epoch: 976 ------>logloss: nan ------> ------> Mse: 0.07144222398802874 \t \n",
            "Epoch: 977 ------>logloss: nan ------> ------> Mse: 0.07074884145208343 \t \n",
            "Epoch: 978 ------>logloss: nan ------> ------> Mse: 0.07008818141874833 \t \n",
            "Epoch: 979 ------>logloss: nan ------> ------> Mse: 0.06945358653163997 \t \n",
            "Epoch: 980 ------>logloss: nan ------> ------> Mse: 0.07993979836529382 \t \n",
            "Epoch: 981 ------>logloss: nan ------> ------> Mse: 0.12779789911252235 \t \n",
            "Epoch: 982 ------>logloss: nan ------> ------> Mse: 0.1075923406796975 \t \n",
            "Epoch: 983 ------>logloss: nan ------> ------> Mse: 0.10978003483552304 \t \n",
            "Epoch: 984 ------>logloss: nan ------> ------> Mse: 0.11821556668186355 \t \n",
            "Epoch: 985 ------>logloss: nan ------> ------> Mse: 0.09717050053950507 \t \n",
            "Epoch: 986 ------>logloss: nan ------> ------> Mse: 0.11751933285361071 \t \n",
            "Epoch: 987 ------>logloss: nan ------> ------> Mse: 0.08980800199536339 \t \n",
            "Epoch: 988 ------>logloss: nan ------> ------> Mse: 0.11629603755344749 \t \n",
            "Epoch: 989 ------>logloss: nan ------> ------> Mse: 0.07362507354841638 \t \n",
            "Epoch: 990 ------>logloss: nan ------> ------> Mse: 0.07238651683796173 \t \n",
            "Epoch: 991 ------>logloss: nan ------> ------> Mse: 0.08301526946596281 \t \n",
            "Epoch: 992 ------>logloss: nan ------> ------> Mse: 0.09288668897339153 \t \n",
            "Epoch: 993 ------>logloss: nan ------> ------> Mse: 0.07527680022510366 \t \n",
            "Epoch: 994 ------>logloss: nan ------> ------> Mse: 0.07445732217682048 \t \n",
            "Epoch: 995 ------>logloss: nan ------> ------> Mse: 0.07368461487622906 \t \n",
            "Epoch: 996 ------>logloss: nan ------> ------> Mse: 0.07294326141095253 \t \n",
            "Epoch: 997 ------>logloss: nan ------> ------> Mse: 0.07222369115348097 \t \n",
            "Epoch: 998 ------>logloss: nan ------> ------> Mse: 0.07152448336002301 \t \n",
            "Epoch: 999 ------>logloss: nan ------> ------> Mse: 0.08194774462611196 \t \n",
            "Converged through maximum epoch no criteria...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO460lWcoWi1",
        "outputId": "13efa43e-5f5d-4522-ddcc-3216553a15d4"
      },
      "source": [
        "# Accuracy check  using train dataset\n",
        "y_predicted = predict(X_train, y_train, all_weights)\n",
        "y_predicted = np.array(y_predicted)\n",
        "print(accuracy_score(y_train , y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9111111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhCmAcJloeF9",
        "outputId": "eccd3118-ebf3-421f-87da-a10519f44c4b"
      },
      "source": [
        "#Test Accuracy\n",
        "y_predicted = predict(X_test, y_test, all_weights)\n",
        "y_predicted = np.array(y_predicted)\n",
        "print(accuracy_score(y_test , y_predicted ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30666666666666664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBzhOnF8ozpM",
        "outputId": "94fac4f2-b96a-4b14-e907-de286c4c4ae4"
      },
      "source": [
        "# validation\n",
        "y_predicted = predict(X_validation, y_validation, all_weights)\n",
        "y_predicted = np.array(y_predicted)\n",
        "print(accuracy_score(y_validation, y_predicted ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeDTnMvSo8XD",
        "outputId": "f4eb7d8e-fe64-4693-9ae8-6de60aa69f89"
      },
      "source": [
        "# Take average of all folds\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn import metrics\n",
        "accuracy = np.ones(5)\n",
        "precision = np.ones(5)\n",
        "recall = np.ones(5)\n",
        "f1 = np.ones(5)\n",
        "for i in range(0,5):\n",
        "  all_weights = sigmoid_neuron(all_x_train[i], all_y_train[i], lr=0.3, roh = 0.000001, num_iter=100)\n",
        "  y_predicted = predict(all_x_test[i], all_y_test[i], all_weights)\n",
        "  y_predicted = np.array(y_predicted)\n",
        "  accuracy[i] = accuracy_score(all_y_test[i] , y_predicted)*100\n",
        "  print(\"Accuracy Score:\", accuracy[i])\n",
        "  precision[i] = precision_score(all_y_test[i], y_predicted, labels=[0,1,2], average='micro')*100\n",
        "  recall[i] = recall_score(all_y_test[i], y_predicted, labels=[0,1,2], average='micro')*100\n",
        "  f1[i] = f1_score(all_y_test[i], y_predicted, labels=[0,1,2], average='micro')*100\n",
        "  print(\"Training Accuracy: \", accuracy[i])\n",
        "  print(\"Prescission Score:\", precision[i])\n",
        "  print(\"Recall Score : \", recall_score(all_y_test[i], y_predicted, labels=[0,1,2], average='micro')*100) \n",
        "  print('F1 Score : ', f1_score(all_y_test[i], y_predicted, labels=[0,1,2], average='micro')*100)\n",
        "  print('Confusion Matrix : \\n' + str(confusion_matrix(all_y_test[i], y_predicted)))\n",
        "  print(\"Classification Report for 3-classes: \")\n",
        "  out_labels = [0,1,2]\n",
        "  print(metrics.classification_report(all_y_test[i], y_predicted, out_labels, digits=3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 ------>logloss: 0.4096247670641712 ------> ------> Mse: 0.027828615711357182 \t \n",
            "Epoch: 1 ------>logloss: 0.6879755496926 ------> ------> Mse: 0.0467051045095569 \t \n",
            "Epoch: 2 ------>logloss: 0.7320025795484637 ------> ------> Mse: 0.03637730003779174 \t \n",
            "Epoch: 3 ------>logloss: 0.9044915838967652 ------> ------> Mse: 0.04171390891661598 \t \n",
            "Epoch: 4 ------>logloss: 0.9304764278543378 ------> ------> Mse: 0.04219453675079695 \t \n",
            "Epoch: 5 ------>logloss: 0.8102018454458568 ------> ------> Mse: 0.03768993979254121 \t \n",
            "Epoch: 6 ------>logloss: 0.5531514058870264 ------> ------> Mse: 0.03260068611574945 \t \n",
            "Epoch: 7 ------>logloss: 0.761128420852221 ------> ------> Mse: 0.038355795729859185 \t \n",
            "Epoch: 8 ------>logloss: 0.8527940436571988 ------> ------> Mse: 0.04616710783672664 \t \n",
            "Epoch: 9 ------>logloss: 0.45978174289367735 ------> ------> Mse: 0.03311898497702261 \t \n",
            "Epoch: 10 ------>logloss: 0.7406662321580887 ------> ------> Mse: 0.04155141319577235 \t \n",
            "Epoch: 11 ------>logloss: 0.7364613210638065 ------> ------> Mse: 0.0414932296561474 \t \n",
            "Epoch: 12 ------>logloss: 0.735550865413669 ------> ------> Mse: 0.041389650701062104 \t \n",
            "Epoch: 13 ------>logloss: 0.7432347219385083 ------> ------> Mse: 0.04158266959047011 \t \n",
            "Epoch: 14 ------>logloss: nan ------> ------> Mse: 0.05330565227698937 \t \n",
            "Epoch: 15 ------>logloss: nan ------> ------> Mse: 0.0541736908453787 \t \n",
            "Epoch: 16 ------>logloss: 0.8613986516979513 ------> ------> Mse: 0.04638987644347905 \t \n",
            "Epoch: 17 ------>logloss: 0.7379190344007126 ------> ------> Mse: 0.04066373761005324 \t \n",
            "Epoch: 18 ------>logloss: 0.7339526451733066 ------> ------> Mse: 0.03937938234497913 \t \n",
            "Epoch: 19 ------>logloss: 0.6719772258995338 ------> ------> Mse: 0.039226851836243325 \t \n",
            "Epoch: 20 ------>logloss: 0.7273848338450901 ------> ------> Mse: 0.041274978536365685 \t \n",
            "Epoch: 21 ------>logloss: nan ------> ------> Mse: 0.05009832360289768 \t \n",
            "Epoch: 22 ------>logloss: nan ------> ------> Mse: 0.04575525492848534 \t \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 ------>logloss: 0.717708663801236 ------> ------> Mse: 0.04074766723022243 \t \n",
            "Epoch: 24 ------>logloss: 0.8851075037971701 ------> ------> Mse: 0.04747833739802158 \t \n",
            "Epoch: 25 ------>logloss: 0.866102530001836 ------> ------> Mse: 0.04478575463256342 \t \n",
            "Epoch: 26 ------>logloss: 0.7279168908574098 ------> ------> Mse: 0.03953038850405652 \t \n",
            "Epoch: 27 ------>logloss: 0.6755860766267759 ------> ------> Mse: 0.03965687282881839 \t \n",
            "Epoch: 28 ------>logloss: nan ------> ------> Mse: 0.049054757441207616 \t \n",
            "Epoch: 29 ------>logloss: 0.7439800690023233 ------> ------> Mse: 0.041314458622137014 \t \n",
            "Epoch: 30 ------>logloss: 0.7424732830599489 ------> ------> Mse: 0.0405999783175602 \t \n",
            "Epoch: 31 ------>logloss: 0.7489448643106769 ------> ------> Mse: 0.03947859888728513 \t \n",
            "Epoch: 32 ------>logloss: 0.8528187320785107 ------> ------> Mse: 0.04640431284940937 \t \n",
            "Epoch: 33 ------>logloss: 0.6220654380365114 ------> ------> Mse: 0.04379811664054202 \t \n",
            "Epoch: 34 ------>logloss: 0.8584043007863376 ------> ------> Mse: 0.04633393794048798 \t \n",
            "Epoch: 35 ------>logloss: nan ------> ------> Mse: 0.051506092286539885 \t \n",
            "Epoch: 36 ------>logloss: nan ------> ------> Mse: 0.05039980549820281 \t \n",
            "Epoch: 37 ------>logloss: 0.7482420839786553 ------> ------> Mse: 0.042498049495398475 \t \n",
            "Epoch: 38 ------>logloss: 1.0302096767953597 ------> ------> Mse: 0.04823024641368323 \t \n",
            "Epoch: 39 ------>logloss: 0.7193635684080498 ------> ------> Mse: 0.03860837847031475 \t \n",
            "Epoch: 40 ------>logloss: 0.8042035888242769 ------> ------> Mse: 0.044464432758543254 \t \n",
            "Epoch: 41 ------>logloss: 0.4245544917275999 ------> ------> Mse: 0.03295672319668464 \t \n",
            "Epoch: 42 ------>logloss: 0.7237420420897462 ------> ------> Mse: 0.042242356832028864 \t \n",
            "Epoch: 43 ------>logloss: nan ------> ------> Mse: 0.053216627864291294 \t \n",
            "Epoch: 44 ------>logloss: nan ------> ------> Mse: 0.05062215837683935 \t \n",
            "Epoch: 45 ------>logloss: 0.8572251470604784 ------> ------> Mse: 0.04683468297266216 \t \n",
            "Epoch: 46 ------>logloss: 0.8628783068472683 ------> ------> Mse: 0.04418697028609905 \t \n",
            "Epoch: 47 ------>logloss: 0.7199182106425208 ------> ------> Mse: 0.038625941784156285 \t \n",
            "Epoch: 48 ------>logloss: 0.7004256498031066 ------> ------> Mse: 0.04178232847884502 \t \n",
            "Epoch: 49 ------>logloss: nan ------> ------> Mse: 0.051116908734906596 \t \n",
            "Epoch: 50 ------>logloss: 1.0425409437661919 ------> ------> Mse: 0.05018037472176324 \t \n",
            "Epoch: 51 ------>logloss: 0.6655391414657987 ------> ------> Mse: 0.04055123413484617 \t \n",
            "Epoch: 52 ------>logloss: 0.7125057578762061 ------> ------> Mse: 0.04271182158763773 \t \n",
            "Epoch: 53 ------>logloss: 1.215439939625903 ------> ------> Mse: 0.04746758520047876 \t \n",
            "Epoch: 54 ------>logloss: nan ------> ------> Mse: 0.04507027042567439 \t \n",
            "Epoch: 55 ------>logloss: 0.6966608254753911 ------> ------> Mse: 0.040686785799017015 \t \n",
            "Epoch: 56 ------>logloss: 0.8675706813089511 ------> ------> Mse: 0.04838379786724253 \t \n",
            "Epoch: 57 ------>logloss: 0.8558880071220608 ------> ------> Mse: 0.0450153253441184 \t \n",
            "Epoch: 58 ------>logloss: 0.7088759331998967 ------> ------> Mse: 0.039725805066955985 \t \n",
            "Epoch: 59 ------>logloss: 0.6511747771825294 ------> ------> Mse: 0.0398156703407198 \t \n",
            "Epoch: 60 ------>logloss: 0.7139710537389675 ------> ------> Mse: 0.042481130171677754 \t \n",
            "Epoch: 61 ------>logloss: nan ------> ------> Mse: 0.054889467625315914 \t \n",
            "Epoch: 62 ------>logloss: nan ------> ------> Mse: 0.05433771944699716 \t \n",
            "Epoch: 63 ------>logloss: 0.686083478476716 ------> ------> Mse: 0.042054934770454945 \t \n",
            "Epoch: 64 ------>logloss: 0.8639094975661872 ------> ------> Mse: 0.04911933582830325 \t \n",
            "Epoch: 65 ------>logloss: nan ------> ------> Mse: 0.051681124508081724 \t \n",
            "Epoch: 66 ------>logloss: 0.8859860319850602 ------> ------> Mse: 0.0459282977611722 \t \n",
            "Epoch: 67 ------>logloss: 1.0228268430131802 ------> ------> Mse: 0.04679160977577191 \t \n",
            "Epoch: 68 ------>logloss: 0.7956926042043457 ------> ------> Mse: 0.04446321864908461 \t \n",
            "Epoch: 69 ------>logloss: 0.42863418352917343 ------> ------> Mse: 0.03342888042487416 \t \n",
            "Epoch: 70 ------>logloss: 0.6962411117550469 ------> ------> Mse: 0.04168361232057092 \t \n",
            "Epoch: 71 ------>logloss: nan ------> ------> Mse: 0.0512760353615823 \t \n",
            "Epoch: 72 ------>logloss: nan ------> ------> Mse: 0.04949316344291436 \t \n",
            "Epoch: 73 ------>logloss: 0.7260684749719551 ------> ------> Mse: 0.042544647521268075 \t \n",
            "Epoch: 74 ------>logloss: 0.9596587341791069 ------> ------> Mse: 0.05016576206352437 \t \n",
            "Epoch: 75 ------>logloss: 0.8617209811646103 ------> ------> Mse: 0.04688448078167023 \t \n",
            "Epoch: 76 ------>logloss: nan ------> ------> Mse: 0.054651120000225345 \t \n",
            "Epoch: 77 ------>logloss: 0.876439715909788 ------> ------> Mse: 0.046330167780564285 \t \n",
            "Epoch: 78 ------>logloss: 0.7346714854055737 ------> ------> Mse: 0.04323555549030533 \t \n",
            "Epoch: 79 ------>logloss: 0.8820679998219411 ------> ------> Mse: 0.04554584658940426 \t \n",
            "Epoch: 80 ------>logloss: 0.7135652690811973 ------> ------> Mse: 0.04347223031376389 \t \n",
            "Epoch: 81 ------>logloss: nan ------> ------> Mse: 0.05925511741018767 \t \n",
            "Epoch: 82 ------>logloss: nan ------> ------> Mse: 0.0561648158343023 \t \n",
            "Epoch: 83 ------>logloss: 0.9034613705988845 ------> ------> Mse: 0.04879847837934776 \t \n",
            "Epoch: 84 ------>logloss: 0.8517532159833016 ------> ------> Mse: 0.0489287417348678 \t \n",
            "Epoch: 85 ------>logloss: 0.8302994666480479 ------> ------> Mse: 0.0470801645460709 \t \n",
            "Epoch: 86 ------>logloss: nan ------> ------> Mse: 0.052755450519395564 \t \n",
            "Epoch: 87 ------>logloss: 1.1272814853335753 ------> ------> Mse: 0.04905582361956375 \t \n",
            "Epoch: 88 ------>logloss: 0.9468443236489866 ------> ------> Mse: 0.04639405773413667 \t \n",
            "Epoch: 89 ------>logloss: 0.7230381784706632 ------> ------> Mse: 0.04162630693287986 \t \n",
            "Epoch: 90 ------>logloss: nan ------> ------> Mse: 0.054535751605571746 \t \n",
            "Epoch: 91 ------>logloss: 0.9081068907152589 ------> ------> Mse: 0.047381782295461645 \t \n",
            "Epoch: 92 ------>logloss: 0.9637903982054427 ------> ------> Mse: 0.050765880617977176 \t \n",
            "Epoch: 93 ------>logloss: 0.8536088368010356 ------> ------> Mse: 0.048400225484312095 \t \n",
            "Epoch: 94 ------>logloss: 0.8280190065196119 ------> ------> Mse: 0.04595581198102978 \t \n",
            "Epoch: 95 ------>logloss: 0.8593728007583129 ------> ------> Mse: 0.043664109180413455 \t \n",
            "Epoch: 96 ------>logloss: nan ------> ------> Mse: 0.05471711152504966 \t \n",
            "Epoch: 97 ------>logloss: 1.3282794214892428 ------> ------> Mse: 0.05250953484059621 \t \n",
            "Epoch: 98 ------>logloss: 0.9468942709213762 ------> ------> Mse: 0.04789005207109927 \t \n",
            "Epoch: 99 ------>logloss: 0.9560132547384238 ------> ------> Mse: 0.04870507201970256 \t \n",
            "Converged through maximum epoch no criteria...\n",
            "Accuracy Score: 30.0\n",
            "Training Accuracy:  30.0\n",
            "Prescission Score: 30.0\n",
            "Recall Score :  30.0\n",
            "F1 Score :  30.0\n",
            "Confusion Matrix : \n",
            "[[ 0  0  9]\n",
            " [ 0  0 12]\n",
            " [ 0  0  9]]\n",
            "Classification Report for 3-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         9\n",
            "           1      0.000     0.000     0.000        12\n",
            "           2      0.300     1.000     0.462         9\n",
            "\n",
            "    accuracy                          0.300        30\n",
            "   macro avg      0.100     0.333     0.154        30\n",
            "weighted avg      0.090     0.300     0.138        30\n",
            "\n",
            "Epoch: 0 ------>logloss: 0.41640264516096936 ------> ------> Mse: 0.028258696930651122 \t \n",
            "Epoch: 1 ------>logloss: 0.6971734162593868 ------> ------> Mse: 0.04804748932389619 \t \n",
            "Epoch: 2 ------>logloss: 0.7441125558397697 ------> ------> Mse: 0.03648609298207765 \t \n",
            "Epoch: 3 ------>logloss: 0.8386396992744009 ------> ------> Mse: 0.03905508485577192 \t \n",
            "Epoch: 4 ------>logloss: 0.7978235394359948 ------> ------> Mse: 0.04139010312566783 \t \n",
            "Epoch: 5 ------>logloss: 0.7871005800128237 ------> ------> Mse: 0.041196320629475744 \t \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 ------>logloss: 0.7855259038965324 ------> ------> Mse: 0.04050568131380376 \t \n",
            "Epoch: 7 ------>logloss: 1.0168543369301832 ------> ------> Mse: 0.04058518431221367 \t \n",
            "Epoch: 8 ------>logloss: 0.6067117675317385 ------> ------> Mse: 0.03494592462982808 \t \n",
            "Epoch: 9 ------>logloss: 0.7823164392680175 ------> ------> Mse: 0.04146541146914239 \t \n",
            "Epoch: 10 ------>logloss: 0.7844875540143514 ------> ------> Mse: 0.04186856064685044 \t \n",
            "Epoch: 11 ------>logloss: nan ------> ------> Mse: 0.04546885724493623 \t \n",
            "Epoch: 12 ------>logloss: 1.2693077673162194 ------> ------> Mse: 0.04798727249788642 \t \n",
            "Epoch: 13 ------>logloss: 0.795383595646262 ------> ------> Mse: 0.04185164531828738 \t \n",
            "Epoch: 14 ------>logloss: 1.0276912330017347 ------> ------> Mse: 0.04618887409679271 \t \n",
            "Epoch: 15 ------>logloss: 1.4137460973266982 ------> ------> Mse: 0.05656938360194005 \t \n",
            "Epoch: 16 ------>logloss: 1.2374364785817777 ------> ------> Mse: 0.04826498159817197 \t \n",
            "Epoch: 17 ------>logloss: 1.0614004620224826 ------> ------> Mse: 0.041619990932663144 \t \n",
            "Epoch: 18 ------>logloss: 0.7725134744152665 ------> ------> Mse: 0.03954417466362995 \t \n",
            "Epoch: 19 ------>logloss: 0.628661158168381 ------> ------> Mse: 0.03451136941530494 \t \n",
            "Epoch: 20 ------>logloss: 0.48327655893524646 ------> ------> Mse: 0.03332897113579206 \t \n",
            "Epoch: 21 ------>logloss: nan ------> ------> Mse: 0.047581812027556535 \t \n",
            "Epoch: 22 ------>logloss: nan ------> ------> Mse: 0.04687617613187658 \t \n",
            "Epoch: 23 ------>logloss: 1.2759661926106634 ------> ------> Mse: 0.05156891881813252 \t \n",
            "Epoch: 24 ------>logloss: 0.9094652988970279 ------> ------> Mse: 0.04771631751797918 \t \n",
            "Epoch: 25 ------>logloss: 0.9128077834442536 ------> ------> Mse: 0.04586979813266312 \t \n",
            "Epoch: 26 ------>logloss: 0.7877198608125178 ------> ------> Mse: 0.03633755092681698 \t \n",
            "Epoch: 27 ------>logloss: 1.2682497995525592 ------> ------> Mse: 0.0501064768505918 \t \n",
            "Epoch: 28 ------>logloss: 1.0162342002126457 ------> ------> Mse: 0.04383854441272838 \t \n",
            "Epoch: 29 ------>logloss: 0.7757450466089306 ------> ------> Mse: 0.041933094397280005 \t \n",
            "Epoch: 30 ------>logloss: 0.7662929411357372 ------> ------> Mse: 0.04152220311893765 \t \n",
            "Epoch: 31 ------>logloss: 0.7713063977983692 ------> ------> Mse: 0.04184305610274673 \t \n",
            "Epoch: 32 ------>logloss: nan ------> ------> Mse: 0.049887428423024675 \t \n",
            "Epoch: 33 ------>logloss: 1.3545845627701951 ------> ------> Mse: 0.06169563161367529 \t \n",
            "Epoch: 34 ------>logloss: 0.8898205672025428 ------> ------> Mse: 0.0453078121218474 \t \n",
            "Epoch: 35 ------>logloss: 0.7604320179641184 ------> ------> Mse: 0.040993161842056744 \t \n",
            "Epoch: 36 ------>logloss: 0.9713571688417856 ------> ------> Mse: 0.04400781478224136 \t \n",
            "Epoch: 37 ------>logloss: 1.1050737460905038 ------> ------> Mse: 0.04293709416512473 \t \n",
            "Epoch: 38 ------>logloss: 1.056572191175417 ------> ------> Mse: 0.05105498752765872 \t \n",
            "Epoch: 39 ------>logloss: 0.9694794766943412 ------> ------> Mse: 0.04215116278535542 \t \n",
            "Epoch: 40 ------>logloss: 0.7554474914762956 ------> ------> Mse: 0.041948356487998405 \t \n",
            "Epoch: 41 ------>logloss: 0.7446126742024636 ------> ------> Mse: 0.041288196685883564 \t \n",
            "Epoch: 42 ------>logloss: 0.7589690755496167 ------> ------> Mse: 0.0415607730965288 \t \n",
            "Epoch: 43 ------>logloss: nan ------> ------> Mse: 0.04700546322914014 \t \n",
            "Epoch: 44 ------>logloss: 1.2923563211137161 ------> ------> Mse: 0.052519485440571057 \t \n",
            "Epoch: 45 ------>logloss: 0.7486555576322114 ------> ------> Mse: 0.041653377909151454 \t \n",
            "Epoch: 46 ------>logloss: nan ------> ------> Mse: 0.046990373616661474 \t \n",
            "Epoch: 47 ------>logloss: 1.2415123099795808 ------> ------> Mse: 0.049502133653165935 \t \n",
            "Epoch: 48 ------>logloss: 0.7725757620175896 ------> ------> Mse: 0.04298598667688933 \t \n",
            "Epoch: 49 ------>logloss: 0.990302980669917 ------> ------> Mse: 0.04761150063093051 \t \n",
            "Epoch: 50 ------>logloss: 1.4375936516136922 ------> ------> Mse: 0.056819566182543024 \t \n",
            "Epoch: 51 ------>logloss: 0.8811410486137758 ------> ------> Mse: 0.04525518583261571 \t \n",
            "Epoch: 52 ------>logloss: 0.9345912722942598 ------> ------> Mse: 0.04175008992960372 \t \n",
            "Epoch: 53 ------>logloss: 0.9730821490992528 ------> ------> Mse: 0.049959164218149214 \t \n",
            "Epoch: 54 ------>logloss: 0.9883523805765705 ------> ------> Mse: 0.047276665104085645 \t \n",
            "Epoch: 55 ------>logloss: nan ------> ------> Mse: 0.04821975193597818 \t \n",
            "Epoch: 56 ------>logloss: nan ------> ------> Mse: 0.050312748007250364 \t \n",
            "Epoch: 57 ------>logloss: 1.4495097209890817 ------> ------> Mse: 0.05871634862438199 \t \n",
            "Epoch: 58 ------>logloss: nan ------> ------> Mse: 0.05219224115679661 \t \n",
            "Epoch: 59 ------>logloss: 1.380927586349409 ------> ------> Mse: 0.05636540314488589 \t \n",
            "Epoch: 60 ------>logloss: 0.9487229403614484 ------> ------> Mse: 0.04914121896317025 \t \n",
            "Epoch: 61 ------>logloss: nan ------> ------> Mse: 0.05242083443332375 \t \n",
            "Epoch: 62 ------>logloss: 1.214355372048358 ------> ------> Mse: 0.04960564300600221 \t \n",
            "Epoch: 63 ------>logloss: 0.7756970912651596 ------> ------> Mse: 0.04405084562870212 \t \n",
            "Epoch: 64 ------>logloss: 1.0506118658847685 ------> ------> Mse: 0.046504666907008475 \t \n",
            "Epoch: 65 ------>logloss: 1.27715226474191 ------> ------> Mse: 0.05045989228245307 \t \n",
            "Epoch: 66 ------>logloss: 0.9045486865986763 ------> ------> Mse: 0.046521326127762594 \t \n",
            "Epoch: 67 ------>logloss: nan ------> ------> Mse: 0.04456100002810723 \t \n",
            "Epoch: 68 ------>logloss: nan ------> ------> Mse: 0.04989814501394348 \t \n",
            "Epoch: 69 ------>logloss: nan ------> ------> Mse: 0.04772038450095235 \t \n",
            "Epoch: 70 ------>logloss: nan ------> ------> Mse: 0.04330828779543328 \t \n",
            "Epoch: 71 ------>logloss: nan ------> ------> Mse: 0.0570521633443997 \t \n",
            "Epoch: 72 ------>logloss: nan ------> ------> Mse: 0.05569255381837585 \t \n",
            "Epoch: 73 ------>logloss: 1.4951549824010284 ------> ------> Mse: 0.05995732234171771 \t \n",
            "Epoch: 74 ------>logloss: nan ------> ------> Mse: 0.055040938856100195 \t \n",
            "Epoch: 75 ------>logloss: 1.3336500396426267 ------> ------> Mse: 0.05481885863577848 \t \n",
            "Epoch: 76 ------>logloss: 0.9085004876256836 ------> ------> Mse: 0.04669980858210262 \t \n",
            "Epoch: 77 ------>logloss: 1.0268746786491982 ------> ------> Mse: 0.04927947202580319 \t \n",
            "Epoch: 78 ------>logloss: 1.4084083738712705 ------> ------> Mse: 0.05758573122747714 \t \n",
            "Epoch: 79 ------>logloss: 0.9832729449066575 ------> ------> Mse: 0.047976865405716045 \t \n",
            "Epoch: 80 ------>logloss: 1.065491210168556 ------> ------> Mse: 0.044984007088020535 \t \n",
            "Epoch: 81 ------>logloss: 1.036934193475283 ------> ------> Mse: 0.055715488052161796 \t \n",
            "Epoch: 82 ------>logloss: 0.9102925281730022 ------> ------> Mse: 0.05101994558608246 \t \n",
            "Epoch: 83 ------>logloss: 0.8719591544713914 ------> ------> Mse: 0.04572987005608117 \t \n",
            "Epoch: 84 ------>logloss: nan ------> ------> Mse: 0.04675710263421503 \t \n",
            "Epoch: 85 ------>logloss: nan ------> ------> Mse: 0.04667134058790777 \t \n",
            "Epoch: 86 ------>logloss: 1.230499759846735 ------> ------> Mse: 0.05077658331623194 \t \n",
            "Epoch: 87 ------>logloss: nan ------> ------> Mse: 0.05221241568246552 \t \n",
            "Epoch: 88 ------>logloss: nan ------> ------> Mse: 0.05553721704807462 \t \n",
            "Epoch: 89 ------>logloss: nan ------> ------> Mse: 0.043974072216393885 \t \n",
            "Epoch: 90 ------>logloss: nan ------> ------> Mse: 0.05762623279690648 \t \n",
            "Epoch: 91 ------>logloss: nan ------> ------> Mse: 0.053982636345467516 \t \n",
            "Epoch: 92 ------>logloss: nan ------> ------> Mse: 0.0488273054840125 \t \n",
            "Epoch: 93 ------>logloss: 0.8761287830605785 ------> ------> Mse: 0.047108985063637365 \t \n",
            "Epoch: 94 ------>logloss: nan ------> ------> Mse: 0.05421084354354103 \t \n",
            "Epoch: 95 ------>logloss: nan ------> ------> Mse: 0.05415389631141228 \t \n",
            "Epoch: 96 ------>logloss: 0.9453838727345153 ------> ------> Mse: 0.050279071386667415 \t \n",
            "Epoch: 97 ------>logloss: nan ------> ------> Mse: 0.05461975446696254 \t \n",
            "Epoch: 98 ------>logloss: nan ------> ------> Mse: 0.04792556388421225 \t \n",
            "Epoch: 99 ------>logloss: 1.4793713933593708 ------> ------> Mse: 0.06139666073905861 \t \n",
            "Converged through maximum epoch no criteria...\n",
            "Accuracy Score: 53.333333333333336\n",
            "Training Accuracy:  53.333333333333336\n",
            "Prescission Score: 53.333333333333336\n",
            "Recall Score :  53.333333333333336\n",
            "F1 Score :  53.333333333333336\n",
            "Confusion Matrix : \n",
            "[[ 0  0  5]\n",
            " [ 0  0  9]\n",
            " [ 0  0 16]]\n",
            "Classification Report for 3-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000         5\n",
            "           1      0.000     0.000     0.000         9\n",
            "           2      0.533     1.000     0.696        16\n",
            "\n",
            "    accuracy                          0.533        30\n",
            "   macro avg      0.178     0.333     0.232        30\n",
            "weighted avg      0.284     0.533     0.371        30\n",
            "\n",
            "Epoch: 0 ------>logloss: 0.4062795138746475 ------> ------> Mse: 0.027544419960141377 \t \n",
            "Epoch: 1 ------>logloss: 0.5621058879860182 ------> ------> Mse: 0.04351120981389113 \t \n",
            "Epoch: 2 ------>logloss: 0.9812461626772702 ------> ------> Mse: 0.04373520233430985 \t \n",
            "Epoch: 3 ------>logloss: 0.8493142585034901 ------> ------> Mse: 0.04067224306799011 \t \n",
            "Epoch: 4 ------>logloss: 0.8361915587852834 ------> ------> Mse: 0.0406359038262609 \t \n",
            "Epoch: 5 ------>logloss: 0.8294100363246446 ------> ------> Mse: 0.04043859282178864 \t \n",
            "Epoch: 6 ------>logloss: 0.826342808132113 ------> ------> Mse: 0.03968057929528815 \t \n",
            "Epoch: 7 ------>logloss: 0.8266257703004439 ------> ------> Mse: 0.03832587464684327 \t \n",
            "Epoch: 8 ------>logloss: 0.9183671929030227 ------> ------> Mse: 0.04472785124374161 \t \n",
            "Epoch: 9 ------>logloss: 0.5359537296465007 ------> ------> Mse: 0.032738710626274266 \t \n",
            "Epoch: 10 ------>logloss: 0.8217148999712082 ------> ------> Mse: 0.041191663577347465 \t \n",
            "Epoch: 11 ------>logloss: 0.8225305521047439 ------> ------> Mse: 0.04117290230953733 \t \n",
            "Epoch: 12 ------>logloss: 0.826469967091582 ------> ------> Mse: 0.041139226840350755 \t \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 ------>logloss: 0.836781538896885 ------> ------> Mse: 0.04138874902749115 \t \n",
            "Epoch: 14 ------>logloss: 0.8592353401727452 ------> ------> Mse: 0.04307311075163384 \t \n",
            "Epoch: 15 ------>logloss: 0.992275496475817 ------> ------> Mse: 0.049314633323946484 \t \n",
            "Epoch: 16 ------>logloss: 1.0546112607696612 ------> ------> Mse: 0.049415349447304226 \t \n",
            "Epoch: 17 ------>logloss: 0.5232675205899818 ------> ------> Mse: 0.03279259624962207 \t \n",
            "Epoch: 18 ------>logloss: 0.818458762858129 ------> ------> Mse: 0.04145601010982217 \t \n",
            "Epoch: 19 ------>logloss: 0.8184619138979434 ------> ------> Mse: 0.041418710107311026 \t \n",
            "Epoch: 20 ------>logloss: 0.8205483677620549 ------> ------> Mse: 0.0412918818993293 \t \n",
            "Epoch: 21 ------>logloss: 0.8271172909098197 ------> ------> Mse: 0.04102024965050377 \t \n",
            "Epoch: 22 ------>logloss: 0.8431974503122112 ------> ------> Mse: 0.04083386171953537 \t \n",
            "Epoch: 23 ------>logloss: 0.8780714768718563 ------> ------> Mse: 0.04266687643718788 \t \n",
            "Epoch: 24 ------>logloss: 0.8834176504115214 ------> ------> Mse: 0.041937927822753567 \t \n",
            "Epoch: 25 ------>logloss: 0.962038444010157 ------> ------> Mse: 0.04531415782660586 \t \n",
            "Epoch: 26 ------>logloss: 0.8225981144790644 ------> ------> Mse: 0.0405339068430066 \t \n",
            "Epoch: 27 ------>logloss: 0.833694926571566 ------> ------> Mse: 0.03973205174287251 \t \n",
            "Epoch: 28 ------>logloss: 0.793759488953132 ------> ------> Mse: 0.04187290868499774 \t \n",
            "Epoch: 29 ------>logloss: 1.0068184538824958 ------> ------> Mse: 0.05033661739097951 \t \n",
            "Epoch: 30 ------>logloss: 0.811327389080556 ------> ------> Mse: 0.040488313006684394 \t \n",
            "Epoch: 31 ------>logloss: 0.8159003410160245 ------> ------> Mse: 0.03912696050423616 \t \n",
            "Epoch: 32 ------>logloss: 0.7651546793191778 ------> ------> Mse: 0.039310910722385434 \t \n",
            "Epoch: 33 ------>logloss: 0.8333337324298989 ------> ------> Mse: 0.04255395007814359 \t \n",
            "Epoch: 34 ------>logloss: 0.9694918572065442 ------> ------> Mse: 0.049226246133031025 \t \n",
            "Epoch: 35 ------>logloss: 0.9461079581853777 ------> ------> Mse: 0.04352799904178853 \t \n",
            "Epoch: 36 ------>logloss: 0.7536124204415656 ------> ------> Mse: 0.03945314747045507 \t \n",
            "Epoch: 37 ------>logloss: 0.8071964446655665 ------> ------> Mse: 0.04132838502094153 \t \n",
            "Epoch: 38 ------>logloss: 0.8074367065004256 ------> ------> Mse: 0.040832167736077056 \t \n",
            "Epoch: 39 ------>logloss: 0.8106450692340271 ------> ------> Mse: 0.03969581514176263 \t \n",
            "Epoch: 40 ------>logloss: 0.7599989500150881 ------> ------> Mse: 0.039892637199555776 \t \n",
            "Epoch: 41 ------>logloss: 0.8280969423127196 ------> ------> Mse: 0.04237420054066988 \t \n",
            "Epoch: 42 ------>logloss: 0.8563789902682498 ------> ------> Mse: 0.04536488159415768 \t \n",
            "Epoch: 43 ------>logloss: 0.9892211192412872 ------> ------> Mse: 0.047414835850371054 \t \n",
            "Epoch: 44 ------>logloss: 0.753155669223088 ------> ------> Mse: 0.04011123988262121 \t \n",
            "Epoch: 45 ------>logloss: 0.8184458400426882 ------> ------> Mse: 0.042396569415996614 \t \n",
            "Epoch: 46 ------>logloss: 0.9394736272429097 ------> ------> Mse: 0.046380070891799526 \t \n",
            "Epoch: 47 ------>logloss: 0.9421953407452199 ------> ------> Mse: 0.046303056197506805 \t \n",
            "Epoch: 48 ------>logloss: 0.9500613628449214 ------> ------> Mse: 0.04283090956456441 \t \n",
            "Epoch: 49 ------>logloss: 0.8875877371178791 ------> ------> Mse: 0.04335863540419737 \t \n",
            "Epoch: 50 ------>logloss: 0.5267779383089254 ------> ------> Mse: 0.033174173553449524 \t \n",
            "Epoch: 51 ------>logloss: 0.8030415474214662 ------> ------> Mse: 0.0414650069481209 \t \n",
            "Epoch: 52 ------>logloss: 0.8081468650619354 ------> ------> Mse: 0.041664754436024666 \t \n",
            "Epoch: 53 ------>logloss: 0.8209490936178145 ------> ------> Mse: 0.04259062847826555 \t \n",
            "Epoch: 54 ------>logloss: 0.9390392250839417 ------> ------> Mse: 0.04644617840168238 \t \n",
            "Epoch: 55 ------>logloss: 0.9379955199270924 ------> ------> Mse: 0.04685678383058457 \t \n",
            "Epoch: 56 ------>logloss: 0.9573388925928584 ------> ------> Mse: 0.042920492618427376 \t \n",
            "Epoch: 57 ------>logloss: 0.8956002593346385 ------> ------> Mse: 0.04407077601145701 \t \n",
            "Epoch: 58 ------>logloss: 0.5357467794037098 ------> ------> Mse: 0.03478634644839363 \t \n",
            "Epoch: 59 ------>logloss: 1.0357723347470058 ------> ------> Mse: 0.05129106248736095 \t \n",
            "Epoch: 60 ------>logloss: 0.7966764272259793 ------> ------> Mse: 0.04152077863622424 \t \n",
            "Epoch: 61 ------>logloss: 0.7946474948428752 ------> ------> Mse: 0.04140859365737985 \t \n",
            "Epoch: 62 ------>logloss: 0.7943745130939779 ------> ------> Mse: 0.04102146326448597 \t \n",
            "Epoch: 63 ------>logloss: 0.7971031651315592 ------> ------> Mse: 0.04010103870874868 \t \n",
            "Epoch: 64 ------>logloss: 0.8057172091465611 ------> ------> Mse: 0.03899050456982105 \t \n",
            "Epoch: 65 ------>logloss: 1.0335788304927072 ------> ------> Mse: 0.04920220866148807 \t \n",
            "Epoch: 66 ------>logloss: 0.6490385170537049 ------> ------> Mse: 0.038042144607574414 \t \n",
            "Epoch: 67 ------>logloss: 0.943106341395363 ------> ------> Mse: 0.046924598232334955 \t \n",
            "Epoch: 68 ------>logloss: 0.9432018257956116 ------> ------> Mse: 0.04705715487046721 \t \n",
            "Epoch: 69 ------>logloss: 0.9229813707206828 ------> ------> Mse: 0.04565587317888627 \t \n",
            "Epoch: 70 ------>logloss: 0.9357210242023013 ------> ------> Mse: 0.047363214782023204 \t \n",
            "Epoch: 71 ------>logloss: 0.938448102636403 ------> ------> Mse: 0.044199458121531345 \t \n",
            "Epoch: 72 ------>logloss: 0.7982111804521427 ------> ------> Mse: 0.03854773228321399 \t \n",
            "Epoch: 73 ------>logloss: 0.7389549413859855 ------> ------> Mse: 0.038558849839766526 \t \n",
            "Epoch: 74 ------>logloss: 0.7920845381829157 ------> ------> Mse: 0.04112236839627462 \t \n",
            "Epoch: 75 ------>logloss: 0.797668602318698 ------> ------> Mse: 0.04043104628935766 \t \n",
            "Epoch: 76 ------>logloss: 0.8118607443116473 ------> ------> Mse: 0.03988497891880945 \t \n",
            "Epoch: 77 ------>logloss: 0.9051584868998426 ------> ------> Mse: 0.046495565233714786 \t \n",
            "Epoch: 78 ------>logloss: 0.9565052512685476 ------> ------> Mse: 0.04875958572663707 \t \n",
            "Epoch: 79 ------>logloss: 0.9156791879414823 ------> ------> Mse: 0.04361973289126954 \t \n",
            "Epoch: 80 ------>logloss: 0.9155710628606847 ------> ------> Mse: 0.0435925846737173 \t \n",
            "Epoch: 81 ------>logloss: 0.8810968669085643 ------> ------> Mse: 0.043349434222000764 \t \n",
            "Epoch: 82 ------>logloss: 0.790586167300861 ------> ------> Mse: 0.04131068615146393 \t \n",
            "Epoch: 83 ------>logloss: 0.7954646664999192 ------> ------> Mse: 0.041102856450754954 \t \n",
            "Epoch: 84 ------>logloss: 0.8083441304099618 ------> ------> Mse: 0.041211058859369286 \t \n",
            "Epoch: 85 ------>logloss: 0.9820499011696934 ------> ------> Mse: 0.05039939325569986 \t \n",
            "Epoch: 86 ------>logloss: 0.7898090558790581 ------> ------> Mse: 0.04148713678781034 \t \n",
            "Epoch: 87 ------>logloss: 0.7853899784344763 ------> ------> Mse: 0.04078767537116065 \t \n",
            "Epoch: 88 ------>logloss: 0.7849418965107471 ------> ------> Mse: 0.03953760085838563 \t \n",
            "Epoch: 89 ------>logloss: 0.7298534728113868 ------> ------> Mse: 0.039760856116441784 \t \n",
            "Epoch: 90 ------>logloss: 0.7880721598242949 ------> ------> Mse: 0.041899448318242445 \t \n",
            "Epoch: 91 ------>logloss: 0.9311915602399825 ------> ------> Mse: 0.04648829353383568 \t \n",
            "Epoch: 92 ------>logloss: 0.932468876726598 ------> ------> Mse: 0.04552771265559511 \t \n",
            "Epoch: 93 ------>logloss: 0.8773413612603581 ------> ------> Mse: 0.04578717705567922 \t \n",
            "Epoch: 94 ------>logloss: 0.9030440603584731 ------> ------> Mse: 0.044413671671117864 \t \n",
            "Epoch: 95 ------>logloss: 0.8977004979353143 ------> ------> Mse: 0.04432952804042886 \t \n",
            "Epoch: 96 ------>logloss: 0.9192745635595074 ------> ------> Mse: 0.046912006171922885 \t \n",
            "Epoch: 97 ------>logloss: 0.9391251721480931 ------> ------> Mse: 0.04269815144949286 \t \n",
            "Epoch: 98 ------>logloss: 0.8015528015168816 ------> ------> Mse: 0.041723870396789 \t \n",
            "Epoch: 99 ------>logloss: 0.7307077613455326 ------> ------> Mse: 0.039405597314526065 \t \n",
            "Converged through maximum epoch no criteria...\n",
            "Accuracy Score: 23.333333333333332\n",
            "Training Accuracy:  23.333333333333332\n",
            "Prescission Score: 23.333333333333332\n",
            "Recall Score :  23.333333333333332\n",
            "F1 Score :  23.333333333333332\n",
            "Confusion Matrix : \n",
            "[[ 0  0 11]\n",
            " [ 0  0 12]\n",
            " [ 0  0  7]]\n",
            "Classification Report for 3-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000        11\n",
            "           1      0.000     0.000     0.000        12\n",
            "           2      0.233     1.000     0.378         7\n",
            "\n",
            "    accuracy                          0.233        30\n",
            "   macro avg      0.078     0.333     0.126        30\n",
            "weighted avg      0.054     0.233     0.088        30\n",
            "\n",
            "Epoch: 0 ------>logloss: 0.36095387079543617 ------> ------> Mse: 0.025654915944458106 \t \n",
            "Epoch: 1 ------>logloss: 1.0357183702936659 ------> ------> Mse: 0.051873434448412734 \t \n",
            "Epoch: 2 ------>logloss: 0.5579856456045228 ------> ------> Mse: 0.03324187125000527 \t \n",
            "Epoch: 3 ------>logloss: 0.8141719575229326 ------> ------> Mse: 0.038462957763765106 \t \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 ------>logloss: 0.3470612204693954 ------> ------> Mse: 0.028102225688579306 \t \n",
            "Epoch: 5 ------>logloss: 0.6696085906267114 ------> ------> Mse: 0.03888195794102583 \t \n",
            "Epoch: 6 ------>logloss: 0.7413439545911324 ------> ------> Mse: 0.050161478019443734 \t \n",
            "Epoch: 7 ------>logloss: 0.8643939077530083 ------> ------> Mse: 0.050599618398933385 \t \n",
            "Epoch: 8 ------>logloss: nan ------> ------> Mse: 0.03971936711708845 \t \n",
            "Epoch: 9 ------>logloss: nan ------> ------> Mse: 0.03961993725266382 \t \n",
            "Epoch: 10 ------>logloss: nan ------> ------> Mse: 0.0425520932273382 \t \n",
            "Epoch: 11 ------>logloss: 0.7577764783651318 ------> ------> Mse: 0.04587154403005405 \t \n",
            "Epoch: 12 ------>logloss: nan ------> ------> Mse: 0.06914273202921034 \t \n",
            "Epoch: 13 ------>logloss: nan ------> ------> Mse: 0.05499719753499399 \t \n",
            "Epoch: 14 ------>logloss: nan ------> ------> Mse: 0.04018021858663792 \t \n",
            "Epoch: 15 ------>logloss: nan ------> ------> Mse: 0.041426294027826986 \t \n",
            "Epoch: 16 ------>logloss: nan ------> ------> Mse: 0.04672595925275862 \t \n",
            "Epoch: 17 ------>logloss: nan ------> ------> Mse: 0.04770994939028321 \t \n",
            "Epoch: 18 ------>logloss: nan ------> ------> Mse: 0.044048882601891104 \t \n",
            "Epoch: 19 ------>logloss: 1.329820140801103 ------> ------> Mse: 0.06980042353701126 \t \n",
            "Epoch: 20 ------>logloss: nan ------> ------> Mse: 0.03993587332838467 \t \n",
            "Epoch: 21 ------>logloss: nan ------> ------> Mse: 0.041240639247731685 \t \n",
            "Epoch: 22 ------>logloss: nan ------> ------> Mse: 0.04939768873294523 \t \n",
            "Epoch: 23 ------>logloss: nan ------> ------> Mse: 0.04163329263598251 \t \n",
            "Epoch: 24 ------>logloss: nan ------> ------> Mse: 0.04685279184741469 \t \n",
            "Epoch: 25 ------>logloss: nan ------> ------> Mse: 0.06823758506667144 \t \n",
            "Epoch: 26 ------>logloss: nan ------> ------> Mse: 0.055102180673737 \t \n",
            "Epoch: 27 ------>logloss: nan ------> ------> Mse: 0.040606603774334386 \t \n",
            "Epoch: 28 ------>logloss: nan ------> ------> Mse: 0.039995594420576576 \t \n",
            "Epoch: 29 ------>logloss: nan ------> ------> Mse: 0.04299600962745948 \t \n",
            "Epoch: 30 ------>logloss: 1.1707848075391278 ------> ------> Mse: 0.06300343539303453 \t \n",
            "Epoch: 31 ------>logloss: nan ------> ------> Mse: 0.05161427567617813 \t \n",
            "Epoch: 32 ------>logloss: nan ------> ------> Mse: 0.05145837656017961 \t \n",
            "Epoch: 33 ------>logloss: nan ------> ------> Mse: 0.04663097984546538 \t \n",
            "Epoch: 34 ------>logloss: nan ------> ------> Mse: 0.05013325745168915 \t \n",
            "Epoch: 35 ------>logloss: nan ------> ------> Mse: 0.04113330232102725 \t \n",
            "Epoch: 36 ------>logloss: nan ------> ------> Mse: 0.04986342562891098 \t \n",
            "Epoch: 37 ------>logloss: nan ------> ------> Mse: 0.049589073479051796 \t \n",
            "Epoch: 38 ------>logloss: nan ------> ------> Mse: 0.05355862990725851 \t \n",
            "Epoch: 39 ------>logloss: nan ------> ------> Mse: 0.057637891015315204 \t \n",
            "Epoch: 40 ------>logloss: nan ------> ------> Mse: 0.058136404997249695 \t \n",
            "Epoch: 41 ------>logloss: nan ------> ------> Mse: 0.049616923675333484 \t \n",
            "Epoch: 42 ------>logloss: 1.1632370939047567 ------> ------> Mse: 0.057995242918591344 \t \n",
            "Epoch: 43 ------>logloss: nan ------> ------> Mse: 0.05130229394782296 \t \n",
            "Epoch: 44 ------>logloss: nan ------> ------> Mse: 0.04989429613199724 \t \n",
            "Epoch: 45 ------>logloss: nan ------> ------> Mse: 0.051081721090142446 \t \n",
            "Epoch: 46 ------>logloss: nan ------> ------> Mse: 0.0465958949704084 \t \n",
            "Epoch: 47 ------>logloss: nan ------> ------> Mse: 0.05301884579008191 \t \n",
            "Epoch: 48 ------>logloss: nan ------> ------> Mse: 0.05300466750418564 \t \n",
            "Epoch: 49 ------>logloss: nan ------> ------> Mse: 0.05773382765250014 \t \n",
            "Epoch: 50 ------>logloss: nan ------> ------> Mse: 0.05475253809406563 \t \n",
            "Epoch: 51 ------>logloss: nan ------> ------> Mse: 0.06107260881510585 \t \n",
            "Epoch: 52 ------>logloss: nan ------> ------> Mse: 0.06845856622475079 \t \n",
            "Epoch: 53 ------>logloss: nan ------> ------> Mse: 0.04824630357147503 \t \n",
            "Epoch: 54 ------>logloss: 1.1222889762858044 ------> ------> Mse: 0.05004875372199043 \t \n",
            "Epoch: 55 ------>logloss: nan ------> ------> Mse: 0.057806073379052685 \t \n",
            "Epoch: 56 ------>logloss: nan ------> ------> Mse: 0.04984432418958161 \t \n",
            "Epoch: 57 ------>logloss: 1.1411943527691155 ------> ------> Mse: 0.05509583189687426 \t \n",
            "Epoch: 58 ------>logloss: nan ------> ------> Mse: 0.0505882094059992 \t \n",
            "Epoch: 59 ------>logloss: nan ------> ------> Mse: 0.052045766512654086 \t \n",
            "Epoch: 60 ------>logloss: nan ------> ------> Mse: 0.050518734593490204 \t \n",
            "Epoch: 61 ------>logloss: nan ------> ------> Mse: 0.046228526055996415 \t \n",
            "Epoch: 62 ------>logloss: nan ------> ------> Mse: 0.04719555959834924 \t \n",
            "Epoch: 63 ------>logloss: nan ------> ------> Mse: 0.05889722517043456 \t \n",
            "Epoch: 64 ------>logloss: nan ------> ------> Mse: 0.05837877234485858 \t \n",
            "Epoch: 65 ------>logloss: nan ------> ------> Mse: 0.05558305648847916 \t \n",
            "Epoch: 66 ------>logloss: nan ------> ------> Mse: 0.04885154445136726 \t \n",
            "Epoch: 67 ------>logloss: nan ------> ------> Mse: 0.05577521879068786 \t \n",
            "Epoch: 68 ------>logloss: nan ------> ------> Mse: 0.05450079869605522 \t \n",
            "Epoch: 69 ------>logloss: nan ------> ------> Mse: 0.06536643492322958 \t \n",
            "Epoch: 70 ------>logloss: nan ------> ------> Mse: 0.06320162657162447 \t \n",
            "Epoch: 71 ------>logloss: nan ------> ------> Mse: 0.06113167231322117 \t \n",
            "Epoch: 72 ------>logloss: nan ------> ------> Mse: 0.038838060007915835 \t \n",
            "Epoch: 73 ------>logloss: 0.9931705644618126 ------> ------> Mse: 0.04653336083499126 \t \n",
            "Epoch: 74 ------>logloss: nan ------> ------> Mse: 0.048099503910852576 \t \n",
            "Epoch: 75 ------>logloss: nan ------> ------> Mse: 0.049715877281028026 \t \n",
            "Epoch: 76 ------>logloss: 0.9438939003824662 ------> ------> Mse: 0.048576035780358254 \t \n",
            "Epoch: 77 ------>logloss: nan ------> ------> Mse: 0.04251112044892811 \t \n",
            "Epoch: 78 ------>logloss: nan ------> ------> Mse: 0.05326944074367549 \t \n",
            "Epoch: 79 ------>logloss: nan ------> ------> Mse: 0.06427713355203481 \t \n",
            "Epoch: 80 ------>logloss: nan ------> ------> Mse: 0.050131987572680205 \t \n",
            "Epoch: 81 ------>logloss: nan ------> ------> Mse: 0.05537577552056031 \t \n",
            "Epoch: 82 ------>logloss: nan ------> ------> Mse: 0.050141789606348894 \t \n",
            "Epoch: 83 ------>logloss: nan ------> ------> Mse: 0.05731905650528239 \t \n",
            "Epoch: 84 ------>logloss: nan ------> ------> Mse: 0.06530747608568255 \t \n",
            "Epoch: 85 ------>logloss: nan ------> ------> Mse: 0.06330615038157218 \t \n",
            "Epoch: 86 ------>logloss: nan ------> ------> Mse: 0.05671754438141598 \t \n",
            "Epoch: 87 ------>logloss: nan ------> ------> Mse: 0.057652398825281136 \t \n",
            "Epoch: 88 ------>logloss: nan ------> ------> Mse: 0.055994101410038945 \t \n",
            "Epoch: 89 ------>logloss: nan ------> ------> Mse: 0.04894731268849955 \t \n",
            "Epoch: 90 ------>logloss: nan ------> ------> Mse: 0.04587199984170672 \t \n",
            "Epoch: 91 ------>logloss: nan ------> ------> Mse: 0.05499624481851992 \t \n",
            "Epoch: 92 ------>logloss: nan ------> ------> Mse: 0.051023272634112674 \t \n",
            "Epoch: 93 ------>logloss: nan ------> ------> Mse: 0.04461836316645962 \t \n",
            "Epoch: 94 ------>logloss: 1.6431420584563383 ------> ------> Mse: 0.058589503758688447 \t \n",
            "Epoch: 95 ------>logloss: nan ------> ------> Mse: 0.05995040329343373 \t \n",
            "Epoch: 96 ------>logloss: nan ------> ------> Mse: 0.04968024780431808 \t \n",
            "Epoch: 97 ------>logloss: 1.1489755077618298 ------> ------> Mse: 0.05473962472928488 \t \n",
            "Epoch: 98 ------>logloss: nan ------> ------> Mse: 0.05864128769548851 \t \n",
            "Epoch: 99 ------>logloss: nan ------> ------> Mse: 0.058386027810163596 \t \n",
            "Converged through maximum epoch no criteria...\n",
            "Accuracy Score: 43.333333333333336\n",
            "Training Accuracy:  43.333333333333336\n",
            "Prescission Score: 43.333333333333336\n",
            "Recall Score :  43.333333333333336\n",
            "F1 Score :  43.333333333333336\n",
            "Confusion Matrix : \n",
            "[[ 0  0 12]\n",
            " [ 0  0  5]\n",
            " [ 0  0 13]]\n",
            "Classification Report for 3-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000        12\n",
            "           1      0.000     0.000     0.000         5\n",
            "           2      0.433     1.000     0.605        13\n",
            "\n",
            "    accuracy                          0.433        30\n",
            "   macro avg      0.144     0.333     0.202        30\n",
            "weighted avg      0.188     0.433     0.262        30\n",
            "\n",
            "Epoch: 0 ------>logloss: 0.49381526133996123 ------> ------> Mse: 0.04256012859651519 \t \n",
            "Epoch: 1 ------>logloss: 0.8412408937271233 ------> ------> Mse: 0.06866843407681426 \t \n",
            "Epoch: 2 ------>logloss: 0.8310504795702204 ------> ------> Mse: 0.034467595126937714 \t \n",
            "Epoch: 3 ------>logloss: 1.019489486553035 ------> ------> Mse: 0.0496447655340009 \t \n",
            "Epoch: 4 ------>logloss: 0.7401955919685146 ------> ------> Mse: 0.043995785377772455 \t \n",
            "Epoch: 5 ------>logloss: 0.5356992187691532 ------> ------> Mse: 0.03334966081059135 \t \n",
            "Epoch: 6 ------>logloss: 1.1102237328887923 ------> ------> Mse: 0.04442198764292297 \t \n",
            "Epoch: 7 ------>logloss: nan ------> ------> Mse: 0.05180014215780507 \t \n",
            "Epoch: 8 ------>logloss: 0.8388552545857217 ------> ------> Mse: 0.04554523768383829 \t \n",
            "Epoch: 9 ------>logloss: 1.0856249716352726 ------> ------> Mse: 0.05327263556310607 \t \n",
            "Epoch: 10 ------>logloss: 0.9910987687227094 ------> ------> Mse: 0.05069539986507164 \t \n",
            "Epoch: 11 ------>logloss: 1.092459085251337 ------> ------> Mse: 0.050156006745859884 \t \n",
            "Epoch: 12 ------>logloss: 1.065028187741911 ------> ------> Mse: 0.04446581834580135 \t \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 ------>logloss: 1.018094857682736 ------> ------> Mse: 0.048055286134289665 \t \n",
            "Epoch: 14 ------>logloss: 1.1938188421629055 ------> ------> Mse: 0.052707255728688326 \t \n",
            "Epoch: 15 ------>logloss: nan ------> ------> Mse: 0.052370231452833566 \t \n",
            "Epoch: 16 ------>logloss: 1.2778582952674828 ------> ------> Mse: 0.051528576292266634 \t \n",
            "Epoch: 17 ------>logloss: 1.0402536323022291 ------> ------> Mse: 0.04855125558567915 \t \n",
            "Epoch: 18 ------>logloss: 1.0536059019226687 ------> ------> Mse: 0.04838279200379901 \t \n",
            "Epoch: 19 ------>logloss: 0.9065173393647861 ------> ------> Mse: 0.046198445854068466 \t \n",
            "Epoch: 20 ------>logloss: 1.0526107434049774 ------> ------> Mse: 0.04807965677073487 \t \n",
            "Epoch: 21 ------>logloss: 1.0510858305669715 ------> ------> Mse: 0.04659608890406997 \t \n",
            "Epoch: 22 ------>logloss: 1.3068124542971438 ------> ------> Mse: 0.05056785359265232 \t \n",
            "Epoch: 23 ------>logloss: 1.0302919401310122 ------> ------> Mse: 0.04993492788412734 \t \n",
            "Epoch: 24 ------>logloss: 0.9647812953452437 ------> ------> Mse: 0.045650434160969075 \t \n",
            "Epoch: 25 ------>logloss: 1.124764164805209 ------> ------> Mse: 0.04797686435095916 \t \n",
            "Epoch: 26 ------>logloss: nan ------> ------> Mse: 0.0521818104424495 \t \n",
            "Epoch: 27 ------>logloss: 1.0367032570939607 ------> ------> Mse: 0.045529263310240875 \t \n",
            "Epoch: 28 ------>logloss: nan ------> ------> Mse: 0.050650539029510486 \t \n",
            "Epoch: 29 ------>logloss: 1.025754842526132 ------> ------> Mse: 0.05008505625874208 \t \n",
            "Epoch: 30 ------>logloss: 0.964933697515782 ------> ------> Mse: 0.045111731782631455 \t \n",
            "Epoch: 31 ------>logloss: 1.1558876336696808 ------> ------> Mse: 0.051787699518714 \t \n",
            "Epoch: 32 ------>logloss: nan ------> ------> Mse: 0.05344274225974384 \t \n",
            "Epoch: 33 ------>logloss: 1.0467415752841551 ------> ------> Mse: 0.04781440482588653 \t \n",
            "Epoch: 34 ------>logloss: nan ------> ------> Mse: 0.05589827847742016 \t \n",
            "Epoch: 35 ------>logloss: 1.1708419990744623 ------> ------> Mse: 0.05340350224149248 \t \n",
            "Epoch: 36 ------>logloss: 1.1087600644045084 ------> ------> Mse: 0.05124946918020815 \t \n",
            "Epoch: 37 ------>logloss: 1.356617292963271 ------> ------> Mse: 0.05350497391649711 \t \n",
            "Epoch: 38 ------>logloss: nan ------> ------> Mse: 0.05401086660639399 \t \n",
            "Epoch: 39 ------>logloss: 1.0157902725476928 ------> ------> Mse: 0.041299249419398026 \t \n",
            "Epoch: 40 ------>logloss: nan ------> ------> Mse: 0.051148477877637925 \t \n",
            "Epoch: 41 ------>logloss: 1.066209046562592 ------> ------> Mse: 0.04789494682621488 \t \n",
            "Epoch: 42 ------>logloss: 1.0277920491977526 ------> ------> Mse: 0.04639788609751483 \t \n",
            "Epoch: 43 ------>logloss: 1.2717496091239475 ------> ------> Mse: 0.05185377330377071 \t \n",
            "Epoch: 44 ------>logloss: 1.0091059617777354 ------> ------> Mse: 0.047889560331203854 \t \n",
            "Epoch: 45 ------>logloss: 1.0442349161124895 ------> ------> Mse: 0.04702262878168019 \t \n",
            "Epoch: 46 ------>logloss: 1.2355783752674998 ------> ------> Mse: 0.05465640966861263 \t \n",
            "Epoch: 47 ------>logloss: 1.0785921309786513 ------> ------> Mse: 0.04950908535051201 \t \n",
            "Epoch: 48 ------>logloss: nan ------> ------> Mse: 0.04849792088035295 \t \n",
            "Epoch: 49 ------>logloss: 1.3460102714757007 ------> ------> Mse: 0.05284487942247117 \t \n",
            "Epoch: 50 ------>logloss: nan ------> ------> Mse: 0.052196707424136145 \t \n",
            "Epoch: 51 ------>logloss: 1.0146362249028826 ------> ------> Mse: 0.042338545959647714 \t \n",
            "Epoch: 52 ------>logloss: nan ------> ------> Mse: 0.050227357228952316 \t \n",
            "Epoch: 53 ------>logloss: 1.0612775005133837 ------> ------> Mse: 0.04877170454899033 \t \n",
            "Epoch: 54 ------>logloss: 0.9491122791788444 ------> ------> Mse: 0.04529294768701399 \t \n",
            "Epoch: 55 ------>logloss: 1.0651919613130163 ------> ------> Mse: 0.04582980707582627 \t \n",
            "Epoch: 56 ------>logloss: nan ------> ------> Mse: 0.05400363275542875 \t \n",
            "Epoch: 57 ------>logloss: 1.04954046889185 ------> ------> Mse: 0.0439938624922771 \t \n",
            "Epoch: 58 ------>logloss: nan ------> ------> Mse: 0.05279962470872824 \t \n",
            "Epoch: 59 ------>logloss: 1.2032460340418558 ------> ------> Mse: 0.056441765094356305 \t \n",
            "Epoch: 60 ------>logloss: 1.0173217115453552 ------> ------> Mse: 0.04830624865712543 \t \n",
            "Epoch: 61 ------>logloss: 1.3421788689100678 ------> ------> Mse: 0.05386754727916179 \t \n",
            "Epoch: 62 ------>logloss: 1.2611078744023665 ------> ------> Mse: 0.05386894763135354 \t \n",
            "Epoch: 63 ------>logloss: 1.004561266797259 ------> ------> Mse: 0.04434650078175171 \t \n",
            "Epoch: 64 ------>logloss: 1.0738858781460487 ------> ------> Mse: 0.04910522080498569 \t \n",
            "Epoch: 65 ------>logloss: nan ------> ------> Mse: 0.05440040630846479 \t \n",
            "Epoch: 66 ------>logloss: 0.9649669478806844 ------> ------> Mse: 0.0460210204308792 \t \n",
            "Epoch: 67 ------>logloss: 1.0412629891216643 ------> ------> Mse: 0.04774743192672536 \t \n",
            "Epoch: 68 ------>logloss: 1.185040117110337 ------> ------> Mse: 0.05256342690322136 \t \n",
            "Epoch: 69 ------>logloss: 1.230665566534717 ------> ------> Mse: 0.049674180974736935 \t \n",
            "Epoch: 70 ------>logloss: 0.9670119472243136 ------> ------> Mse: 0.04617035287388975 \t \n",
            "Epoch: 71 ------>logloss: 1.0536174498872741 ------> ------> Mse: 0.04712312650130604 \t \n",
            "Epoch: 72 ------>logloss: 0.9872369985489979 ------> ------> Mse: 0.042425894619625405 \t \n",
            "Epoch: 73 ------>logloss: 1.0753026790313949 ------> ------> Mse: 0.04718953717862914 \t \n",
            "Epoch: 74 ------>logloss: 1.1171581518531633 ------> ------> Mse: 0.04827885763953293 \t \n",
            "Epoch: 75 ------>logloss: 0.9751712661534483 ------> ------> Mse: 0.044984173162879455 \t \n",
            "Epoch: 76 ------>logloss: 1.035839050115627 ------> ------> Mse: 0.04620939806637398 \t \n",
            "Epoch: 77 ------>logloss: 1.069418000947255 ------> ------> Mse: 0.04749770044404713 \t \n",
            "Epoch: 78 ------>logloss: 1.007132923395625 ------> ------> Mse: 0.04190941503803446 \t \n",
            "Epoch: 79 ------>logloss: 1.1053070852964926 ------> ------> Mse: 0.04869013102035204 \t \n",
            "Epoch: 80 ------>logloss: 1.150463440956133 ------> ------> Mse: 0.051501182299298655 \t \n",
            "Epoch: 81 ------>logloss: nan ------> ------> Mse: 0.05075829387339757 \t \n",
            "Epoch: 82 ------>logloss: 1.0400886601998265 ------> ------> Mse: 0.04737870741082332 \t \n",
            "Epoch: 83 ------>logloss: 1.2849139838979549 ------> ------> Mse: 0.05316407445556661 \t \n",
            "Epoch: 84 ------>logloss: 0.8886132240578761 ------> ------> Mse: 0.04385032525783642 \t \n",
            "Epoch: 85 ------>logloss: 1.0573797387498762 ------> ------> Mse: 0.04793382561350688 \t \n",
            "Epoch: 86 ------>logloss: 1.0439913713446238 ------> ------> Mse: 0.046400903076982615 \t \n",
            "Epoch: 87 ------>logloss: 1.0418944433960413 ------> ------> Mse: 0.046163865840053685 \t \n",
            "Epoch: 88 ------>logloss: 0.7862891768370077 ------> ------> Mse: 0.037363240841294734 \t \n",
            "Epoch: 89 ------>logloss: 1.0027814108302573 ------> ------> Mse: 0.046392266311319166 \t \n",
            "Epoch: 90 ------>logloss: 0.9843338727506876 ------> ------> Mse: 0.046260686013535834 \t \n",
            "Epoch: 91 ------>logloss: 1.0620221044110882 ------> ------> Mse: 0.047369884450910456 \t \n",
            "Epoch: 92 ------>logloss: 1.0411718935257153 ------> ------> Mse: 0.04641411000713171 \t \n",
            "Epoch: 93 ------>logloss: 0.8100213237512327 ------> ------> Mse: 0.038188140896805396 \t \n",
            "Epoch: 94 ------>logloss: 1.0860061408836337 ------> ------> Mse: 0.047599156299755654 \t \n",
            "Epoch: 95 ------>logloss: 0.9686405977235945 ------> ------> Mse: 0.0449859835025537 \t \n",
            "Epoch: 96 ------>logloss: 1.0659363760494722 ------> ------> Mse: 0.04567062242303387 \t \n",
            "Epoch: 97 ------>logloss: nan ------> ------> Mse: 0.05972435836973153 \t \n",
            "Epoch: 98 ------>logloss: 1.0989600677125273 ------> ------> Mse: 0.04862056246005996 \t \n",
            "Epoch: 99 ------>logloss: 1.0644649378461368 ------> ------> Mse: 0.047686358156361956 \t \n",
            "Converged through maximum epoch no criteria...\n",
            "Accuracy Score: 16.666666666666664\n",
            "Training Accuracy:  16.666666666666664\n",
            "Prescission Score: 16.666666666666664\n",
            "Recall Score :  16.666666666666664\n",
            "F1 Score :  16.666666666666664\n",
            "Confusion Matrix : \n",
            "[[ 0  0 13]\n",
            " [ 0  0 12]\n",
            " [ 0  0  5]]\n",
            "Classification Report for 3-classes: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.000     0.000     0.000        13\n",
            "           1      0.000     0.000     0.000        12\n",
            "           2      0.167     1.000     0.286         5\n",
            "\n",
            "    accuracy                          0.167        30\n",
            "   macro avg      0.056     0.333     0.095        30\n",
            "weighted avg      0.028     0.167     0.048        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9aXti-0ph6P",
        "outputId": "a7bcb927-b1c6-4f3a-c09c-61a1cfaeb958"
      },
      "source": [
        "print(\"Mean Accuracy: \",accuracy.mean())\n",
        "print(\"Mean precission: \", precision.mean())\n",
        "print(\"Mean recall: \",recall.mean())\n",
        "print(\"Mean f1 score: \",f1.mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Accuracy:  36.66666666666667\n",
            "Mean precission:  36.66666666666667\n",
            "Mean recall:  36.66666666666667\n",
            "Mean f1 score:  36.66666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm_kV51OpjtH",
        "outputId": "8f56a4cf-b1f5-40ce-e591-f8f2edc2b60e"
      },
      "source": [
        "# ====>> Hyperparameter tuning. on the Validatiopn Set \n",
        "\n",
        "# Do the splitting on the first fold\n",
        "# Train test validation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "# train(70%), validation (10%), and test(20%)\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(all_x_train[0], all_y_train[0] , test_size=0.1, random_state=random.randint(30,100))\n",
        "print(\"Size of the train dataset:\" + str(X_train.shape))\n",
        "print(\"Size of the validation dataset:\" + str(X_validation.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the train dataset:(108, 4)\n",
            "Size of the validation dataset:(12, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03i4VGBgp1rQ"
      },
      "source": [
        "# Hyperparameter tuning on the validation set is required to be done.\n",
        "# here we are choosing the best hyperparameters based on the accuracy value\n",
        "def get_best_hyperparameter(X_train, y_train, X_validation, y_validation, alpha, roh, num_iter):\n",
        "  valid_hypothesis = []\n",
        "  validation_accuracy = []\n",
        "  x = add_intercept(X_validation)\n",
        "  for i in range(0, len(alpha)):\n",
        "    all_hypothesis_valid = []\n",
        "    final_hypothesis = []\n",
        "    all_weights = sigmoid_neuron(X_train, y_train, lr=alpha[i], roh = roh[i], num_iter=num_iter[i])\n",
        "    y_predicted = predict(X_validation, y_validation, all_weights)\n",
        "    y_predicted = np.array(y_predicted)\n",
        "    accuracy[i] = accuracy_score(y_validation, y_predicted)*100\n",
        "    print(\"Validation Accuracy: \" + str(accuracy[i]))\n",
        "    # calculate the accuracy in the validation set\n",
        "  max_index = np.argmax(accuracy)\n",
        "  print(\"Best hyperparameter value is alpha = \" + str(alpha[max_index]) + \", roh = \" + str(roh[max_index]) + \" and num_iter = \" + str(num_iter[max_index]))\n",
        "  print(\"Best Hyperparameter accuracy: \" + str(accuracy[max_index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en6cYTPnp1uI"
      },
      "source": [
        "alpha = [0.01, 0.0001, 0.1, 0.2]\n",
        "roh =   [0.0001, 0.0000001, 0.000000001, 0.0000000000001]\n",
        "num_iter = [10, 20, 30, 40]\n",
        "get_best_hyperparameter(X_train, y_train, X_validation, y_validation,alpha, roh, num_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVZvSkIrqIE3"
      },
      "source": [
        "# Overfitting detection   \n",
        "def plotting(x, y_1, y_2, label_1, label_2, t):\n",
        "      plt.plot(x, y_1, label = label_1)\n",
        "      plt.plot(x, y_2, label = label_2)\n",
        "      plt.title(t)\n",
        "      plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GjlZXIpqPg5"
      },
      "source": [
        "def predict_inner(X, all_weights):\n",
        "  # add intercept into x values\n",
        "  #X = add_intercept(x)\n",
        "  y = []\n",
        "  for i in range(len(X)):\n",
        "    d1 = np.dot(all_weights[0], X[i].T)\n",
        "    d2 = np.dot(all_weights[1], X[i].T)\n",
        "    d3 = np.dot(all_weights[2], X[i].T)\n",
        "    if (d1 > d2 and d1 > d3):\n",
        "      y.append(0)\n",
        "    elif (d2 > d1 and d2 > d3):\n",
        "      y.append(1)\n",
        "    else :\n",
        "      y.append(2)\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwLPX79oqUlS"
      },
      "source": [
        "def sigmoid_neuron_overfitting_detection(x, y, x_valid, y_valid, lr=0.01, roh = 0.000001, num_iter=100):\n",
        "  x = add_intercept(x) # add intercept in the feature vectors (in independent varibales)\n",
        "  x_valid = add_intercept(x_valid)\n",
        "  all_hypothesis = []\n",
        "  all_weights = []\n",
        "  final_hypothesis = []\n",
        "  train_logloss = []\n",
        "  train_mse = []\n",
        "  validation_logloss = []\n",
        "  validation_mse = []\n",
        "  classes = list(set(y)) # find how many classes are there...\n",
        "  d = np.ones(len(classes))\n",
        "  # calculate the weight vector (2D array, shape will be (no_of_classes*no_of_feature_vector))\n",
        "  for i in range(0, len(classes)):\n",
        "    weight = np.ones(x.shape[1])*0.1\n",
        "    all_weights.append(weight)\n",
        "  all_weights = np.array(all_weights)\n",
        "  converged = True\n",
        "  epoch = 0\n",
        "  # make one hot encoding\n",
        "  y_onehot = one_hot_encoding(y)\n",
        "  y_valid_onehot = one_hot_encoding(y_valid)\n",
        "  current_loss = 0\n",
        "  while converged:\n",
        "    logloss_error = 0\n",
        "    mse_error = 0   # at the starting of each epoch mse will be 0\n",
        "    #----------------------------     Training Sample   ------------------------\n",
        "    for i in range(0, x.shape[0]): # for each training sample one by one\n",
        "      hypo = np.ones(len(classes))\n",
        "      for k in range(0, len(classes)): # for calculating d values\n",
        "        z = np.dot(x[i], all_weights[k].T)\n",
        "        h = sigmoid(z)  # hypothesis\n",
        "        hypo[k] = h\n",
        "        if (h>=0.5):\n",
        "          d[k] = 1 # predicted one\n",
        "        if (h<0.5):\n",
        "          d[k] = 0 # predicted one\n",
        "      # calculate the errror (mse and logloss)\n",
        "      # but we are converging through the logloss only\n",
        "      mse_error = mse_error + mse_in_iter(d, y_onehot[i])\n",
        "      logloss_error = logloss_error + loss(d, y_onehot[i])\n",
        "      # Weight updation using the current training sample\n",
        "      update_weights = []\n",
        "      for j in range(0, len(classes)):\n",
        "        all_weights[j] = all_weights[j] + x[i]*(y_onehot[i][j]-d[j])*lr\n",
        "    #---------------------------------------------------------------------------\n",
        "    # store train and validation mse epoch by epoch\n",
        "    train_logloss.append(logloss_error)\n",
        "    train_mse.append(mse_error)\n",
        "    #-----------------       check for the validation   ------------------------\n",
        "    for i in range(0, x_valid.shape[0]): # for each training sample one by one\n",
        "      hypo_valid = np.ones(len(classes))\n",
        "      for k in range(0, len(classes)): # for calculating d values\n",
        "        z_valid = np.dot(x_valid[i], all_weights[k].T)\n",
        "        h_valid = sigmoid(z_valid)  # hypothesis\n",
        "        hypo_valid[k] = h_valid\n",
        "      valid_mse_error = mse_error + mse_in_iter(d, y_valid_onehot[i])\n",
        "      valid_logloss_error = logloss_error + loss(d, y_valid_onehot[i])\n",
        "    validation_logloss.append(valid_logloss_error)\n",
        "    validation_mse.append(valid_mse_error)\n",
        "    print(f'Epoch: {epoch} ------>' + f'logloss: {logloss_error/x.shape[0]} ------>' + f' ------> Mse: {mse_error/x.shape[0]} \\t ')\n",
        "    if(abs(current_loss - (logloss_error/x.shape[0])) <= roh):\n",
        "        print(f\"Converged through roh criteria: epoch = {i}\")\n",
        "        break # converged\n",
        "    current_loss = logloss_error/x.shape[0] # save the previous error to calculate the diff in current error and previous error\n",
        "    epoch = epoch + 1\n",
        "    if (epoch== num_iter):\n",
        "      print(\"Converged through maximum epoch no criteria...\") # converged\n",
        "      # return the traning accuracy also\n",
        "      return all_weights\n",
        "  train_logloss = np.array(train_logloss)\n",
        "  train_mse = np.array(train_mse)\n",
        "  validation_logloss =  np.array(validation_logloss)\n",
        "  validation_mse = np.array(validation_mse)\n",
        "  plot_x = []\n",
        "  for i in range(0, epoch+1):\n",
        "    plot_x.append(i+1)\n",
        "  # plot here\n",
        "  plotting(plot_x, train_mse, validation_mse, \"Train Mse\",\"Validation Mse\", \"Epoch vs Training and Validation Mse\")\n",
        "  plotting(plot_x, train_logloss, validation_logloss, \"Train Logloss\",\"Validation Logloss\", \"Epoch vs Training and Validation Logloss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQhkFIaNqY6g",
        "outputId": "f4c03f70-3cf5-4b3b-c720-df828d118300"
      },
      "source": [
        "sigmoid_neuron_overfitting_detection(X_train, y_train, X_validation, y_validation, lr=0.01, roh = 0.000001, num_iter=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in multiply\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 1 ------>logloss: nan ------> ------> Mse: 0.6805555555555556 \t \n",
            "Epoch: 2 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 3 ------>logloss: nan ------> ------> Mse: 0.6898148148148148 \t \n",
            "Epoch: 4 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 5 ------>logloss: nan ------> ------> Mse: 0.6666666666666666 \t \n",
            "Epoch: 6 ------>logloss: nan ------> ------> Mse: 0.6712962962962963 \t \n",
            "Epoch: 7 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 8 ------>logloss: nan ------> ------> Mse: 0.6435185185185185 \t \n",
            "Epoch: 9 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 10 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 11 ------>logloss: nan ------> ------> Mse: 0.6990740740740741 \t \n",
            "Epoch: 12 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 13 ------>logloss: nan ------> ------> Mse: 0.6712962962962963 \t \n",
            "Epoch: 14 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 15 ------>logloss: nan ------> ------> Mse: 0.6435185185185185 \t \n",
            "Epoch: 16 ------>logloss: nan ------> ------> Mse: 0.6666666666666666 \t \n",
            "Epoch: 17 ------>logloss: nan ------> ------> Mse: 0.6574074074074074 \t \n",
            "Epoch: 18 ------>logloss: nan ------> ------> Mse: 0.6342592592592593 \t \n",
            "Epoch: 19 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 20 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 21 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 22 ------>logloss: nan ------> ------> Mse: 0.6574074074074074 \t \n",
            "Epoch: 23 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 24 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 25 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 26 ------>logloss: nan ------> ------> Mse: 0.6111111111111112 \t \n",
            "Epoch: 27 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 28 ------>logloss: nan ------> ------> Mse: 0.6342592592592593 \t \n",
            "Epoch: 29 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 30 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 31 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 32 ------>logloss: nan ------> ------> Mse: 0.6574074074074074 \t \n",
            "Epoch: 33 ------>logloss: nan ------> ------> Mse: 0.6805555555555556 \t \n",
            "Epoch: 34 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 35 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 36 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 37 ------>logloss: nan ------> ------> Mse: 0.6481481481481481 \t \n",
            "Epoch: 38 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 39 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 40 ------>logloss: nan ------> ------> Mse: 0.6666666666666666 \t \n",
            "Epoch: 41 ------>logloss: nan ------> ------> Mse: 0.6481481481481481 \t \n",
            "Epoch: 42 ------>logloss: nan ------> ------> Mse: 0.6481481481481481 \t \n",
            "Epoch: 43 ------>logloss: nan ------> ------> Mse: 0.6712962962962963 \t \n",
            "Epoch: 44 ------>logloss: nan ------> ------> Mse: 0.6018518518518519 \t \n",
            "Epoch: 45 ------>logloss: nan ------> ------> Mse: 0.6064814814814815 \t \n",
            "Epoch: 46 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 47 ------>logloss: nan ------> ------> Mse: 0.6666666666666666 \t \n",
            "Epoch: 48 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 49 ------>logloss: nan ------> ------> Mse: 0.6666666666666666 \t \n",
            "Epoch: 50 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 51 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 52 ------>logloss: nan ------> ------> Mse: 0.6064814814814815 \t \n",
            "Epoch: 53 ------>logloss: nan ------> ------> Mse: 0.6435185185185185 \t \n",
            "Epoch: 54 ------>logloss: nan ------> ------> Mse: 0.6203703703703703 \t \n",
            "Epoch: 55 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 56 ------>logloss: nan ------> ------> Mse: 0.6064814814814815 \t \n",
            "Epoch: 57 ------>logloss: nan ------> ------> Mse: 0.6342592592592593 \t \n",
            "Epoch: 58 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 59 ------>logloss: nan ------> ------> Mse: 0.5972222222222222 \t \n",
            "Epoch: 60 ------>logloss: nan ------> ------> Mse: 0.6342592592592593 \t \n",
            "Epoch: 61 ------>logloss: nan ------> ------> Mse: 0.6064814814814815 \t \n",
            "Epoch: 62 ------>logloss: nan ------> ------> Mse: 0.625 \t \n",
            "Epoch: 63 ------>logloss: nan ------> ------> Mse: 0.625 \t \n",
            "Epoch: 64 ------>logloss: nan ------> ------> Mse: 0.6111111111111112 \t \n",
            "Epoch: 65 ------>logloss: nan ------> ------> Mse: 0.625 \t \n",
            "Epoch: 66 ------>logloss: nan ------> ------> Mse: 0.6481481481481481 \t \n",
            "Epoch: 67 ------>logloss: nan ------> ------> Mse: 0.625 \t \n",
            "Epoch: 68 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 69 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Epoch: 70 ------>logloss: nan ------> ------> Mse: 0.6435185185185185 \t \n",
            "Epoch: 71 ------>logloss: nan ------> ------> Mse: 0.6342592592592593 \t \n",
            "Epoch: 72 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 73 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 74 ------>logloss: nan ------> ------> Mse: 0.6574074074074074 \t \n",
            "Epoch: 75 ------>logloss: nan ------> ------> Mse: 0.6574074074074074 \t \n",
            "Epoch: 76 ------>logloss: nan ------> ------> Mse: 0.6435185185185185 \t \n",
            "Epoch: 77 ------>logloss: nan ------> ------> Mse: 0.6111111111111112 \t \n",
            "Epoch: 78 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 79 ------>logloss: nan ------> ------> Mse: 0.5972222222222222 \t \n",
            "Epoch: 80 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 81 ------>logloss: nan ------> ------> Mse: 0.6759259259259259 \t \n",
            "Epoch: 82 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 83 ------>logloss: nan ------> ------> Mse: 0.6157407407407407 \t \n",
            "Epoch: 84 ------>logloss: nan ------> ------> Mse: 0.5972222222222222 \t \n",
            "Epoch: 85 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 86 ------>logloss: nan ------> ------> Mse: 0.625 \t \n",
            "Epoch: 87 ------>logloss: nan ------> ------> Mse: 0.6666666666666666 \t \n",
            "Epoch: 88 ------>logloss: nan ------> ------> Mse: 0.6388888888888888 \t \n",
            "Epoch: 89 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 90 ------>logloss: nan ------> ------> Mse: 0.6481481481481481 \t \n",
            "Epoch: 91 ------>logloss: nan ------> ------> Mse: 0.5925925925925926 \t \n",
            "Epoch: 92 ------>logloss: nan ------> ------> Mse: 0.6203703703703703 \t \n",
            "Epoch: 93 ------>logloss: nan ------> ------> Mse: 0.6296296296296297 \t \n",
            "Epoch: 94 ------>logloss: nan ------> ------> Mse: 0.6435185185185185 \t \n",
            "Epoch: 95 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 96 ------>logloss: nan ------> ------> Mse: 0.6342592592592593 \t \n",
            "Epoch: 97 ------>logloss: nan ------> ------> Mse: 0.6527777777777778 \t \n",
            "Epoch: 98 ------>logloss: nan ------> ------> Mse: 0.6759259259259259 \t \n",
            "Epoch: 99 ------>logloss: nan ------> ------> Mse: 0.6620370370370371 \t \n",
            "Converged through maximum epoch no criteria...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.12 , -0.16 ,  0.098,  0.045, -0.111],\n",
              "       [ 1.2  , -0.231, -0.031, -0.178,  0.436],\n",
              "       [-0.67 ,  0.183, -0.073, -0.018, -0.161]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}